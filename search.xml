<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Spark读写MySQL</title>
      <link href="/2022/03/12/SparkMySQL/"/>
      <url>/2022/03/12/SparkMySQL/</url>
      
        <content type="html"><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>本文就简单介绍一下Spark读写MySQL的几种方式，不同场景下可以灵活选取。    </p><p>环境说明：    </p><blockquote><p>CDH版本：CDH 6.3.1<br>Spark版本：2.4.0<br>MySQL版本：5.7    </p></blockquote><h3 id="读取MySQL表"><a href="#读取MySQL表" class="headerlink" title="读取MySQL表"></a>读取MySQL表</h3><p>Spark读取MySQL数据可以有单分区和多分区两种方式，一般读取小数据量的表采用简单的单分区模式就可以，对于比较大的单分区抽取需要消耗时间较长的表来说，采用多分区模式读取性能会更好。    </p><h4 id="单分区单线程读取"><a href="#单分区单线程读取" class="headerlink" title="单分区单线程读取"></a>单分区单线程读取</h4><p>此种方式是最简单的读取方式，但只有单线程，仅限于小数据量表，需要谨慎在生产库中使用，指定连接地址和表名即可:    </p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> jdbcUrl = <span class="string">&quot;jdbc:mysql://xxx.xxx.xxx.xxx:3306/test?useUnicode=true&amp;characterEncoding=utf8&amp;tinyInt1isBit=false&quot;</span></span><br><span class="line"><span class="keyword">val</span> jdbcUser = <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="keyword">val</span> jdbcPass = <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="comment">// 可以直接指定表名，也可以写 SELECT 语句（必须要有临时表包裹），比如：</span></span><br><span class="line"><span class="comment">// val table = &quot;(select * from test.test_table where status = 1) tmp&quot;</span></span><br><span class="line"><span class="keyword">val</span> table = <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="keyword">val</span> df = spark.read</span><br><span class="line">  .format(<span class="string">&quot;jdbc&quot;</span>)</span><br><span class="line">  .option(<span class="string">&quot;url&quot;</span>, jdbcUrl)</span><br><span class="line">  .option(<span class="string">&quot;user&quot;</span>, jdbcUser)</span><br><span class="line">  .option(<span class="string">&quot;password&quot;</span>, jdbcPass)</span><br><span class="line">  .option(<span class="string">&quot;driver&quot;</span>, <span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>)</span><br><span class="line">  .option(<span class="string">&quot;dbtable&quot;</span>, table)</span><br><span class="line">  .load()</span><br></pre></td></tr></table></figure><h4 id="多分区并行读取"><a href="#多分区并行读取" class="headerlink" title="多分区并行读取"></a>多分区并行读取</h4><p>此种方式对于抽取数据量较大的表有很好的性能提升，但仅限于有连续数值型主键（比如自增id）的数据表：    </p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> jdbcUrl = <span class="string">&quot;jdbc:mysql://xxx.xxx.xxx.xxx:3306/test?useUnicode=true&amp;characterEncoding=utf8&amp;tinyInt1isBit=false&quot;</span></span><br><span class="line"><span class="keyword">val</span> jdbcUser = <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="keyword">val</span> jdbcPass = <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="comment">// 可以直接指定表名，也可以写 SELECT 语句（必须要有临时表包裹），比如：</span></span><br><span class="line"><span class="comment">// val table = &quot;(select * from test.test_table where status = 1) tmp&quot;</span></span><br><span class="line"><span class="keyword">val</span> table = <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="keyword">val</span> partitionNum = <span class="number">6</span></span><br><span class="line"><span class="keyword">val</span> minId = <span class="number">1</span></span><br><span class="line"><span class="keyword">val</span> maxId = <span class="number">6000000</span></span><br><span class="line"><span class="keyword">val</span> df = spark.read</span><br><span class="line">  .format(<span class="string">&quot;jdbc&quot;</span>)</span><br><span class="line">  .option(<span class="string">&quot;url&quot;</span>, jdbcUrl)</span><br><span class="line">  .option(<span class="string">&quot;user&quot;</span>, jdbcUser)</span><br><span class="line">  .option(<span class="string">&quot;password&quot;</span>, jdbcPass)</span><br><span class="line">  .option(<span class="string">&quot;driver&quot;</span>, <span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>)</span><br><span class="line">  .option(<span class="string">&quot;dbtable&quot;</span>, table)</span><br><span class="line">  <span class="comment">// 以下4个配置项必须同时使用</span></span><br><span class="line">  <span class="comment">// 分区数量，可以理解为读取并行度、线程数</span></span><br><span class="line">  .option(<span class="string">&quot;numPartitions&quot;</span>, partitionNum)</span><br><span class="line">  <span class="comment">// 分区字段，必须为数字、日期、时间戳字段</span></span><br><span class="line">  .option(<span class="string">&quot;partitionColumn&quot;</span>, <span class="string">&quot;id&quot;</span>)</span><br><span class="line">  <span class="comment">// lowerBound 和 upperBound 仅用于计算每个分区的取数步长，不用于数据过滤</span></span><br><span class="line">  <span class="comment">// 分区字段的最小值</span></span><br><span class="line">  .option(<span class="string">&quot;lowerBound&quot;</span>, minId)</span><br><span class="line">  <span class="comment">// 分区字段的最大值</span></span><br><span class="line">  .option(<span class="string">&quot;upperBound&quot;</span>, maxId)</span><br><span class="line">  .load()</span><br></pre></td></tr></table></figure><h3 id="写入MySQL表"><a href="#写入MySQL表" class="headerlink" title="写入MySQL表"></a>写入MySQL表</h3><p>追加写和覆盖写比较简单，但要注意覆盖写表可能会出现删表重建的操作。    </p><h4 id="追加写"><a href="#追加写" class="headerlink" title="追加写"></a>追加写</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">df.write</span><br><span class="line">  .format(<span class="string">&quot;jdbc&quot;</span>)</span><br><span class="line">  .mode(<span class="type">SaveMode</span>.<span class="type">Append</span>)</span><br><span class="line">  .option(<span class="string">&quot;driver&quot;</span>, <span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>)</span><br><span class="line">  .option(<span class="string">&quot;url&quot;</span>, jdbcUrl)</span><br><span class="line">  .option(<span class="string">&quot;dbtable&quot;</span>, table)</span><br><span class="line">  .option(<span class="string">&quot;user&quot;</span>, jdbcUser)</span><br><span class="line">  .option(<span class="string">&quot;password&quot;</span>, jdbcPass)</span><br><span class="line">  <span class="comment">// JDBC批大小，默认 1000，灵活调整该值可以提高写入性能</span></span><br><span class="line">  .option(<span class="string">&quot;batchsize&quot;</span>, <span class="number">10000</span>)</span><br><span class="line">  <span class="comment">// 事务级别，默认为 READ_UNCOMMITTED，无事务要求可以填 NONE 以提高性能</span></span><br><span class="line">  .option(<span class="string">&quot;isolationLevel&quot;</span>, <span class="string">&quot;NONE&quot;</span>)</span><br><span class="line">  .save()</span><br></pre></td></tr></table></figure><h4 id="覆盖写"><a href="#覆盖写" class="headerlink" title="覆盖写"></a>覆盖写</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">df.write</span><br><span class="line">  .format(<span class="string">&quot;jdbc&quot;</span>)</span><br><span class="line">  .mode(<span class="type">SaveMode</span>.<span class="type">Overwrite</span>)</span><br><span class="line">  .option(<span class="string">&quot;driver&quot;</span>, <span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>)</span><br><span class="line">  .option(<span class="string">&quot;url&quot;</span>, jdbcUrl)</span><br><span class="line">  .option(<span class="string">&quot;dbtable&quot;</span>, table)</span><br><span class="line">  .option(<span class="string">&quot;user&quot;</span>, jdbcUser)</span><br><span class="line">  .option(<span class="string">&quot;password&quot;</span>, jdbcPass)</span><br><span class="line">  <span class="comment">// JDBC批大小，默认 1000，灵活调整该值可以提高写入性能</span></span><br><span class="line">  .option(<span class="string">&quot;batchsize&quot;</span>, <span class="number">10000</span>)</span><br><span class="line">  <span class="comment">// 事务级别，默认为 READ_UNCOMMITTED，无事务要求可以填 NONE 以提高性能</span></span><br><span class="line">  .option(<span class="string">&quot;isolationLevel&quot;</span>, <span class="string">&quot;NONE&quot;</span>)</span><br><span class="line">  <span class="comment">// 需要注意该配置项，Overwrite 模式下，不设置为 true 会删表重建</span></span><br><span class="line">  .option(<span class="string">&quot;truncate&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br><span class="line">  .save()</span><br></pre></td></tr></table></figure><h4 id="更新写-UPSERT-INSERT-OR-UPDATE"><a href="#更新写-UPSERT-INSERT-OR-UPDATE" class="headerlink" title="更新写(UPSERT/INSERT OR UPDATE)"></a>更新写(UPSERT/INSERT OR UPDATE)</h4><p>更新接入比较复杂一些，一般结合 <code>foreachPartition</code> 使用。同时需要目标表创建 <code>UNIQUE KEY</code>，因为需要基于<code>UNIQUE KEY</code>来实现<code>UPSERT</code>。    </p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">df.foreachPartition(iter =&gt; &#123;</span><br><span class="line">  <span class="keyword">val</span> conn = ds.getConnection</span><br><span class="line">  <span class="keyword">val</span> sql =</span><br><span class="line">      <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        |INSERT INTO test_table (uid,a,b,c,d,e)</span></span><br><span class="line"><span class="string">        |VALUES (?,?,?,?,?,?)</span></span><br><span class="line"><span class="string">        |ON DUPLICATE KEY</span></span><br><span class="line"><span class="string">        |UPDATE c = ?, d = ?</span></span><br><span class="line"><span class="string">        |&quot;&quot;&quot;</span>.stripMargin</span><br><span class="line">  <span class="keyword">val</span> ps = conn.prepareStatement(sql)</span><br><span class="line">  iter.foreach(row =&gt; &#123;</span><br><span class="line">    <span class="keyword">val</span> uid = row.getAs[<span class="type">Long</span>](<span class="string">&quot;pid&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> a = row.getAs[<span class="type">Long</span>](<span class="string">&quot;a&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> b = row.getAs[<span class="type">String</span>](<span class="string">&quot;b&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> c = row.getAs[java.math.<span class="type">BigDecimal</span>](<span class="string">&quot;c&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> d = row.getAs[java.math.<span class="type">BigDecimal</span>](<span class="string">&quot;d&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> e = row.getAs[<span class="type">Byte</span>](<span class="string">&quot;e&quot;</span>)</span><br><span class="line">    ps.setLong(<span class="number">1</span>, uid)</span><br><span class="line">    ps.setLong(<span class="number">2</span>, a)</span><br><span class="line">    ps.setString(<span class="number">3</span>, b)</span><br><span class="line">    ps.setBigDecimal(<span class="number">4</span>, c)</span><br><span class="line">    ps.setBigDecimal(<span class="number">5</span>, d)</span><br><span class="line">    ps.setByte(<span class="number">6</span>, e)</span><br><span class="line">    ps.setBigDecimal(<span class="number">7</span>, c)</span><br><span class="line">    ps.setBigDecimal(<span class="number">8</span>, d)</span><br><span class="line">    ps.executeUpdate()</span><br><span class="line">  &#125;)</span><br><span class="line">  <span class="type">DbUtil</span>.close(conn)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure><h3 id="代码封装示例"><a href="#代码封装示例" class="headerlink" title="代码封装示例"></a>代码封装示例</h3><p>基于上面的介绍，可以将Spark读写MySQL进行一个简单地封装，使用起来会更加方便：</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 读取 MySQL 表，并行读取时固定 id 为分区字段</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @param spark        SparkSession</span></span><br><span class="line"><span class="comment"> * @param table        表名</span></span><br><span class="line"><span class="comment"> * @param partitionNum 分区数量</span></span><br><span class="line"><span class="comment"> * @param filterKey    过滤字段</span></span><br><span class="line"><span class="comment"> * @param filterMin    过滤条件最小值</span></span><br><span class="line"><span class="comment"> * @param filterMax     过滤条件最大值</span></span><br><span class="line"><span class="comment"> * @param jdbcUrl      url</span></span><br><span class="line"><span class="comment"> * @param jdbcUser     user</span></span><br><span class="line"><span class="comment"> * @param jdbcPass     password</span></span><br><span class="line"><span class="comment"> * @return</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readMysqlPartById</span></span>(spark: <span class="type">SparkSession</span>, table: <span class="type">String</span>, partitionNum: <span class="type">Int</span> = <span class="number">0</span>,</span><br><span class="line">                      filterKey: <span class="type">String</span> = <span class="string">&quot;&quot;</span>, filterMin: <span class="type">String</span> = <span class="string">&quot;&quot;</span>, filterMax: <span class="type">String</span> = <span class="string">&quot;&quot;</span>,</span><br><span class="line">                      jdbcUrl: <span class="type">String</span> = url, jdbcUser: <span class="type">String</span> = user, jdbcPass: <span class="type">String</span> = pass): <span class="type">DataFrame</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> conn = spark.read</span><br><span class="line">    .format(<span class="string">&quot;jdbc&quot;</span>)</span><br><span class="line">    .option(<span class="string">&quot;url&quot;</span>, jdbcUrl)</span><br><span class="line">    .option(<span class="string">&quot;user&quot;</span>, jdbcUser)</span><br><span class="line">    .option(<span class="string">&quot;password&quot;</span>, jdbcPass)</span><br><span class="line">    .option(<span class="string">&quot;driver&quot;</span>, <span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>)</span><br><span class="line">  <span class="keyword">if</span> (partitionNum == <span class="number">0</span>) &#123;</span><br><span class="line">    conn.option(<span class="string">&quot;dbtable&quot;</span>, table).load()</span><br><span class="line">  &#125; esle &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="string">&quot;&quot;</span>.equals(filterKey)) &#123;</span><br><span class="line">      <span class="comment">// 读取最大id</span></span><br><span class="line">      <span class="keyword">val</span> ids = conn.option(<span class="string">&quot;dbtable&quot;</span>, <span class="string">s&quot;(select min(id),max(id) from <span class="subst">$table</span>) tmp&quot;</span>)</span><br><span class="line">        .load()</span><br><span class="line">        .first()</span><br><span class="line">      <span class="keyword">if</span> (ids.isNullAt(<span class="number">0</span>)) &#123;</span><br><span class="line">        spark.emptyDataFrame</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">val</span> minId = <span class="type">String</span>.valueOf(ids.get(<span class="number">0</span>)).toLong</span><br><span class="line">        <span class="keyword">val</span> maxId = <span class="type">String</span>.valueOf(ids.get(<span class="number">1</span>)).toLong</span><br><span class="line">        conn.option(<span class="string">&quot;dbtable&quot;</span>, table)</span><br><span class="line">          .option(<span class="string">&quot;numPartitions&quot;</span>, partitionNum)</span><br><span class="line">          .option(<span class="string">&quot;partitionColumn&quot;</span>, <span class="string">&quot;id&quot;</span>)</span><br><span class="line">          .option(<span class="string">&quot;lowerBound&quot;</span>, minId)</span><br><span class="line">          .option(<span class="string">&quot;upperBound&quot;</span>, maxId)</span><br><span class="line">          .load()</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">val</span> filter = <span class="string">s&quot;where <span class="subst">$filterKey</span> between &#x27;<span class="subst">$filterMin</span>&#x27; and &#x27;<span class="subst">$filterMax</span>&#x27;&quot;</span></span><br><span class="line">      <span class="comment">// 读取最大id</span></span><br><span class="line">      <span class="keyword">val</span> ids = conn.option(<span class="string">&quot;dbtable&quot;</span>, <span class="string">s&quot;(select min(id),max(id) from <span class="subst">$table</span> <span class="subst">$filter</span>) tmp&quot;</span>)</span><br><span class="line">        .load()</span><br><span class="line">        .first()</span><br><span class="line">      <span class="keyword">if</span> (ids.isNullAt(<span class="number">0</span>)) &#123;</span><br><span class="line">        spark.emptyDataFrame</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">val</span> minId = <span class="type">String</span>.valueOf(ids.get(<span class="number">0</span>)).toLong</span><br><span class="line">        <span class="keyword">val</span> maxId = <span class="type">String</span>.valueOf(ids.get(<span class="number">1</span>)).toLong</span><br><span class="line">        conn.option(<span class="string">&quot;dbtable&quot;</span>, <span class="string">s&quot;(select * from <span class="subst">$table</span> <span class="subst">$filter</span>) tmp&quot;</span>)</span><br><span class="line">          .option(<span class="string">&quot;numPartitions&quot;</span>, partitionNum)</span><br><span class="line">          .option(<span class="string">&quot;partitionColumn&quot;</span>, <span class="string">&quot;id&quot;</span>)</span><br><span class="line">          .option(<span class="string">&quot;lowerBound&quot;</span>, minId)</span><br><span class="line">          .option(<span class="string">&quot;upperBound&quot;</span>, maxId)</span><br><span class="line">          .load()</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Spark写入MySQL通用方法</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @param df       Spark DataFrame</span></span><br><span class="line"><span class="comment"> * @param saveMode 写入模式，覆盖 or 追加</span></span><br><span class="line"><span class="comment"> * @param table    目标表名</span></span><br><span class="line"><span class="comment"> * @param jdbcUrl  目标数据库jdbc连接</span></span><br><span class="line"><span class="comment"> * @param jdbcUser 目标数据库访问用户</span></span><br><span class="line"><span class="comment"> * @param jdbcPass 目标数据库访问密码</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">writeMysql</span></span>(df: <span class="type">DataFrame</span>, saveMode: <span class="type">SaveMode</span>, table: <span class="type">String</span>,</span><br><span class="line">               jdbcUrl: <span class="type">String</span> = url, jdbcUser: <span class="type">String</span> = user, jdbcPass: <span class="type">String</span> = pass): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> dfWriter = df.write</span><br><span class="line">    .format(<span class="string">&quot;jdbc&quot;</span>)</span><br><span class="line">    .mode(saveMode)</span><br><span class="line">    .option(<span class="string">&quot;driver&quot;</span>, <span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>)</span><br><span class="line">    .option(<span class="string">&quot;url&quot;</span>, jdbcUrl)</span><br><span class="line">    .option(<span class="string">&quot;dbtable&quot;</span>, table)</span><br><span class="line">    .option(<span class="string">&quot;user&quot;</span>, jdbcUser)</span><br><span class="line">    .option(<span class="string">&quot;password&quot;</span>, jdbcPass)</span><br><span class="line">    .option(<span class="string">&quot;batchsize&quot;</span>, <span class="number">10000</span>)</span><br><span class="line">    .option(<span class="string">&quot;isolationLevel&quot;</span>, <span class="string">&quot;NONE&quot;</span>)</span><br><span class="line">  <span class="keyword">if</span> (saveMode == <span class="type">SaveMode</span>.<span class="type">Overwrite</span>) &#123;</span><br><span class="line">    <span class="comment">// 如果覆盖写入，采用 truncate 模式，避免重建表</span></span><br><span class="line">    dfWriter.option(<span class="string">&quot;truncate&quot;</span>, <span class="string">&quot;true&quot;</span>).save()</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    dfWriter.save()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="参考内容"><a href="#参考内容" class="headerlink" title="参考内容"></a>参考内容</h3><blockquote><p><a href="https://spark.apache.org/docs/2.4.0/sql-data-sources-jdbc.html">Spark JDBC data sources</a>    </p></blockquote><h3 id="本章完"><a href="#本章完" class="headerlink" title="本章完"></a>本章完</h3>]]></content>
      
      
      <categories>
          
          <category> Spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL </tag>
            
            <tag> ETL </tag>
            
            <tag> Spark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CDH6集群中安装StreamSets</title>
      <link href="/2020/01/03/sdcInstall/"/>
      <url>/2020/01/03/sdcInstall/</url>
      
        <content type="html"><![CDATA[<h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>StreamSets（StreamSets Data Collector）是一款开源的强大的实时数据采集和ETL工具，具有易于使用的用户界面，甚至于不需要写任何代码，只需要做一些拖拽和配置即可完成复杂的Pipeline（数据管道）设计。<br>类似于我们所熟知的ETL工具Kettle，StreamSets也具有很多的组件，其组件可分为三大类，分别对应数据的采集、处理和落地：    </p><ul><li>Origin（数据源）</li><li>Processor（处理器）</li><li>Destination（目的地）   </li></ul><p>StreamSets有多种安装方式，可以使用tar包、rpm包、Cloudera Parcels等方式进行安装。由于我所使用的集群为CDH，故本文就只简单介绍一下StreamSets在CDH集群中的安装配置过程，在后续的文章中我会使用一些例子来介绍StreamSets具体的使用。    </p><p>环境说明：    </p><blockquote><p>Linux版本：CentOS 7.7<br>CDH版本：CDH 6.3.1<br>StreamSets版本：3.12.0    </p></blockquote><p>相关链接：    </p><blockquote><p><a href="https://archives.streamsets.com/index.html">StreamSets 下载页面</a><br><a href="https://github.com/streamsets/datacollector">StreamSets Github页面</a><br><a href="https://streamsets.com/">StreamSets 官网</a>    </p></blockquote><h4 id="安装文件准备"><a href="#安装文件准备" class="headerlink" title="安装文件准备"></a>安装文件准备</h4><p>进入下载页面，默认最先展示的即为最新版本，找到Cloudera Parcels下面对应操作系统版本的下载链接，下载3个文件即可：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/sdc/20200103/tVErKLwtRLwE.png" alt="download"><br>分别为：    </p><blockquote><p>parcel包：STREAMSETS_DATACOLLECTOR-3.12.0-el7.parcel<br>校验文件：STREAMSETS_DATACOLLECTOR-3.12.0-el7.parcel.sha<br>csd文件：STREAMSETS-3.12.0.jar    </p></blockquote><p>文件下载完成后将parcel包和校验文件上传至CDH管理节点上的parcel本地存储库目录下，通常该目录默认为：<code>/opt/cloudera/parcel-repo</code>。将csd文件上传至CDH管理节点上的<code>/opt/cloudera/csd</code>目录下，然后将这几个文件的所有者修改为<code>cloudera-scm:cloudera-scm</code>。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/sdc/20200103/u1BlMTWjTIR0.png" alt="parcel"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/sdc/20200103/ukx0gjrNN1cf.png" alt="csd">    </p><p>最后重启一下<strong>cloudera-scm-server</strong>服务即可在CM的WEB界面上看到StreamSets的Parcel包，默认为<code>未分配/未激活</code>状态，手动分配激活一下即可。<br><code># systemctl restart cloudera-scm-server</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/sdc/20200103/Y52zdZ0CuR3J.png" alt="img">    </p><h4 id="StreamSets安装"><a href="#StreamSets安装" class="headerlink" title="StreamSets安装"></a>StreamSets安装</h4><p>如果上面的步骤都没有出错的话，已经可以在集群的添加服务列表中看到StreamSets选项了，勾选StreamSets，继续：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/sdc/20200103/WcqRvcpErTNu.png" alt="img"><br>分配主机：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/sdc/20200103/1GMzhZCJt1dx.png" alt="img"><br>修改配置（最好还是修改一下默认目录）：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/sdc/20200103/HVizr6OusqnL.png" alt="img"><br>后续下一步下一步即可安装成功，可在CM首页看到StreamSets服务项：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/sdc/20200103/LIgrS1KS4fiP.png" alt="img"><br>安装完成后即可访问StreamSets的web界面的，默认端口为：18630，默认用户密码为：admin/admin。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/sdc/20200103/zexdPcUK322A.png" alt="img">    </p><h4 id="StreamSets配置项"><a href="#StreamSets配置项" class="headerlink" title="StreamSets配置项"></a>StreamSets配置项</h4><ul><li>修改java最大堆内存<br>默认为1G内存，可根据实际应用场景修改，前往CM网页StreamSets的服务配置页搜索<code>sdc-env.sh</code>，在<code>sdc-env.sh 的 Data Collector 高级配置代码段（安全阀）</code>配置项中添加<code>export SDC_JAVA_OPTS=&quot;-Xmx3072m -Xms3072m&quot;</code>     </li><li>修改最大batch大小<br>表示每次从数据源读取一批数据的最大记录数，默认最大batch大小为1000，可根据实际情况进行调整，前往CM网页StreamSets的服务配置页搜索<code>maxBatchSize</code>，修改<code>Max Batch Size (Running)</code>的值为合适大小。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/sdc/20200103/mTfhAtXnoika.png" alt="img"><br>其余配置项可参考<a href="https://streamsets.com/documentation/datacollector/3.12.x/help/datacollector/UserGuide/Configuration/DCConfig.html#task_lxk_kjw_1r">官方配置文档</a>。<br>配置修改完成后重启服务生效。</li></ul><h4 id="本章完"><a href="#本章完" class="headerlink" title="本章完"></a>本章完</h4>]]></content>
      
      
      <categories>
          
          <category> StreamSets </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CDH </tag>
            
            <tag> Hadoop </tag>
            
            <tag> Hive </tag>
            
            <tag> ETL </tag>
            
            <tag> StreamSets </tag>
            
            <tag> Kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MongoDB简单使用操作</title>
      <link href="/2019/10/01/MongoDB/"/>
      <url>/2019/10/01/MongoDB/</url>
      
        <content type="html"><![CDATA[<p>本文简单介绍了MongoDB在Linux下的简单安装和配置操作，基于MongoDB 4.0.10，CentOS版本7.2。</p><p>官方推荐操作系统：</p><ul><li>Amazon Linux</li><li>Debian 8</li><li>RHEL/CentOS 6.2+</li><li>SLES 12</li><li>Ubuntu LTS 16.04</li><li>Windows Server 2012 R2</li></ul><h4 id="数据库安装"><a href="#数据库安装" class="headerlink" title="数据库安装"></a>数据库安装</h4><ol><li><p>下载安装包<br><code># wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel70-4.0.10.tgz</code></p></li><li><p>解压<br><code># tar -zxvf mongodb-linux-x86_64-rhel70-4.0.10.tgz -C /opt/mongodb/</code></p></li><li><p>安装依赖<br><code># yum -y install libcurl openssl</code></p></li><li><p>添加环境变量<br><code># vim /etc/profile</code>    </p> <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=/opt/mongodb/mongodb-linux-x86_64-rhel70-4.0.10</span><br><span class="line">bin:<span class="variable">$PATH</span></span><br><span class="line">```    </span><br><span class="line">`<span class="comment"># source /etc/profile`</span></span><br><span class="line"></span><br><span class="line">5. 查看是否安装成功    </span><br><span class="line">`<span class="comment"># mongod --version`</span></span><br></pre></td></tr></table></figure><p> db version v4.0.10<br> git version: c389e7f69f637f7a1ac3cc9fae843b635f20b766<br> OpenSSL version: OpenSSL 1.0.1e-fips 11 Feb 2013<br> allocator: tcmalloc<br> modules: none<br> build environment:</p><pre><code>distmod: rhel70distarch: x86_64target_arch: x86_64</code></pre> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">6. 创建mongod用户    </span><br><span class="line">`# useradd mongod`</span><br><span class="line"></span><br><span class="line">7. 更改mongodb安装目录用户组    </span><br><span class="line">`# chown mongod:mongod -R mongodb/`</span><br><span class="line"></span><br><span class="line">8. 切换到mongod用户    </span><br><span class="line">`# su mongod`</span><br><span class="line">注：以下全部为在mongod用户下进行的操作</span><br><span class="line"></span><br><span class="line">9. 创建config文件    </span><br><span class="line">`$ vim /opt/mongodb/datas/configs/mongod0.conf`    </span><br><span class="line">配置示例：    </span><br><span class="line">```profile</span><br><span class="line">systemLog:</span><br><span class="line">   destination: file</span><br><span class="line">   path: &quot;/opt/mongodb/datas/logs/mongod0.log&quot;</span><br><span class="line">   logAppend: true</span><br><span class="line">storage:</span><br><span class="line">   dbPath: /opt/mongodb/datas/data0</span><br><span class="line">   journal:</span><br><span class="line">      enabled: true</span><br><span class="line">processManagement:</span><br><span class="line">   fork: true</span><br><span class="line">   pidFilePath: /opt/mongodb/datas/logs/mongod0.pid</span><br><span class="line">net:</span><br><span class="line">   # 配置127.0.0.1只允许本机连接mongodb服务</span><br><span class="line">   # bindIp: 127.0.0.1</span><br><span class="line">   # 配置0.0.0.0可允许所有其他主机连接mongodb服务</span><br><span class="line">   bindIp: 0.0.0.0 </span><br><span class="line">   port: 20001</span><br><span class="line">setParameter:</span><br><span class="line">   enableLocalhostAuthBypass: false</span><br></pre></td></tr></table></figure></li><li><p>创建目录<br><code>$ mkdir /opt/mongodb/datas/data0</code><br><code>$ mkdir /opt/mongodb/datas/logs</code></p></li><li><p>启动mongod服务<br><code>$ mongod -f /opt/mongodb/datas/configs/mongod0.conf</code></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">about to fork child process, waiting until server is ready for connections.</span><br><span class="line">forked process: 20240</span><br><span class="line">child process started successfully, parent exiting</span><br></pre></td></tr></table></figure></li><li><p>关闭mongod服务<br><code>$ mongod --shutdown -f /opt/mongodb/datas/configs/mongod0.conf</code></p></li><li><p>进入shell<br><code>mongo --port 20001</code></p></li></ol><h4 id="配置副本集群"><a href="#配置副本集群" class="headerlink" title="配置副本集群"></a>配置副本集群</h4><ol><li>配置文件示例     <figure class="highlight profile"><table><tr><td class="code"><pre><span class="line">systemLog:</span><br><span class="line">   destination: file</span><br><span class="line">   path: <span class="string">&quot;/opt/mongod/log/mongod82.log&quot;</span></span><br><span class="line">   logAppend: true</span><br><span class="line">storage:</span><br><span class="line">   dbPath: /opt/mongod/data</span><br><span class="line">   journal:</span><br><span class="line">      enabled: true</span><br><span class="line">   wiredTiger:</span><br><span class="line">      engineConfig:</span><br><span class="line">         cacheSizeGB: <span class="number">32</span></span><br><span class="line">replication:</span><br><span class="line">  replSetName: myRep</span><br><span class="line">processManagement:</span><br><span class="line">   fork: true</span><br><span class="line">   pidFilePath: /opt/mongod/log/mongod82.pid</span><br><span class="line">net:</span><br><span class="line">   bindIp: <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span></span><br><span class="line">   port: <span class="number">30001</span></span><br><span class="line">setParameter:</span><br><span class="line">   enableLocalhostAuthBypass: false</span><br></pre></td></tr></table></figure></li><li>初始化集群<br><code>&gt; rs.initiate(&#123;_id:&quot;myRep&quot;, members:[&#123;_id:0, host:&quot;192.168.5.52:30001&quot;&#125;,&#123;_id:1, host:&quot;192.168.5.53:30001&quot;&#125;]&#125;)</code></li><li>为集群添加仲裁节点<br><code>&gt; rs.addArb(&quot;192.168.5.51:30001&quot;)</code></li><li>查看集群状态<br><code>&gt; rs.status()</code></li></ol><h4 id="其他配置说明"><a href="#其他配置说明" class="headerlink" title="其他配置说明"></a>其他配置说明</h4><ul><li><p>dbPath</p><ul><li>mongod用户必须拥有对配置的dbPath目录的读写权限</li><li>目录中的dbPath文件必须与配置的存储引擎相对应。如果dbPath包含由指定的存储引擎以外的存储引擎创建的数据文件，则不会启动</li></ul></li><li><p>WiredTiger</p><ul><li>默认WiredTiger内部缓存大小：50%(RAM - 1G) 或者 256MB</li><li>默认的WiredTiger内部缓存大小值假定每台计算机有一个MongoDB实例。如果单个计算机包含多个MongoDB实例，则应减少该设置以适应其他mongod 实例。</li><li>调整WiredTiger内部缓存参数：storage.wiredTiger.engineConfig.cacheSizeGB</li><li>应避免将WiredTiger内部缓存大小增加到其默认值以上</li></ul></li><li><p>Linux 平台的 NUMA 配置（根据实际情况配置）</p><ul><li>需要在Linux上禁用zone reclaim</li><li>修改方式：sysctl -w vm.zone_reclaim_mode=0</li><li>使用numactl启动mongod：numactl –interleave=all mongod -f /etc/mongod.conf</li><li>查看系统numa状态：numactl –hardware</li></ul></li><li><p>存储系统不建议使用NFS</p></li><li><p>使用NTP同步所有MongoDB节点</p></li><li><p>文件系统</p><ul><li>Linux下建议使用XFS</li><li>Windows下使用NTFS，不要使用任何FAT文件系统</li></ul></li><li><p>设置vm.swappiness值为1</p><ul><li>编辑文件：/etc/sysctl.conf ，添加一行：vm.swappiness=1</li><li>参考文章：<a href="https://blog.holoyoo.com/2018/11/30/CDH6Performance/">https://blog.holoyoo.com/2018/11/30/CDH6Performance/</a></li></ul></li><li><p>禁用THP</p><ul><li>编辑/etc/rc.d/rc.local文件，最下面添加两行配置：<ul><li>echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</li><li>echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag</li></ul></li><li>然后赋予/etc/rc.d/rc.local文件可执行权限：chmod +x /etc/rc.d/rc.local</li><li>参考文章：<a href="https://blog.holoyoo.com/2018/11/30/CDH6Performance/">https://blog.holoyoo.com/2018/11/30/CDH6Performance/</a></li></ul></li><li><p>RHEL/CentOS 7 下禁用tuned</p><ul><li>参考文章：<a href="https://blog.holoyoo.com/2018/11/30/CDH6Performance/">https://blog.holoyoo.com/2018/11/30/CDH6Performance/</a></li></ul></li><li><p>关闭selinux</p></li><li><p>后台运行</p><ul><li>mongod –fork</li><li>示例配置：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">systemLog:</span><br><span class="line">   destination: file</span><br><span class="line">   path: &quot;/var/log/mongodb/mongod.log&quot;</span><br><span class="line">   logAppend: true</span><br><span class="line">storage:</span><br><span class="line">   journal:</span><br><span class="line">      enabled: true</span><br><span class="line">processManagement:</span><br><span class="line">   fork: true</span><br><span class="line">   pidFilePath: /var/run/mongod.pid</span><br><span class="line">net:</span><br><span class="line">   bindIp: 127.0.0.1</span><br><span class="line">   port: 27017</span><br><span class="line">setParameter:</span><br><span class="line">   enableLocalhostAuthBypass: false</span><br></pre></td></tr></table></figure></li></ul></li><li><p>关闭mongod进程</p><ul><li>使用<code>kill -2 &lt;pid&gt;</code></li><li>永远不要使用 <code>kill -9 &lt;pid&gt;</code> 来关闭mongod进程</li></ul></li></ul><h4 id="修改副本集群所有节点IP"><a href="#修改副本集群所有节点IP" class="headerlink" title="修改副本集群所有节点IP"></a>修改副本集群所有节点IP</h4><ol><li>停止集群中所有节点mongod服务    </li><li>重新启动所有节点服务，不使用–replSet选项，使用不同于集群的端口号，并指定dbpath路径<br><code>mongod --dbpath /opt/mongod/data --port 30002</code></li><li>登陆mongo shell修改副本集配置<br><code>&gt; use local</code></li><li>查看原配置<br><code>&gt; db.system.replset.find()</code></li><li>在原配置基础上修改IP配置<br><code>&gt; cfg=&#123; &quot;_id&quot; : &quot;myRep&quot;, &quot;version&quot; : 1, &quot;protocolVersion&quot; : NumberLong(1), &quot;members&quot; : [ &#123; &quot;_id&quot; : 0, &quot;host&quot; : &quot;192.168.5.53:30001&quot;, &quot;arbiterOnly&quot; : false, &quot;buildIndexes&quot; : true, &quot;hidden&quot; : false, &quot;priority&quot; : 3, &quot;tags&quot; : &#123;  &#125;, &quot;slaveDelay&quot; : NumberLong(0), &quot;votes&quot; : 1 &#125;, &#123; &quot;_id&quot; : 1, &quot;host&quot; : &quot;192.168.5.52:30001&quot;, &quot;arbiterOnly&quot; : false, &quot;buildIndexes&quot; : true, &quot;hidden&quot; : false, &quot;priority&quot; : 2, &quot;tags&quot; : &#123;  &#125;, &quot;slaveDelay&quot; : NumberLong(0), &quot;votes&quot; : 1 &#125;, &#123; &quot;_id&quot; : 2, &quot;host&quot; : &quot;192.168.5.51:30001&quot;, &quot;arbiterOnly&quot; : true, &quot;buildIndexes&quot; : true, &quot;hidden&quot; : false, &quot;priority&quot; : 1, &quot;tags&quot; : &#123;  &#125;, &quot;slaveDelay&quot; : NumberLong(0), &quot;votes&quot; : 1 &#125; ], &quot;settings&quot; : &#123; &quot;chainingAllowed&quot; : true, &quot;heartbeatIntervalMillis&quot; : 2000, &quot;heartbeatTimeoutSecs&quot; : 10, &quot;electionTimeoutMillis&quot; : 10000, &quot;getLastErrorModes&quot; : &#123;  &#125;, &quot;getLastErrorDefaults&quot; : &#123; &quot;w&quot; : 1, &quot;wtimeout&quot; : 0 &#125; &#125; &#125;</code></li><li>更新配置<br><code>&gt; db.system.replset.update( &#123; &quot;_id&quot;: &quot;myRep&quot; &#125; , cfg )</code></li><li>退出mongo shell    </li><li>重新按照正常配置开启 mongodb 集群，查看集群状态<br><code>mongod -f /opt/mongod/config/mongod.conf</code></li></ol><h4 id="UnrecoverableRollbackError"><a href="#UnrecoverableRollbackError" class="headerlink" title="UnrecoverableRollbackError"></a>UnrecoverableRollbackError</h4><p>说明：副本集群某节点宕机后，无法回滚超过一天的数据，导致无法启动<br>报错信息：    </p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Rollback failed with unrecoverable error: UnrecoverableRollbackError: not willing to roll back more than 86400 seconds of data.</span><br></pre></td></tr></table></figure><p>解决办法：<br>  默认回滚时长为86400秒，即一天时间，可在配置中修改此参数。<br>  配置文件中添加一项配置，并设置合适的数值即可：</p><figure class="highlight profile"><table><tr><td class="code"><pre><span class="line">setParameter:</span><br><span class="line">   rollbackTimeLimitSecs: <span class="number">864000</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MongoDB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Logstash 7.0.0的简单使用操作</title>
      <link href="/2019/10/01/Logstash7/"/>
      <url>/2019/10/01/Logstash7/</url>
      
        <content type="html"><![CDATA[<p>本文是Logstash 7.0.0的同步任务的详细配置说明。<br>主要是自定义mapping以及多个数据源和目标的配置，我就直接放同步任务配置文件的内容了。<br>需要注意的是：    </p><ul><li>严禁过滤掉Logstash自动生成的<strong>type</strong>字段，否则会导致无法正常同步。</li><li>output中的type值需要与input中jdbc的type值相对应。</li></ul><h4 id="同步任务配置文件示例"><a href="#同步任务配置文件示例" class="headerlink" title="同步任务配置文件示例"></a>同步任务配置文件示例</h4><figure class="highlight profile"><table><tr><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">stdin &#123;&#125;</span><br><span class="line">jdbc &#123;</span><br><span class="line">type =&gt; <span class="string">&quot;audit_law&quot;</span></span><br><span class="line"> # 数据库连接地址</span><br><span class="line">jdbc_connection_string =&gt; <span class="string">&quot;jdbc:mysql://192.168.0.196:3306/auditbase?characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&quot;</span></span><br><span class="line"> # 数据库连接账号密码；</span><br><span class="line">jdbc_user =&gt; <span class="string">&quot;aaaa&quot;</span></span><br><span class="line">jdbc_password =&gt; <span class="string">&quot;123456&quot;</span></span><br><span class="line"> # MySQL依赖包路径；</span><br><span class="line">jdbc_driver_library =&gt; <span class="string">&quot;lib/jars/mysql-connector-java-5.1.41-bin.jar&quot;</span></span><br><span class="line"> # the name of the driver class for mysql</span><br><span class="line">jdbc_driver_class =&gt; <span class="string">&quot;com.mysql.jdbc.Driver&quot;</span></span><br><span class="line"># 解决中文乱码</span><br><span class="line">codec =&gt; plain &#123;charset =&gt; <span class="string">&quot;UTF-8&quot;</span>&#125;</span><br><span class="line"> # 数据库重连尝试次数</span><br><span class="line">connection_retry_attempts =&gt; <span class="string">&quot;3&quot;</span></span><br><span class="line"> # 判断数据库连接是否可用，默认false不开启</span><br><span class="line">jdbc_validate_connection =&gt; <span class="string">&quot;true&quot;</span></span><br><span class="line"> # 数据库连接可用校验超时时间，默认<span class="number">3600</span>S</span><br><span class="line">jdbc_validation_timeout =&gt; <span class="string">&quot;3600&quot;</span></span><br><span class="line"> # 开启分页查询（默认false不开启）；</span><br><span class="line">jdbc_paging_enabled =&gt; <span class="string">&quot;true&quot;</span></span><br><span class="line"> # 单次分页查询条数（默认<span class="number">100000</span>,若字段较多且更新频率较高，建议调低此值）；</span><br><span class="line">jdbc_page_size =&gt; <span class="string">&quot;5000&quot;</span></span><br><span class="line"> # statement为查询数据sql，如果sql较复杂，建议配通过statement_filepath配置sql文件的存放路径；</span><br><span class="line"> # sql_last_value为内置的变量，存放上次查询结果中最后一条数据tracking_column的值，此处即为ModifyTime；</span><br><span class="line"> # statement_filepath =&gt; <span class="string">&quot;mysql/jdbc.sql&quot;</span></span><br><span class="line">statement =&gt; <span class="string">&quot;SELECT a.ID,&#x27;01&#x27; AS TYPE,a.NAME,a.DOCUMENT_NO,a.INDUSTRY_NAME,a.REGION_NAME,b.CONTENT,a.PUBLISH_TIME FROM audit_law a LEFT JOIN tab_file_content b ON a.CONTENT_ID = b.ID WHERE a.STATE_CODE=&#x27;03&#x27; AND PUBLISH_TIME &gt; :sql_last_value ORDER BY PUBLISH_TIME ASC&quot;</span></span><br><span class="line"> # 是否将字段名转换为小写，默认true（如果有数据序列化、反序列化需求，建议改为false）；</span><br><span class="line">lowercase_column_names =&gt; false</span><br><span class="line"> # Value can be any of: fatal,error,warn,info,debug，默认info；</span><br><span class="line">sql_log_level =&gt; warn</span><br><span class="line"> # 是否记录上次执行结果，true表示会将上次执行结果的tracking_column字段的值保存到last_run_metadata_path指定的文件中；</span><br><span class="line">record_last_run =&gt; true</span><br><span class="line"> # 需要记录查询结果某字段的值时，此字段为true，否则默认tracking_column为timestamp的值；</span><br><span class="line">use_column_value =&gt; true</span><br><span class="line"> # 需要记录的字段，用于增量同步，需是数据库字段</span><br><span class="line">tracking_column =&gt; <span class="string">&quot;PUBLISH_TIME&quot;</span></span><br><span class="line"> # Value can be any of: numeric,timestamp，Default value is <span class="string">&quot;numeric&quot;</span></span><br><span class="line">tracking_column_type =&gt; timestamp</span><br><span class="line"> # record_last_run上次数据存放位置；</span><br><span class="line">last_run_metadata_path =&gt; <span class="string">&quot;mysql/audit_law_last_id.txt&quot;</span></span><br><span class="line"> # 是否清除last_run_metadata_path的记录，需要增量同步时此字段必须为false；</span><br><span class="line">clean_run =&gt; false</span><br><span class="line"> # 同步频率(<span class="string">分 时 天 月 年)，默认每分钟同步一次；</span></span><br><span class="line"><span class="string">schedule =&gt; &quot;* * * * *&quot;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">jdbc &#123;</span></span><br><span class="line"><span class="string">type =&gt; &quot;audit_basis&quot;</span></span><br><span class="line"><span class="string"> # 数据库连接地址</span></span><br><span class="line"><span class="string">jdbc_connection_string =&gt; &quot;jdbc:mysql://192.168.0.196:3306/auditbase?characterEncoding=UTF-8&amp;autoReconnect=true&amp;useSSL=false&quot;</span></span><br><span class="line"><span class="string"> # 数据库连接账号密码；</span></span><br><span class="line"><span class="string">jdbc_user =&gt; &quot;aaaa&quot;</span></span><br><span class="line"><span class="string">jdbc_password =&gt; &quot;123456&quot;</span></span><br><span class="line"><span class="string"> # MySQL依赖包路径；</span></span><br><span class="line"><span class="string">jdbc_driver_library =&gt; &quot;lib/jars/mysql-connector-java-5.1.41-bin.jar&quot;</span></span><br><span class="line"><span class="string"> # the name of the driver class for mysql</span></span><br><span class="line"><span class="string">jdbc_driver_class =&gt; &quot;com.mysql.jdbc.Driver&quot;</span></span><br><span class="line"><span class="string"># 解决中文乱码</span></span><br><span class="line"><span class="string">codec =&gt; plain &#123;charset =&gt; &quot;UTF-8&quot;&#125;</span></span><br><span class="line"><span class="string"> # 数据库重连尝试次数</span></span><br><span class="line"><span class="string">connection_retry_attempts =&gt; &quot;3&quot;</span></span><br><span class="line"><span class="string"> # 判断数据库连接是否可用，默认false不开启</span></span><br><span class="line"><span class="string">jdbc_validate_connection =&gt; &quot;true&quot;</span></span><br><span class="line"><span class="string"> # 数据库连接可用校验超时时间，默认3600S</span></span><br><span class="line"><span class="string">jdbc_validation_timeout =&gt; &quot;3600&quot;</span></span><br><span class="line"><span class="string"> # 开启分页查询（默认false不开启）；</span></span><br><span class="line"><span class="string">jdbc_paging_enabled =&gt; &quot;true&quot;</span></span><br><span class="line"><span class="string"> # 单次分页查询条数（默认100000,若字段较多且更新频率较高，建议调低此值）；</span></span><br><span class="line"><span class="string">jdbc_page_size =&gt; &quot;5000&quot;</span></span><br><span class="line"><span class="string"> # statement为查询数据sql，如果sql较复杂，建议配通过statement_filepath配置sql文件的存放路径；</span></span><br><span class="line"><span class="string"> # sql_last_value为内置的变量，存放上次查询结果中最后一条数据tracking_column的值，此处即为ModifyTime；</span></span><br><span class="line"><span class="string"> # statement_filepath =&gt; &quot;mysql/jdbc.sql&quot;</span></span><br><span class="line"><span class="string">statement =&gt; &quot;SELECT * FROM (SELECT a.ID,&#x27;02&#x27; as TYPE,a.QUESTION_NAME AS NAME,a.AUDIT_ITEM_NAME,b.AUDIT_LAW_NAME,GROUP_CONCAT(b.LAW_ITEM_TEXT SEPARATOR &#x27;\n&#x27;) AS LAW_TEXT,MAX(b.PUBLISH_TIME) AS PUBLISH_TIME FROM audit_basis a LEFT JOIN audit_basis_detail b ON a.ID = b.AUDIT_BASIS_ID WHERE b.STATE_CODE = &#x27;02&#x27; GROUP BY a.ID) c WHERE PUBLISH_TIME &gt; :sql_last_value ORDER BY PUBLISH_TIME ASC&quot;</span></span><br><span class="line"><span class="string"> # 是否将字段名转换为小写，默认true（如果有数据序列化、反序列化需求，建议改为false）；</span></span><br><span class="line"><span class="string">lowercase_column_names =&gt; false</span></span><br><span class="line"><span class="string"> # Value can be any of: fatal,error,warn,info,debug，默认info；</span></span><br><span class="line"><span class="string">sql_log_level =&gt; warn</span></span><br><span class="line"><span class="string"> # 是否记录上次执行结果，true表示会将上次执行结果的tracking_column字段的值保存到last_run_metadata_path指定的文件中；</span></span><br><span class="line"><span class="string">record_last_run =&gt; true</span></span><br><span class="line"><span class="string"> # 需要记录查询结果某字段的值时，此字段为true，否则默认tracking_column为timestamp的值；</span></span><br><span class="line"><span class="string">use_column_value =&gt; true</span></span><br><span class="line"><span class="string"> # 需要记录的字段，用于增量同步，需是数据库字段</span></span><br><span class="line"><span class="string">tracking_column =&gt; &quot;PUBLISH_TIME&quot;</span></span><br><span class="line"><span class="string"> # Value can be any of: numeric,timestamp，Default value is &quot;numeric&quot;</span></span><br><span class="line"><span class="string">tracking_column_type =&gt; timestamp</span></span><br><span class="line"><span class="string"> # record_last_run上次数据存放位置；</span></span><br><span class="line"><span class="string">last_run_metadata_path =&gt; &quot;mysql/audit_basis_last_id.txt&quot;</span></span><br><span class="line"><span class="string"> # 是否清除last_run_metadata_path的记录，需要增量同步时此字段必须为false；</span></span><br><span class="line"><span class="string">clean_run =&gt; false</span></span><br><span class="line"><span class="string"> # 同步频率(分 时 天 月 年)，默认每分钟同步一次；</span></span><br><span class="line"><span class="string">schedule =&gt; &quot;* * * * *&quot;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">filter &#123;</span></span><br><span class="line"><span class="string">json &#123;</span></span><br><span class="line"><span class="string">source =&gt; &quot;message&quot;</span></span><br><span class="line"><span class="string">remove_field =&gt; [&quot;message&quot;]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"># 去除自动添加的 &quot;@timestamp&quot;, &quot;@version&quot; 字段</span></span><br><span class="line"><span class="string"># 严禁过滤 &quot;type&quot; 字段，会导致无法成功同步数据</span></span><br><span class="line"><span class="string">mutate &#123;</span></span><br><span class="line"><span class="string">remove_field =&gt; [&quot;@timestamp&quot;, &quot;@version&quot;]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">output &#123;</span></span><br><span class="line"><span class="string"># type 值需与 jdbc 中的 type 值相对应</span></span><br><span class="line"><span class="string">if [type] == &quot;audit_law&quot; &#123;</span></span><br><span class="line"><span class="string">elasticsearch &#123;</span></span><br><span class="line"><span class="string"> # 配置ES集群地址</span></span><br><span class="line"><span class="string">hosts =&gt; [&quot;192.168.0.62:9200&quot;]</span></span><br><span class="line"><span class="string"> # 索引名字，必须小写</span></span><br><span class="line"><span class="string">index =&gt; &quot;audit_law&quot;</span></span><br><span class="line"><span class="string"> # 数据唯一索引（建议使用数据库KeyID）</span></span><br><span class="line"><span class="string">document_id =&gt; &quot;%&#123;ID&#125;&quot;</span></span><br><span class="line"><span class="string">template_overwrite =&gt; true</span></span><br><span class="line"><span class="string">template =&gt; &quot;mysql/audit_law_mapping.json&quot;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">if [type] == &quot;audit_basis&quot; &#123;</span></span><br><span class="line"><span class="string">elasticsearch &#123;</span></span><br><span class="line"><span class="string"> # 配置ES集群地址</span></span><br><span class="line"><span class="string">hosts =&gt; [&quot;192.168.0.62:9200&quot;]</span></span><br><span class="line"><span class="string"> # 索引名字，必须小写</span></span><br><span class="line"><span class="string">index =&gt; &quot;audit_basis&quot;</span></span><br><span class="line"><span class="string"> # 数据唯一索引（建议使用数据库KeyID）</span></span><br><span class="line"><span class="string">document_id =&gt; &quot;%&#123;ID&#125;&quot;</span></span><br><span class="line"><span class="string">template_overwrite =&gt; true</span></span><br><span class="line"><span class="string">template =&gt; &quot;mysql/audit_basis_mapping.json&quot;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">stdout &#123;</span></span><br><span class="line"><span class="string">codec =&gt; json_lines</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure><h4 id="自定义mapping文件示例"><a href="#自定义mapping文件示例" class="headerlink" title="自定义mapping文件示例"></a>自定义mapping文件示例</h4><figure class="highlight json"><table><tr><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;settings&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;number_of_shards&quot;</span> <span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;number_of_replicas&quot;</span> <span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;analysis.char_filter&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;html_strip&quot;</span><span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;mappings&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;properties&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;ID&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;keyword&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;TYPE&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;keyword&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;NAME&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;text&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;analyzer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ik_max_word&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;search_analyzer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ik_smart&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;DOCUMENT_NO&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;keyword&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;INDUSTRY_NAME&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;text&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;analyzer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ik_max_word&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;search_analyzer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ik_smart&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;REGION_NAME&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;text&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;analyzer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ik_max_word&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;search_analyzer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ik_smart&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;CONTENT&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;text&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;analyzer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ik_max_word&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;search_analyzer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ik_smart&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;PUBLISH_TIME&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;date&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 全文检索 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES </tag>
            
            <tag> 全文检索 </tag>
            
            <tag> Logstash </tag>
            
            <tag> ELK </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ES 7.0.0的简单使用操作</title>
      <link href="/2019/10/01/ES7/"/>
      <url>/2019/10/01/ES7/</url>
      
        <content type="html"><![CDATA[<p>本文是基于ES 7.0.0的简单使用操作。<br>大部分是一些RESTFUL API的使用，内容比较基础且杂乱，仅仅是一个记录。</p><ul><li><p>ES 7.0.0版本去除了类型<strong>type</strong>的概念，每个index下默认创建一个类型<strong>_doc</strong></p></li><li><p>创建索引示例：<br>创建一个名为<strong>laws</strong>的索引，指定默认分词器为<strong>ik_max_word</strong>，并过滤掉文档中的<strong>html</strong>标签，同时定义文档结构m<strong>apping</strong></p>  <figure class="highlight json"><table><tr><td class="code"><pre><span class="line">PUT /laws</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;settings&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;number_of_shards&quot;</span> <span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;number_of_replicas&quot;</span> <span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;analysis.analyzer.default.type&quot;</span><span class="punctuation">:</span><span class="string">&quot;ik_max_word&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;analysis.char_filter&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;html_strip&quot;</span><span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;mappings&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;properties&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;text&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;DocNo&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;text&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;unit&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;text&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;text&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li><li><p>为每个字段设置分词器<strong>analyzer</strong>以及搜索分词器<strong>search_analyzer</strong>    </p>  <figure class="highlight json"><table><tr><td class="code"><pre><span class="line">PUT /laws20190718</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;settings&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;number_of_shards&quot;</span> <span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;number_of_replicas&quot;</span> <span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;analysis.char_filter&quot;</span><span class="punctuation">:</span><span class="punctuation">[</span><span class="string">&quot;html_strip&quot;</span><span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;mappings&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;properties&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;keyword&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;title&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;text&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;analyzer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ik_max_word&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;search_analyzer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ik_smart&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;strs&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;text&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;analyzer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ik_max_word&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;search_analyzer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ik_smart&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;category&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;text&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;analyzer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ik_max_word&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;search_analyzer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ik_smart&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;date&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span><span class="string">&quot;date&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li><li><p>写入单条数据，文档内容含有英文双引号的，需要使用三引号”””包围在文档内容两侧</p>  <figure class="highlight json"><table><tr><td class="code"><pre><span class="line">PUT laws/_doc/<span class="number">1</span></span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;tid&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;1&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;content&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="string">&quot;&lt;p align=&quot;</span>center<span class="string">&quot;&gt;2019&lt;/p&gt;&quot;</span><span class="string">&quot;&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li><li><p>批量写入文档数据，文档内容含有英文双引号的，需要使用三引号”””包围在文档内容两侧</p>  <figure class="highlight json"><table><tr><td class="code"><pre><span class="line">PUT /laws/_bulk</span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;index&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;_id&quot;</span> <span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;tid&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;1&quot;</span><span class="punctuation">,</span><span class="attr">&quot;content&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="string">&quot;&lt;p align=&quot;</span>center<span class="string">&quot;&gt;2019&lt;/p&gt;&quot;</span><span class="string">&quot;&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;index&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;_id&quot;</span> <span class="punctuation">:</span> <span class="number">3</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;tid&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;1&quot;</span><span class="punctuation">,</span><span class="attr">&quot;content&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="string">&quot;&lt;p align=&quot;</span>center<span class="string">&quot;&gt;2020&lt;/p&gt;&quot;</span><span class="string">&quot;&quot;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;index&quot;</span><span class="punctuation">:</span><span class="punctuation">&#123;</span><span class="attr">&quot;_id&quot;</span> <span class="punctuation">:</span> <span class="number">4</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;tid&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;1&quot;</span><span class="punctuation">,</span><span class="attr">&quot;content&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="string">&quot;&lt;p align=&quot;</span>center<span class="string">&quot;&gt;2021&lt;/p&gt;&quot;</span><span class="string">&quot;&quot;</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li><li><p>简单搜索<strong>match</strong><br>参数：from  从指定的偏移量中提取搜索结果，默认为 0<br>参数：size  返回搜索结果条数，默认为 10</p>  <figure class="highlight json"><table><tr><td class="code"><pre><span class="line">GET /laws/_search?from=<span class="number">0</span>&amp;size=<span class="number">10</span></span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;query&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;match&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;content&quot;</span><span class="punctuation">:</span> <span class="string">&quot;采购&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li><li><p>ik分词模式</p><ul><li>ik_smart 最粗粒度的拆分</li><li>ik_max_word 将文本做最细粒度的拆分，会穷尽各种可能的词语组合</li></ul></li><li><p>结巴分词模式</p><ul><li>jieba_search 倾向于完整、顺序的切分，类似于ik_smart</li><li>jieba_index 倾向于分出更多可能的词，类似于ik_max_word</li></ul></li><li><p>测试分词引擎</p>  <figure class="highlight json"><table><tr><td class="code"><pre><span class="line">GET _analyze</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;text&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;我爱中华人民共和国&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;analyzer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ik_smart&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line">ik_smart返回结果</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;tokens&quot;</span> <span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;token&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;我&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;start_offset&quot;</span> <span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;end_offset&quot;</span> <span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;CN_CHAR&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;position&quot;</span> <span class="punctuation">:</span> <span class="number">0</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;token&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;爱&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;start_offset&quot;</span> <span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;end_offset&quot;</span> <span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;CN_CHAR&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;position&quot;</span> <span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;token&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;中华人民共和国&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;start_offset&quot;</span> <span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;end_offset&quot;</span> <span class="punctuation">:</span> <span class="number">9</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;CN_WORD&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;position&quot;</span> <span class="punctuation">:</span> <span class="number">2</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line">GET _analyze</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;text&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;我爱中华人民共和国&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;analyzer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ik_max_word&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line">   ik_max_word返回结果</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;tokens&quot;</span> <span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;token&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;我&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;start_offset&quot;</span> <span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;end_offset&quot;</span> <span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;CN_CHAR&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;position&quot;</span> <span class="punctuation">:</span> <span class="number">0</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;token&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;爱&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;start_offset&quot;</span> <span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;end_offset&quot;</span> <span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;CN_CHAR&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;position&quot;</span> <span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;token&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;中华人民共和国&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;start_offset&quot;</span> <span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;end_offset&quot;</span> <span class="punctuation">:</span> <span class="number">9</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;CN_WORD&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;position&quot;</span> <span class="punctuation">:</span> <span class="number">2</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;token&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;中华人民&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;start_offset&quot;</span> <span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;end_offset&quot;</span> <span class="punctuation">:</span> <span class="number">6</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;CN_WORD&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;position&quot;</span> <span class="punctuation">:</span> <span class="number">3</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;token&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;中华&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;start_offset&quot;</span> <span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;end_offset&quot;</span> <span class="punctuation">:</span> <span class="number">4</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;CN_WORD&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;position&quot;</span> <span class="punctuation">:</span> <span class="number">4</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;token&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;华人&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;start_offset&quot;</span> <span class="punctuation">:</span> <span class="number">3</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;end_offset&quot;</span> <span class="punctuation">:</span> <span class="number">5</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;CN_WORD&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;position&quot;</span> <span class="punctuation">:</span> <span class="number">5</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;token&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;人民共和国&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;start_offset&quot;</span> <span class="punctuation">:</span> <span class="number">4</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;end_offset&quot;</span> <span class="punctuation">:</span> <span class="number">9</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;CN_WORD&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;position&quot;</span> <span class="punctuation">:</span> <span class="number">6</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;token&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;人民&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;start_offset&quot;</span> <span class="punctuation">:</span> <span class="number">4</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;end_offset&quot;</span> <span class="punctuation">:</span> <span class="number">6</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;CN_WORD&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;position&quot;</span> <span class="punctuation">:</span> <span class="number">7</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;token&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;共和国&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;start_offset&quot;</span> <span class="punctuation">:</span> <span class="number">6</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;end_offset&quot;</span> <span class="punctuation">:</span> <span class="number">9</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;CN_WORD&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;position&quot;</span> <span class="punctuation">:</span> <span class="number">8</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;token&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;共和&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;start_offset&quot;</span> <span class="punctuation">:</span> <span class="number">6</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;end_offset&quot;</span> <span class="punctuation">:</span> <span class="number">8</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;CN_WORD&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;position&quot;</span> <span class="punctuation">:</span> <span class="number">9</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;token&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;国&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;start_offset&quot;</span> <span class="punctuation">:</span> <span class="number">8</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;end_offset&quot;</span> <span class="punctuation">:</span> <span class="number">9</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;CN_CHAR&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;position&quot;</span> <span class="punctuation">:</span> <span class="number">10</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line">GET _analyze</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;text&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;我爱中华人民共和国&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;analyzer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;jieba_index&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line">jieba_index返回结果</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;tokens&quot;</span> <span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;token&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;我爱&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;start_offset&quot;</span> <span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;end_offset&quot;</span> <span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;word&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;position&quot;</span> <span class="punctuation">:</span> <span class="number">0</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;token&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;中华&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;start_offset&quot;</span> <span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;end_offset&quot;</span> <span class="punctuation">:</span> <span class="number">4</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;word&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;position&quot;</span> <span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;token&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;中华人民共和国&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;start_offset&quot;</span> <span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;end_offset&quot;</span> <span class="punctuation">:</span> <span class="number">9</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;word&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;position&quot;</span> <span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;token&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;华人&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;start_offset&quot;</span> <span class="punctuation">:</span> <span class="number">3</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;end_offset&quot;</span> <span class="punctuation">:</span> <span class="number">5</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;word&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;position&quot;</span> <span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;token&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;人民&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;start_offset&quot;</span> <span class="punctuation">:</span> <span class="number">4</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;end_offset&quot;</span> <span class="punctuation">:</span> <span class="number">6</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;word&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;position&quot;</span> <span class="punctuation">:</span> <span class="number">2</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;token&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;共和&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;start_offset&quot;</span> <span class="punctuation">:</span> <span class="number">6</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;end_offset&quot;</span> <span class="punctuation">:</span> <span class="number">8</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;word&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;position&quot;</span> <span class="punctuation">:</span> <span class="number">3</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;token&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;共和国&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;start_offset&quot;</span> <span class="punctuation">:</span> <span class="number">6</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;end_offset&quot;</span> <span class="punctuation">:</span> <span class="number">9</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;word&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;position&quot;</span> <span class="punctuation">:</span> <span class="number">3</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line">GET _analyze</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;text&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;我爱中华人民共和国&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;analyzer&quot;</span><span class="punctuation">:</span> <span class="string">&quot;jieba_search&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line">jieba_search返回结果</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;tokens&quot;</span> <span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;token&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;我爱&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;start_offset&quot;</span> <span class="punctuation">:</span> <span class="number">0</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;end_offset&quot;</span> <span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;word&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;position&quot;</span> <span class="punctuation">:</span> <span class="number">0</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;token&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;中华人民共和国&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;start_offset&quot;</span> <span class="punctuation">:</span> <span class="number">2</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;end_offset&quot;</span> <span class="punctuation">:</span> <span class="number">9</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;word&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;position&quot;</span> <span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li><li><p>多字段检索<strong>multi_match</strong></p>  <figure class="highlight json"><table><tr><td class="code"><pre><span class="line">GET /lawss/_search</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;query&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;multi_match&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;query&quot;</span><span class="punctuation">:</span> <span class="string">&quot;spark&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;fields&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;title&quot;</span><span class="punctuation">,</span><span class="string">&quot;strs&quot;</span><span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li><li><p>结果关键词高亮</p>  <figure class="highlight json"><table><tr><td class="code"><pre><span class="line">GET /lawss/_search</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;query&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;multi_match&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;query&quot;</span><span class="punctuation">:</span> <span class="string">&quot;数据仓库&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;fields&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;title&quot;</span><span class="punctuation">,</span><span class="string">&quot;strs&quot;</span><span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;highlight&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;pre_tags&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;&lt;b&gt;&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;post_tags&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;&lt;/b&gt;&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;fields&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;title&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;strs&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li><li><p>简单SQL查询</p>  <figure class="highlight json"><table><tr><td class="code"><pre><span class="line">POST /_sql</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;query&quot;</span><span class="punctuation">:</span> <span class="string">&quot;SELECT title,category FROM lawss WHERE date &gt; &#x27;2018-01-01&#x27;&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line"># 加入format=txt参数可以将json结果转为表格形式</span><br><span class="line"># 支持的返回格式：csv、json（默认）、tsv、txt、yaml、cbor（二进制）、smile（二进制）</span><br><span class="line"># 设置“fetch_size”数值可控制返回记录数（可在SQL语句中添加LIMIT控制返回记录数）</span><br><span class="line"># 默认每次请求提取<span class="number">1000</span>条记录</span><br><span class="line">POST /_sql?format=txt</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;query&quot;</span><span class="punctuation">:</span> <span class="string">&quot;SELECT title,category FROM lawss WHERE date &gt; &#x27;2018-01-01&#x27;&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;fetch_size&quot;</span> <span class="punctuation">:</span> <span class="number">5</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li><li><p>索引别名，重建索引时可不影响现有业务正常运行。<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.0/indices-aliases.html">官方文档</a></p>  <figure class="highlight json"><table><tr><td class="code"><pre><span class="line"># 添加别名</span><br><span class="line">POST /_aliases</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;actions&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;add&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span> <span class="string">&quot;lawss&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;alias&quot;</span><span class="punctuation">:</span> <span class="string">&quot;laws&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"># 删除别名</span><br><span class="line">POST /_aliases</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;actions&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;remove&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span> <span class="string">&quot;lawss&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;alias&quot;</span><span class="punctuation">:</span> <span class="string">&quot;laws&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li><li><p>重建索引<strong>reindex</strong><br>需要预先创建好新索引的设置以及映射等。<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.0/docs-reindex.html">官方文档</a></p>  <figure class="highlight json"><table><tr><td class="code"><pre><span class="line"># 将索引<span class="string">&quot;lawss&quot;</span>重建至索引<span class="string">&quot;laws20190718&quot;</span></span><br><span class="line">POST _reindex</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;source&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span> <span class="string">&quot;lawss&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;dest&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;index&quot;</span><span class="punctuation">:</span> <span class="string">&quot;laws20190718&quot;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li><li><p>自定义检索返回字段<br>如下所示，只返回ID、NAME、TYPE这三个字段的数据</p>  <figure class="highlight json"><table><tr><td class="code"><pre><span class="line">GET /audit_law/_search</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;query&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;multi_match&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;query&quot;</span><span class="punctuation">:</span> <span class="string">&quot;项目&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;fields&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;_source&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;ID&quot;</span><span class="punctuation">,</span><span class="string">&quot;NAME&quot;</span><span class="punctuation">,</span><span class="string">&quot;TYPE&quot;</span><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li><li><p>多条件组合查询</p>  <figure class="highlight json"><table><tr><td class="code"><pre><span class="line">GET /audit_law/_search</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;query&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;bool&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;must&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span><span class="attr">&quot;multi_match&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;query&quot;</span><span class="punctuation">:</span> <span class="string">&quot;专项资金&quot;</span><span class="punctuation">,</span><span class="attr">&quot;fields&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">      <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;filter&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span><span class="attr">&quot;term&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;RELEASE_ORGAN&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;财政&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="punctuation">&#123;</span><span class="attr">&quot;term&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;REGION_NAME&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;全国&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="punctuation">&#123;</span><span class="attr">&quot;term&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;NAME&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;财政&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="punctuation">&#123;</span><span class="attr">&quot;term&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;DOCUMENT_NO&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;value&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2018年12月28日&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="punctuation">&#123;</span><span class="attr">&quot;term&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;INDUSTRY_NAME&quot;</span><span class="punctuation">:</span> <span class="string">&quot;教育&quot;</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="punctuation">&#123;</span><span class="attr">&quot;terms&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="attr">&quot;LAW_TYPE_CODE&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;10805&quot;</span><span class="punctuation">,</span><span class="string">&quot;10303&quot;</span><span class="punctuation">]</span><span class="punctuation">&#125;</span><span class="punctuation">&#125;</span></span><br><span class="line">      <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;sort&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;PUBLISH_TIME&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;order&quot;</span><span class="punctuation">:</span> <span class="string">&quot;desc&quot;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span><span class="punctuation">,</span> </span><br><span class="line">  <span class="attr">&quot;_source&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;ID&quot;</span><span class="punctuation">,</span><span class="string">&quot;NAME&quot;</span><span class="punctuation">,</span><span class="string">&quot;TYPE&quot;</span><span class="punctuation">,</span><span class="string">&quot;INDUSTRY_NAME&quot;</span><span class="punctuation">,</span><span class="string">&quot;RELEASE_ORGAN&quot;</span><span class="punctuation">,</span><span class="string">&quot;DOCUMENT_NO&quot;</span><span class="punctuation">,</span><span class="string">&quot;REGION_NAME&quot;</span><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> 全文检索 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ES </tag>
            
            <tag> 全文检索 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>你好，2019</title>
      <link href="/2019/01/06/Hello2019/"/>
      <url>/2019/01/06/Hello2019/</url>
      
        <content type="html"><![CDATA[<p>又一年过去了。</p><h4 id="博客概况"><a href="#博客概况" class="headerlink" title="博客概况"></a>博客概况</h4><p>距离建站刚好一年半，期间也没写多少东西，乱七八糟的只有33篇文章，可写的内容实在是太少。<br>我几乎每天都会去看一下当天的访问数据，好在博客的访问量还是在缓慢增长着的。<br>博客首页显示已有3200多的访问量，这个数字其实不太准确的，因为有一部分是我自己刷出来的，另外访问量统计插件的提供商更换了一次链接，而我好像没有很及时的发现，导致有一部分未统计到。<br>博客已从Github Pages迁移Google Cloud Platform，并已全站启用HTTPS，国内用户访问起来体验将会更加友好，希望今年我的博客可以帮助到更多的同好。    </p><h4 id="FLAG"><a href="#FLAG" class="headerlink" title="FLAG"></a>FLAG</h4><p>18年立的FLAG没有一个实现，很失败。<br>一本书看了一年还没有看完，没有旅行，也没有业余爱好，独自一人，做着自己不喜欢做的事，碌碌无为。    </p><p>但是新年FLAG该立还是要立，总得有个目标去努力吧，不然跟咸鱼有什么区别：    </p><ul><li>多给爸妈打电话。工作越来越忙，回家的机会也很少（其实是懒），要多往家里打打电话。</li><li>绝对不熬夜了。熬夜伤身，要养成早睡早起的良好作息习惯。</li><li>学会理财，珍惜血汗钱。我一向花钱大手大脚，必须要开始学习理财了。</li><li>一个月至少去一次电影院。忙碌之余也要放松放松自己，去电影院美美的享受一场视觉盛宴。</li><li>学习弹钢琴。这个想法很早很早就有了，今年必须要开始搞起来！</li><li>与对的人去对的地方旅行。世界这么大，趁着年轻，要多向外走走，看看外面的花花世界，体验一下不同的民俗风情。</li><li>月更至少一篇文章。我知道这个实现起来很难，但是就是要列上！</li><li>每月至少读一本书。去年没实现的今年继续搞！</li><li>听一场音乐会。如果生活没有了音乐，那怎么还能叫做生活？</li><li>健身！自从毕业以后，就再也没怎么健过身，身体不知道虚成什么样了。</li><li>增重10斤！一米八的身高却只有一百二十斤的体重，瘦的跟麻杆似的，必须要增重！增重！增重！</li></ul><h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><p>感谢所有质疑、批评过我的人。<br>感谢所有鼓励、支持、帮助过我的人。<br>感谢所有数据组小伙伴们，感谢你们的支持、陪伴与配合。    </p><p>向数据组所有小伙伴们道歉，很抱歉，没能带你们搞真正的大数据。<br>向所有我伤害过的人道歉，对不起。    </p><p>山小杰，2019年，希望你能混的更好一点。</p>]]></content>
      
      
      <categories>
          
          <category> 杂记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 杂记 </tag>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CentOS7下完全离线安装CDH6集群</title>
      <link href="/2018/12/01/CDH6Install/"/>
      <url>/2018/12/01/CDH6Install/</url>
      
        <content type="html"><![CDATA[<p>本文是在CentOS7.5下进行CDH6集群的完全离线部署。CDH5集群与CDH6集群的部署区别比较大，关于CDH5集群的部署请移步：<a href="https://blog.holoyoo.com/2018/02/08/CDH5Install/">CDH5高可用集群离线部署</a>。    </p><p>环境准备部分在上一篇文章：<a href="https://blog.holoyoo.com/2018/12/01/CDH6BeforeInstall/">安装CDH6集群之前的环境准备</a>。    </p><p>说明：本文内容所有操作都是在root用户下进行的。</p><h2 id="文件下载"><a href="#文件下载" class="headerlink" title="文件下载"></a>文件下载</h2><p>首先一些安装CDH6集群的必须文件要先在外网环境先下载好。</p><h3 id="Cloudera-Manager-6-0-1"><a href="#Cloudera-Manager-6-0-1" class="headerlink" title="Cloudera Manager 6.0.1"></a>Cloudera Manager 6.0.1</h3><p>CM6 RPM：<a href="https://archive.cloudera.com/cm6/6.0.1/redhat7/yum/RPMS/x86_64/">https://archive.cloudera.com/cm6/6.0.1/redhat7/yum/RPMS/x86_64/</a><br>需要下载该链接下的所有RPM文件，由于jdk1.8我在环境准备部分已经手动安装了，所以可以不用下载<code>RPMS/x86_64/</code>目录下的jdk包<code>oracle-j2sdk1.8-1.8.0+update141-1.x86_64.rpm</code>，但是其他4个rpm包一定要下载，保存到<code>cloudera-repos</code>目录下。    </p><p>ASC文件：<a href="https://archive.cloudera.com/cm6/6.0.1/allkeys.asc">https://archive.cloudera.com/cm6/6.0.1/allkeys.asc</a><br>同时还需要下载一个asc文件，同样保存到<code>cloudera-repos</code>目录下：    </p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/upload/cloudera-repos/</span><br><span class="line">├── allkeys.asc</span><br><span class="line">├── cloudera-manager-agent-6.0.1-610811.el7.x86_64.rpm</span><br><span class="line">├── cloudera-manager-daemons-6.0.1-610811.el7.x86_64.rpm</span><br><span class="line">├── cloudera-manager-server-6.0.1-610811.el7.x86_64.rpm</span><br><span class="line">└── cloudera-manager-server-db-2-6.0.1-610811.el7.x86_64.rpm</span><br><span class="line"></span><br><span class="line">0 directories, 4 files</span><br></pre></td></tr></table></figure><h3 id="MySQL-JDBC驱动"><a href="#MySQL-JDBC驱动" class="headerlink" title="MySQL JDBC驱动"></a>MySQL JDBC驱动</h3><p>要求使用5.1.26以上版本的jdbc驱动，可<a href="https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.47.tar.gz">点击这里</a>直接下载<code>mysql-connector-java-5.1.47.tar.gz</code>   </p><h3 id="CDH-6-0-1"><a href="#CDH-6-0-1" class="headerlink" title="CDH 6.0.1"></a>CDH 6.0.1</h3><p>CDH6 Parcels：<a href="https://archive.cloudera.com/cdh6/6.0.1/parcels/">https://archive.cloudera.com/cdh6/6.0.1/parcels/</a><br>需要下载<code>CDH-6.0.1-1.cdh6.0.1.p0.590678-el7.parcel</code>和<code>manifest.json</code>这两个文件</p><h2 id="配置Cloudera-Manager-yum库"><a href="#配置Cloudera-Manager-yum库" class="headerlink" title="配置Cloudera Manager yum库"></a>配置Cloudera Manager yum库</h2><p>注意：不要尝试使用FTP搭建CM的YUM库！    </p><p>首先安装<code>httpd</code>和<code>createrepo</code>：<br><code>yum -y install httpd createrepo</code><br>启动<code>httpd</code>服务并设置开机自启动：<br><code>systemctl start httpd</code><br><code>systemctl enable httpd</code><br>然后进入到前面准备好的存放Cloudera Manager RPM包的目录<code>cloudera-repos</code>下：<br><code>cd /upload/cloudera-repos/</code><br>生成RPM元数据：<br><code>createrepo .</code>    </p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@cdh601 cloudera-repos]# createrepo .</span><br><span class="line">Spawning worker 0 with 2 pkgs</span><br><span class="line">Spawning worker 1 with 2 pkgs</span><br><span class="line">Workers Finished</span><br><span class="line">Saving Primary metadata</span><br><span class="line">Saving file lists metadata</span><br><span class="line">Saving other metadata</span><br><span class="line">Generating sqlite DBs</span><br><span class="line">Sqlite DBs complete</span><br></pre></td></tr></table></figure><p>然后将<code>cloudera-repos</code>目录移动到httpd的html目录下：<br><code>mv cloudera-repos /var/www/html/</code><br>确保可以通过浏览器查看到这些RPM包：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181203/86sifJkpHNT5.png" alt="img"><br>接着在<strong>Cloudera Manager Server</strong>主机上创建cm6的repo文件（要把哪个节点作为Cloudera Manager Server节点，就在这个节点上创建repo文件）：<br><code>cd /etc/yum.repos.d</code><br><code>vim cloudera-manager.repo</code><br>添加如下内容：    </p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[cloudera-manager]</span><br><span class="line">name=Cloudera Manager 6.0.1</span><br><span class="line">baseurl=http://cdh601/cloudera-repos/</span><br><span class="line">gpgcheck=0</span><br><span class="line">enabled=1</span><br></pre></td></tr></table></figure><p>保存，退出,然后执行<code>yum clean all &amp;&amp; yum makecache</code>命令：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181203/zR1TeRS8nYWb.png" alt="img"></p><h2 id="安装Cloudera-Manager-Server"><a href="#安装Cloudera-Manager-Server" class="headerlink" title="安装Cloudera Manager Server"></a>安装Cloudera Manager Server</h2><p>这一步只需要在CM Server节点上操作。<br>执行下面的命令：<br><code>yum install cloudera-manager-daemons cloudera-manager-agent cloudera-manager-server</code><br>将会需要很多依赖包，所以说还是有必要搭一个局域网内yum源的：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/k5JHMj3QUGvi.png" alt="img">    </p><h2 id="配置本地Parcel存储库"><a href="#配置本地Parcel存储库" class="headerlink" title="配置本地Parcel存储库"></a>配置本地Parcel存储库</h2><p>Cloudera Manager Server安装完成后，进入到本地Parcel存储库目录：<br><code>cd /opt/cloudera/parcel-repo</code><br>将第一部分下载的CDH Parcel文件（<code>CDH-6.0.1-1.cdh6.0.1.p0.590678-el7.parcel</code>和<code>manifest.json</code>）上传至该目录下，然后执行命令生成sha文件：<br><code>sha1sum CDH-6.0.1-1.cdh6.0.1.p0.590678-el7.parcel | awk &#39;&#123; print $1 &#125;&#39; &gt; CDH-6.0.1-1.cdh6.0.1.p0.590678-el7.parcel.sha</code><br>然后执行下面的命令修改文件所有者：<br><code>chown -R cloudera-scm:cloudera-scm /opt/cloudera/parcel-repo/*</code><br>最终<code>/opt/cloudera/parcel-repo</code>目录内容如下：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/vEGbZpYWxa47.png" alt="img"></p><h2 id="安装数据库"><a href="#安装数据库" class="headerlink" title="安装数据库"></a>安装数据库</h2><p>MySQL的安装在环境准备部分中已经有说明，这里就跳过MySQL安装了。    </p><h3 id="数据库配置"><a href="#数据库配置" class="headerlink" title="数据库配置"></a>数据库配置</h3><p>CDH官方给的有一份推荐的MySQL的配置内容：    </p><figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="section">[mysqld]</span></span><br><span class="line"><span class="attr">datadir</span>=/var/lib/mysql</span><br><span class="line"><span class="attr">socket</span>=/var/lib/mysql/mysql.sock</span><br><span class="line"><span class="attr">transaction-isolation</span> = READ-COMMITTED</span><br><span class="line"><span class="comment"># Disabling symbolic-links is recommended to prevent assorted security risks;</span></span><br><span class="line"><span class="comment"># to do so, uncomment this line:</span></span><br><span class="line"><span class="attr">symbolic-links</span> = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="attr">key_buffer_size</span> = <span class="number">32</span>M</span><br><span class="line"><span class="attr">max_allowed_packet</span> = <span class="number">32</span>M</span><br><span class="line"><span class="attr">thread_stack</span> = <span class="number">256</span>K</span><br><span class="line"><span class="attr">thread_cache_size</span> = <span class="number">64</span></span><br><span class="line"><span class="attr">query_cache_limit</span> = <span class="number">8</span>M</span><br><span class="line"><span class="attr">query_cache_size</span> = <span class="number">64</span>M</span><br><span class="line"><span class="attr">query_cache_type</span> = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="attr">max_connections</span> = <span class="number">550</span></span><br><span class="line"><span class="comment">#expire_logs_days = 10</span></span><br><span class="line"><span class="comment">#max_binlog_size = 100M</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#log_bin should be on a disk with enough free space.</span></span><br><span class="line"><span class="comment">#Replace &#x27;/var/lib/mysql/mysql_binary_log&#x27; with an appropriate path for your</span></span><br><span class="line"><span class="comment">#system and chown the specified folder to the mysql user.</span></span><br><span class="line"><span class="attr">log_bin</span>=/var/lib/mysql/mysql_binary_log</span><br><span class="line"></span><br><span class="line"><span class="comment">#In later versions of MySQL, if you enable the binary log and do not set</span></span><br><span class="line"><span class="comment">#a server_id, MySQL will not start. The server_id must be unique within</span></span><br><span class="line"><span class="comment">#the replicating group.</span></span><br><span class="line"><span class="attr">server_id</span>=<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="attr">binlog_format</span> = mixed</span><br><span class="line"></span><br><span class="line"><span class="attr">read_buffer_size</span> = <span class="number">2</span>M</span><br><span class="line"><span class="attr">read_rnd_buffer_size</span> = <span class="number">16</span>M</span><br><span class="line"><span class="attr">sort_buffer_size</span> = <span class="number">8</span>M</span><br><span class="line"><span class="attr">join_buffer_size</span> = <span class="number">8</span>M</span><br><span class="line"></span><br><span class="line"><span class="comment"># InnoDB settings</span></span><br><span class="line"><span class="attr">innodb_file_per_table</span> = <span class="number">1</span></span><br><span class="line"><span class="attr">innodb_flush_log_at_trx_commit</span>  = <span class="number">2</span></span><br><span class="line"><span class="attr">innodb_log_buffer_size</span> = <span class="number">64</span>M</span><br><span class="line"><span class="attr">innodb_buffer_pool_size</span> = <span class="number">4</span>G</span><br><span class="line"><span class="attr">innodb_thread_concurrency</span> = <span class="number">8</span></span><br><span class="line"><span class="attr">innodb_flush_method</span> = O_DIRECT</span><br><span class="line"><span class="attr">innodb_log_file_size</span> = <span class="number">512</span>M</span><br><span class="line"></span><br><span class="line"><span class="section">[mysqld_safe]</span></span><br><span class="line"><span class="attr">log-error</span>=/var/log/mysqld.log</span><br><span class="line"><span class="attr">pid-file</span>=/var/run/mysqld/mysqld.pid</span><br><span class="line"></span><br><span class="line"><span class="attr">sql_mode</span>=STRICT_ALL_TABLES</span><br></pre></td></tr></table></figure><h3 id="配置mysql-jdbc驱动"><a href="#配置mysql-jdbc驱动" class="headerlink" title="配置mysql jdbc驱动"></a>配置mysql jdbc驱动</h3><p>从前面下载好的<code>mysql-connector-java-5.1.47.tar.gz</code>包中解压出<code>mysql-connector-java-5.1.47-bin.jar</code>文件，将<code>mysql-connector-java-5.1.47-bin.jar</code>文件上传至CM Server节点上的<code>/usr/share/java/</code>目录下并重命名为<code>mysql-connector-java.jar</code>（如果<code>/usr/share/java/</code>目录不存在，需要手动创建）：<br><code>tar zxvf mysql-connector-java-5.1.47.tar.gz</code><br><code>mkdir -p /usr/share/java/</code><br><code>cp mysql-connector-java-5.1.47-bin.jar /usr/share/java/mysql-connector-java.jar</code></p><h3 id="创建CDH所需要的数据库"><a href="#创建CDH所需要的数据库" class="headerlink" title="创建CDH所需要的数据库"></a>创建CDH所需要的数据库</h3><p>根据所需要安装的服务参照下表创建对应的数据库以及数据库用户，数据库必须使用utf8编码，创建数据库时要记录好用户名及对应密码： </p><table><thead><tr><th align="center">服务名</th><th align="center">数据库名</th><th align="center">用户名</th></tr></thead><tbody><tr><td align="center">Cloudera Manager Server</td><td align="center">scm</td><td align="center">scm</td></tr><tr><td align="center">Activity Monitor</td><td align="center">amon</td><td align="center">amon</td></tr><tr><td align="center">Reports Manager</td><td align="center">rman</td><td align="center">rman</td></tr><tr><td align="center">Hue</td><td align="center">hue</td><td align="center">hue</td></tr><tr><td align="center">Hive Metastore Server</td><td align="center">metastore</td><td align="center">hive</td></tr><tr><td align="center">Sentry Server</td><td align="center">sentry</td><td align="center">sentry</td></tr><tr><td align="center">Cloudera Navigator Audit Server</td><td align="center">nav</td><td align="center">nav</td></tr><tr><td align="center">Cloudera Navigator Metadata Server</td><td align="center">navms</td><td align="center">navms</td></tr><tr><td align="center">Oozie</td><td align="center">oozie</td><td align="center">oozie</td></tr></tbody></table><p>我这里就先创建4个数据库及对应用户：    </p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE</span> DATABASE scm <span class="keyword">DEFAULT</span> <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8 <span class="keyword">DEFAULT</span> <span class="keyword">COLLATE</span> utf8_general_ci;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.11</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE</span> DATABASE amon <span class="keyword">DEFAULT</span> <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8 <span class="keyword">DEFAULT</span> <span class="keyword">COLLATE</span> utf8_general_ci;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE</span> DATABASE rman <span class="keyword">DEFAULT</span> <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8 <span class="keyword">DEFAULT</span> <span class="keyword">COLLATE</span> utf8_general_ci;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">CREATE</span> DATABASE metastore <span class="keyword">DEFAULT</span> <span class="type">CHARACTER</span> <span class="keyword">SET</span> utf8 <span class="keyword">DEFAULT</span> <span class="keyword">COLLATE</span> utf8_general_ci;</span><br><span class="line">Query OK, <span class="number">1</span> <span class="type">row</span> affected (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">GRANT</span> <span class="keyword">ALL</span> <span class="keyword">ON</span> scm.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;scm&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;scm&#x27;</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected, <span class="number">1</span> warning (<span class="number">0.16</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">GRANT</span> <span class="keyword">ALL</span> <span class="keyword">ON</span> amon.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;amon&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;amon&#x27;</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected, <span class="number">1</span> warning (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">GRANT</span> <span class="keyword">ALL</span> <span class="keyword">ON</span> rman.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;rman&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;rman&#x27;</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected, <span class="number">1</span> warning (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">GRANT</span> <span class="keyword">ALL</span> <span class="keyword">ON</span> metastore.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;hive&#x27;</span>@<span class="string">&#x27;%&#x27;</span> IDENTIFIED <span class="keyword">BY</span> <span class="string">&#x27;hive&#x27;</span>;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected, <span class="number">1</span> warning (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> FLUSH PRIVILEGES;</span><br><span class="line">Query OK, <span class="number">0</span> <span class="keyword">rows</span> affected (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><p>查看授权是否正确：    </p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SHOW</span> GRANTS <span class="keyword">FOR</span> <span class="string">&#x27;scm&#x27;</span>@<span class="string">&#x27;%&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> Grants <span class="keyword">for</span> scm@<span class="operator">%</span>                             <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">GRANT</span> USAGE <span class="keyword">ON</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;scm&#x27;</span>@<span class="string">&#x27;%&#x27;</span>              <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">GRANT</span> <span class="keyword">ALL</span> PRIVILEGES <span class="keyword">ON</span> `scm`.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;scm&#x27;</span>@<span class="string">&#x27;%&#x27;</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SHOW</span> GRANTS <span class="keyword">FOR</span> <span class="string">&#x27;amon&#x27;</span>@<span class="string">&#x27;%&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> Grants <span class="keyword">for</span> amon@<span class="operator">%</span>                              <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">GRANT</span> USAGE <span class="keyword">ON</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;amon&#x27;</span>@<span class="string">&#x27;%&#x27;</span>               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">GRANT</span> <span class="keyword">ALL</span> PRIVILEGES <span class="keyword">ON</span> `amon`.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;amon&#x27;</span>@<span class="string">&#x27;%&#x27;</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------------------------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SHOW</span> GRANTS <span class="keyword">FOR</span> <span class="string">&#x27;rman&#x27;</span>@<span class="string">&#x27;%&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> Grants <span class="keyword">for</span> rman@<span class="operator">%</span>                              <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">GRANT</span> USAGE <span class="keyword">ON</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;rman&#x27;</span>@<span class="string">&#x27;%&#x27;</span>               <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">GRANT</span> <span class="keyword">ALL</span> PRIVILEGES <span class="keyword">ON</span> `rman`.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;rman&#x27;</span>@<span class="string">&#x27;%&#x27;</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">------------------------------------------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"></span><br><span class="line">mysql<span class="operator">&gt;</span> <span class="keyword">SHOW</span> GRANTS <span class="keyword">FOR</span> <span class="string">&#x27;hive&#x27;</span>@<span class="string">&#x27;%&#x27;</span>;</span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> Grants <span class="keyword">for</span> metastore@<span class="operator">%</span>                                   <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------------+</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">GRANT</span> USAGE <span class="keyword">ON</span> <span class="operator">*</span>.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;hive&#x27;</span>@<span class="string">&#x27;%&#x27;</span>                    <span class="operator">|</span></span><br><span class="line"><span class="operator">|</span> <span class="keyword">GRANT</span> <span class="keyword">ALL</span> PRIVILEGES <span class="keyword">ON</span> `metastore`.<span class="operator">*</span> <span class="keyword">TO</span> <span class="string">&#x27;hive&#x27;</span>@<span class="string">&#x27;%&#x27;</span> <span class="operator">|</span></span><br><span class="line"><span class="operator">+</span><span class="comment">----------------------------------------------------------+</span></span><br><span class="line"><span class="number">2</span> <span class="keyword">rows</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure><h2 id="设置Cloudera-Manager-数据库"><a href="#设置Cloudera-Manager-数据库" class="headerlink" title="设置Cloudera Manager 数据库"></a>设置Cloudera Manager 数据库</h2><p>Cloudera Manager Server包含一个配置数据库的脚本。</p><ul><li>mysql数据库与CM Server是同一台主机<br>执行命令：<code>/opt/cloudera/cm/schema/scm_prepare_database.sh mysql scm scm</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/EmwlJvBIFSac.png" alt="img"></li><li>mysql数据库与CM Server不在同一台主机上<br>执行命令：<code>/opt/cloudera/cm/schema/scm_prepare_database.sh mysql -h &lt;mysql-host-ip&gt; --scm-host &lt;cm-server-ip&gt; scm scm</code></li></ul><h2 id="安装CDH节点"><a href="#安装CDH节点" class="headerlink" title="安装CDH节点"></a>安装CDH节点</h2><h3 id="启动Cloudera-Manager-Server服务"><a href="#启动Cloudera-Manager-Server服务" class="headerlink" title="启动Cloudera Manager Server服务"></a>启动Cloudera Manager Server服务</h3><p><code>systemctl start cloudera-scm-server</code><br>然后等待Cloudera Manager Server启动，可能需要稍等一会儿，可以通过命令<code>tail -f /var/log/cloudera-scm-server/cloudera-scm-server.log</code>去监控服务启动状态。    </p><p>当看到<code>INFO WebServerImpl:com.cloudera.server.cmf.WebServerImpl: Started Jetty server.</code>日志打印出来后，说明服务启动成功，可以通过浏览器访问Cloudera Manager WEB界面了。</p><h3 id="访问Cloudera-Manager-WEB界面"><a href="#访问Cloudera-Manager-WEB界面" class="headerlink" title="访问Cloudera Manager WEB界面"></a>访问Cloudera Manager WEB界面</h3><p>打开浏览器，访问地址：<code>http://&lt;server_host&gt;:7180</code>，默认账号和密码都为<strong>admin</strong>：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/OKCHFxlvw7Wp.png" alt="img">    </p><h3 id="欢迎页面"><a href="#欢迎页面" class="headerlink" title="欢迎页面"></a>欢迎页面</h3><p>首先是Cloudera Manager的欢迎页面，点击页面右下角的【继续】按钮进行下一步：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/voTfsKVLDRNC.png" alt="img"></p><h3 id="接受条款"><a href="#接受条款" class="headerlink" title="接受条款"></a>接受条款</h3><p>勾选接受条款，点击【继续】进行下一步：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/6W0La4w5LY13.png" alt="img"></p><h3 id="版本选择"><a href="#版本选择" class="headerlink" title="版本选择"></a>版本选择</h3><p>这里我就选择免费版了：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/bYZx2FSZo7DM.png" alt="img"></p><h3 id="第二个欢迎界面"><a href="#第二个欢迎界面" class="headerlink" title="第二个欢迎界面"></a>第二个欢迎界面</h3><p>选择版本以后会出现第二个欢迎界面，不过这个是安装集群的欢迎页：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/hZ9k81ZTEwQa.png" alt="img"></p><h3 id="选择主机"><a href="#选择主机" class="headerlink" title="选择主机"></a>选择主机</h3><p>这一步是要搜索并选择用于安装CDH集群的主机，在主机名称后面的输入框中输入各个节点的hostname，中间使用英文逗号分隔开，然后点击搜索，在结果列表中勾选要安装CDH的节点即可：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/GPvK28GUzQqK.png" alt="img"></p><h3 id="指定存储库"><a href="#指定存储库" class="headerlink" title="指定存储库"></a>指定存储库</h3><h4 id="Cloudera-Manager-Agent"><a href="#Cloudera-Manager-Agent" class="headerlink" title="Cloudera Manager Agent"></a>Cloudera Manager Agent</h4><p>这里选择自定义，填写上面使用httpd搭建好的Cloudera Manager YUM 库URL：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181203/bxONuKvBzUqg.png" alt="img"></p><h4 id="CDH-and-other-software"><a href="#CDH-and-other-software" class="headerlink" title="CDH and other software"></a>CDH and other software</h4><p>如果我们之前的【配置本地Parcel存储库】步骤操作无误的话，这里会自动选择【使用Parcel】，并加载出CDH版本，确认无误后点击【继续】：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181202/vUMRwQ12HQ9f.png" alt="img"></p><h3 id="JDK安装选项"><a href="#JDK安装选项" class="headerlink" title="JDK安装选项"></a>JDK安装选项</h3><p>这一步骤我就不再勾选安装JDK了，因为我在环境准备部分已经安装过了。取消勾选，然后继续：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/u7pRN3Tgh9Ba.png" alt="img"></p><h3 id="SSH登录配置"><a href="#SSH登录配置" class="headerlink" title="SSH登录配置"></a>SSH登录配置</h3><p>用于配置集群主机之间的SSH登录，填写root用户的密码，根据集群配置填写合适的【同时安装数量】值即可：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/WCEx9xZKZ8S6.png" alt="img"></p><h3 id="安装Agent"><a href="#安装Agent" class="headerlink" title="安装Agent"></a>安装Agent</h3><p>到这一步会自动进行节点Agent的安装，稍等一会儿，即可安装完成：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181203/P2CrQYOzRD5n.png" alt="img"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181203/wOzDIDATTiby.png" alt="img"></p><h3 id="安装Parcels"><a href="#安装Parcels" class="headerlink" title="安装Parcels"></a>安装Parcels</h3><p>这一步同样是自动安装，分配步骤的速度主要取决于网络环境，耐心等待即可（我的3台虚拟机性能实在是太差了，这一步等了好久）：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181203/gK0C7FkGUFu9.png" alt="img"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181203/hr8YAhLnK0Vp.png" alt="img"></p><h3 id="主机检查"><a href="#主机检查" class="headerlink" title="主机检查"></a>主机检查</h3><p>等待检查完成即可：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181203/yHezTfwq7iS3.png" alt="img"></p><h2 id="安装CDH集群"><a href="#安装CDH集群" class="headerlink" title="安装CDH集群"></a>安装CDH集群</h2><h3 id="选择服务类型"><a href="#选择服务类型" class="headerlink" title="选择服务类型"></a>选择服务类型</h3><p>这里我选择自定义服务，HDFS，Hive，Yarn：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181203/Ex5GAhAXmpfB.png" alt="img"></p><h3 id="角色分配"><a href="#角色分配" class="headerlink" title="角色分配"></a>角色分配</h3><p>CDH会自动给出一个角色分配，如果觉得不合理，我们可以手动调整一下，注意角色分配均衡：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181203/tbEKMMOnrorV.png" alt="img">    </p><h3 id="数据库设置"><a href="#数据库设置" class="headerlink" title="数据库设置"></a>数据库设置</h3><p>因为我选择的服务中只有Hive需要数据库，故这里只需要配置Hive的metastore数据库。注意要将mysql的jdbc驱动放到hive metastore主机的<code>/usr/share/java/</code>目录下：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181203/yKbDuM7pejiO.png" alt="img">    </p><p>到这里CDH集群的安装基本上就已经完成了，我的虚拟机实在是承受不住了，后续内容等我换个环境再补充~。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> CDH </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>安装CDH6集群之前的环境准备</title>
      <link href="/2018/12/01/CDH6BeforeInstall/"/>
      <url>/2018/12/01/CDH6BeforeInstall/</url>
      
        <content type="html"><![CDATA[<p>这篇文章是安装CDH6集群之前的环境准备部分。<br>基于CentOS 7.x，其他类型Linux请参考CDH官方文档进行配置。</p><h1 id="环境要求"><a href="#环境要求" class="headerlink" title="环境要求"></a>环境要求</h1><h2 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h2><h3 id="软件依赖"><a href="#软件依赖" class="headerlink" title="软件依赖"></a>软件依赖</h3><ul><li>Python 2.7+，不支持Python 3（安装HUE需要）</li><li>perl</li><li>python-psycopg2 2.5.4+（安装HUE需要）</li><li>iproute package<ul><li>RHEL7：iproute-3.10</li><li>RHEL6：iproute-2.6</li></ul></li></ul><p>说明：通常这部分依赖环境操作系统已经自带，不需要手动安装。</p><h3 id="系统版本"><a href="#系统版本" class="headerlink" title="系统版本"></a>系统版本</h3><ul><li>RHEL系列：6.10，6.9，6.8，7.2，7.3，7.4，7.5</li><li>SELS：12 SP3,12 SP2</li><li>Ubuntu系列：16.04 LTS</li></ul><h3 id="文件系统"><a href="#文件系统" class="headerlink" title="文件系统"></a>文件系统</h3><ul><li>ext3</li><li>ext4</li><li>XFS</li><li>S3</li></ul><p>Kudu仅支持ext4和XFS文件系统。    </p><p>不支持NFS和NAS存储。</p><h3 id="文件访问记录"><a href="#文件访问记录" class="headerlink" title="文件访问记录"></a>文件访问记录</h3><p>Cloudera建议禁用该项功能，可以提升磁盘性能。<br>配置<code>/etc/fstab</code>文件：<br><code>/dev/sdb1    /data1    ext4    defaults,noatime    0    0</code><br>不重启即生效命令：<br><code>mount -o remount /data1</code></p><h3 id="nproc配置"><a href="#nproc配置" class="headerlink" title="nproc配置"></a>nproc配置</h3><p>配置文件位置<code>/etc/security/limits.conf</code>，Cloudera Manager通常会自动配置该文件，但是该项配置可能会被<code>/etc/security/limits.d/</code>目录下的文件覆盖掉。确保nproc限制设置的足够高，比如65536或者262144。</p><h2 id="数据库要求"><a href="#数据库要求" class="headerlink" title="数据库要求"></a>数据库要求</h2><p>Cloudera Manager和CDH内置嵌入式PostgreSQL数据库，用于非生产环境。生产环境不支持PostgreSQL数据库，必须为集群配置专用外部数据库。</p><p>注意：</p><ul><li>数据库需要使用<strong>UTF8</strong>编码。对于<strong>MySQL</strong>和<strong>MariaDB</strong>，必须使用<strong>UTF8</strong>编码，而不是<strong>utf8mb4</strong>；</li><li>对于MySQL5.7，必须要额外安装<strong>MySQL-shared-compat</strong>或者<strong>MySQL-shared</strong>包</li></ul><p>版本要求：</p><ul><li>MySQL：5.7</li><li>MariaDB：5.5，10.0</li><li>PostgreSQL：8.4，9.2，9.4</li><li>Oracle：12C</li></ul><h2 id="Java要求"><a href="#Java要求" class="headerlink" title="Java要求"></a>Java要求</h2><p>仅支持Oracle 64位JDK8，不支持JDK7，JDK9。</p><p>版本要求：最低要求1.8u31，推荐1.8u74，1.8u91，1.8u102，1.8u111，1.8u121，1.8u131，1.8u162</p><h2 id="网络以及安全要求"><a href="#网络以及安全要求" class="headerlink" title="网络以及安全要求"></a>网络以及安全要求</h2><ul><li>CDH不支持IPv6，操作系统必须要禁用IPv6</li><li>集群主机必须正确配置<code>/etc/hosts</code>文件<ul><li>应该包含集群中所有主机的主机名和对应IP地址</li><li>不能含有大写主机名</li><li>不能有重复的IP地址</li></ul></li><li>SELinux不得阻止Cloudera Manager或者CDH的操作</li><li>防火墙必须被禁用或者放开CDH集群所使用的端口</li><li>对于RHEL或者CENTOS，<code>/etc/sysconfig/network</code>文件中必须包含正确的主机名</li></ul><h2 id="浏览器要求"><a href="#浏览器要求" class="headerlink" title="浏览器要求"></a>浏览器要求</h2><ul><li>Chrome：63+</li><li>Firefox：59+</li><li>Safari</li><li>IE：11+</li><li>Edge：41+</li></ul><h2 id="所使用的端口"><a href="#所使用的端口" class="headerlink" title="所使用的端口"></a>所使用的端口</h2><p>这个直接看官方文档吧：<a href="https://www.cloudera.com/documentation/enterprise/6/6.0/topics/cm_ig_ports.html">CDH集群端口占用列表</a></p><h2 id="组件版本"><a href="#组件版本" class="headerlink" title="组件版本"></a>组件版本</h2><table><thead><tr><th align="center">组件名称</th><th align="center">组件版本</th></tr></thead><tbody><tr><td align="center">Apache Avro</td><td align="center">1.8.2</td></tr><tr><td align="center">Apache Flume</td><td align="center">1.8.0</td></tr><tr><td align="center">Apache Hadoop</td><td align="center">3.0.0</td></tr><tr><td align="center">Apache HBase</td><td align="center">2.0.0</td></tr><tr><td align="center">HBase Indexer</td><td align="center">1.5</td></tr><tr><td align="center">Apache Hive</td><td align="center">2.1.1</td></tr><tr><td align="center">Hue</td><td align="center">4.2.0</td></tr><tr><td align="center">Apache Impala</td><td align="center">3.0.0</td></tr><tr><td align="center">Apache Kafka</td><td align="center">1.0.1</td></tr><tr><td align="center">Kite SDK</td><td align="center">1.0.0</td></tr><tr><td align="center">Apache Kudu</td><td align="center">1.6.0</td></tr><tr><td align="center">Apache Solr</td><td align="center">7.0.0</td></tr><tr><td align="center">Apache Oozie</td><td align="center">5.0.0</td></tr><tr><td align="center">Apache Parquet</td><td align="center">1.9.0</td></tr><tr><td align="center">Parquet-format</td><td align="center">2.3.1</td></tr><tr><td align="center">Apache Pig</td><td align="center">0.17.0</td></tr><tr><td align="center">Apache Sentry</td><td align="center">2.0.0</td></tr><tr><td align="center">Apache Spark</td><td align="center">2.2.0</td></tr><tr><td align="center">Apache Sqoop</td><td align="center">1.4.7</td></tr><tr><td align="center">Apache ZooKeeper</td><td align="center">3.4.5</td></tr></tbody></table><h1 id="安装之前"><a href="#安装之前" class="headerlink" title="安装之前"></a>安装之前</h1><h2 id="网络相关配置"><a href="#网络相关配置" class="headerlink" title="网络相关配置"></a>网络相关配置</h2><ul><li>设置唯一主机名：<code>hostnamectl set-hostname new-hostname</code></li><li>配置<code>/etc/hosts</code></li><li>检测主机名与IP是否正确对应</li></ul><h2 id="禁用防火墙"><a href="#禁用防火墙" class="headerlink" title="禁用防火墙"></a>禁用防火墙</h2><ul><li>停止防火墙：<code>systemctl stop firewalld</code></li><li>关闭防火墙开机自启动：<code>systemctl disable firewalld</code></li></ul><h2 id="设置SELinux执行模式"><a href="#设置SELinux执行模式" class="headerlink" title="设置SELinux执行模式"></a>设置SELinux执行模式</h2><ol><li>检查SELinux模式：<code>getenforce</code>，如果输出<strong>permissive</strong>或者<strong>disabled</strong>，你可以跳过该步骤，如果输出<strong>enforcing</strong>，则需要继续下面的操作步骤。</li><li>编辑<code>/etc/selinux/config</code>（在某些操作系统可能是<code>/etc/sysconfig/selinux</code>）文件，将<code>SELINUX=enforcing</code>修改为<code>SELINUX=permissive</code>，保存该文件。</li><li>重启操作系统生效或者执行：<code>setenforce 0</code>临时禁用SELinux。</li><li>当CDH安装部署完成之后，可以重新启用SELinux，修改SELinux配置文件，然后执行：<code>setenforce 1</code>命令。</li></ol><h2 id="配置局域网内yum源"><a href="#配置局域网内yum源" class="headerlink" title="配置局域网内yum源"></a>配置局域网内yum源</h2><p>安装Cloudera Manager需要很多依赖包，强烈建议搭建一个局域网内yum源，在集群中某一个节点上部署即可。<br>可参考我之前的文章：<a href="https://blog.holoyoo.com/2018/01/24/YumRepoCreate/">CentOS7下使用FTP搭建局域网内Yum源</a>    </p><h2 id="配置NTP服务"><a href="#配置NTP服务" class="headerlink" title="配置NTP服务"></a>配置NTP服务</h2><p>集群中所有节点的时间必须要保持同步，可以选择集群中其中一个节点作为ntp服务端，其余节点作为客户端。    </p><ul><li>安装ntp软件：<code>yum -y install ntp</code></li><li>配置ntp服务端<code>/etc/ntp.conf</code></li><li>配置ntp客户端<code>/etc/ntp.conf</code></li><li>启动ntp服务：<code>systemctl start ntpd</code></li><li>配置开机自启动：<code>systemctl enable ntpd</code></li><li>同步客户端时间与服务端时间相同：<code>ntpdate -u &lt;ntp-server&gt;</code></li></ul><p>具体配置说明可参考我之前的文章：<a href="https://blog.holoyoo.com/2017/11/05/SetEnv/#配置ntp时间同步">环境准备-配置ntp时间同步</a></p><h2 id="安装jdk8"><a href="#安装jdk8" class="headerlink" title="安装jdk8"></a>安装jdk8</h2><p>集群所有节点都要安装。<br>可参考我之前的文章：<a href="https://blog.holoyoo.com/2017/11/05/SetEnv/#JDK1-8安装">环境准备-JDK1.8安装</a></p><h2 id="安装mysql5-7"><a href="#安装mysql5-7" class="headerlink" title="安装mysql5.7"></a>安装mysql5.7</h2><p>只需要在集群中某一个节点上安装即可。<br>可参考我之前的文章：<a href="https://blog.holoyoo.com/2018/12/01/InstallMysql7OnCentos7/">CentOS7下使用RPM安装MySQL5.7</a></p><h2 id="集群性能优化相关配置"><a href="#集群性能优化相关配置" class="headerlink" title="集群性能优化相关配置"></a>集群性能优化相关配置</h2><p>集群所有节点都需要进行这些配置。<br>可参考我之前的文章：<a href="https://blog.holoyoo.com/2018/11/30/CDH6Performance/">CDH6集群性能调优（操作系统层面）</a></p><h1 id="环境准备部分完毕"><a href="#环境准备部分完毕" class="headerlink" title="环境准备部分完毕"></a>环境准备部分完毕</h1>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> CDH </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CentOS7下使用RPM安装MySQL5.7</title>
      <link href="/2018/12/01/InstallMysql7OnCentos7/"/>
      <url>/2018/12/01/InstallMysql7OnCentos7/</url>
      
        <content type="html"><![CDATA[<p>MySQL5.7的RPM安装方式与MySQL5.6的安装方式略有不同。由于安装CDH6需要MySQL5.7，故这篇文章就来介绍一下CentOS7下安装MySQL5.7的操作流程。</p><ul><li><p>文件准备：<a href="https://dev.mysql.com/downloads/mysql/5.7.html#downloads">mysql-5.7.24-1.el7.x86_64.rpm-bundle.tar</a><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/dZeUiydsuGE6.png" alt="img"></p></li><li><p>首先卸载操作系统可能会自带的mariadb-libs<br><code>yum -y remove mariadb-libs</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/qb9NPmvrmcnJ.png" alt="img"></p></li><li><p>解压mysql rpm-bundle tar包<br><code>tar -xvf mysql-5.7.24-1.el7.x86_64.rpm-bundle.tar</code></p></li><li><p>开始安装mysql<br>一定要按照下面的顺序来安装，否则会安装不成功：<br><code>rpm -ivh mysql-community-common-5.7.24-1.el7.x86_64.rpm</code><br><code>rpm -ivh mysql-community-libs-5.7.24-1.el7.x86_64.rpm</code><br><code>rpm -ivh mysql-community-client-5.7.24-1.el7.x86_64.rpm</code><br><code>rpm -ivh mysql-community-server-5.7.24-1.el7.x86_64.rpm</code><br><code>rpm -ivh mysql-community-libs-compat-5.7.24-1.el7.x86_64.rpm</code>（安装Cloudera Manager6需要）<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/FYFU39cQLbSZ.png" alt="img"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/02BIjwBd6qZa.png" alt="img"></p></li><li><p>启动mysql服务<br><code>systemctl start mysqld</code><br>如果无法启动，则需要修改mysql数据目录所有者：<code>chown -R mysql:mysql /var/lib/mysql/</code></p></li><li><p>查看root用户初始密码<br><code>grep password /var/log/mysqld.log</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/LrVOvP7ONoaQ.png" alt="img"></p></li><li><p>登录mysql修改root密码<br><code>mysql -uroot -p</code><br><code>mysql&gt; set password = password(&#39;123456&#39;);</code><br>如果密码复杂度不够，则会禁止修改，默认密码规则为：包含数字、大小写字母、特殊字符，同时还有长度要求：    </p>  <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; set password = password(&#x27;123456&#x27;);</span><br><span class="line">ERROR 1819 (HY000): Your password does not satisfy the current policy requirements</span><br></pre></td></tr></table></figure><p>  可以通过修改全局参数来解决，但是还是要求密码长度至少为8位：<br><code>mysql&gt; set global validate_password_policy=0;</code><br><code>mysql&gt; set password = password(&#39;12345678&#39;);</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/inPy7TQSSL1P.png" alt="img"></p></li><li><p>设置远程登录权限<br><code>mysql&gt; grant all privileges on *.* to &#39;root&#39;@&#39;%&#39; identified by &#39;12345678&#39;;</code><br><code>mysql&gt; flush privileges;</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/MK1AoczaO6Dx.png" alt="img"></p></li><li><p>修改mysql数据库默认编码<br>查看原数据库编码：<code>mysql&gt; SHOW VARIABLES LIKE &#39;char%&#39;;</code>可以看到数据库和服务端的编码都还不是utf8：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/jexnClh1vJOg.png" alt="img"><br>编辑<code>/etc/my.cnf</code>文件，在<code>[mysqld]</code>下面添加一行<code>character-set-server=utf8</code>：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/FpitZfNGvVc7.png" alt="img"><br>重启mysql服务：<code>systemctl restart mysqld</code>，再次登录数据库查看编码，修改成功：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/y252yb8RlCLP.png" alt="img"></p></li><li><p>MySQL5.7安装配置完毕！</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CentOS </tag>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CDH6集群性能调优（操作系统层面）</title>
      <link href="/2018/11/30/CDH6Performance/"/>
      <url>/2018/11/30/CDH6Performance/</url>
      
        <content type="html"><![CDATA[<p>本文内容是参照CDH官方文档来写的，主要是对CDH6集群主机操作系统层面上的一些性能参数调优，不包含CDH组件的参数调优（比如MR、YARN等）。    </p><p>本文所有配置内容基于RHEL 7.x（CentOS 7.5），其他版本或者其他类型Linux的配置方式可能有所不同。    </p><p>本文所有操作都是在<strong>root</strong>用户下进行的。    </p><p>建议这部分操作在安装CDH6集群之前进行。</p><h2 id="禁用-RHEL7系列Linux的TUNED服务"><a href="#禁用-RHEL7系列Linux的TUNED服务" class="headerlink" title="禁用 RHEL7系列Linux的TUNED服务"></a>禁用 RHEL7系列Linux的TUNED服务</h2><ol><li>确保tuned服务已开启<br><code>systemctl start tuned</code><br><code>systemctl status tuned</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/glIS6IcEIDVb.png" alt="img"></li><li>关闭tuned服务<br><code>tuned-adm off</code></li><li>确保没有已激活的配置<br><code>tuned-adm list</code><br>如果输出内容中包含<code>No current active profile</code>表示关闭成功:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/JSDyuwjnqoKm.png" alt="img"></li><li>关闭并且禁用tuned服务<br><code>systemctl stop tuned</code><br><code>systemctl disable tuned</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/h6JjSHEfVddp.png" alt="img"></li></ol><h2 id="禁用THP"><a href="#禁用THP" class="headerlink" title="禁用THP"></a>禁用THP</h2><p>大多数Linux平台都包含一个名为<strong>transparent hugepages</strong>的功能，该功能可能会严重降低Hadoop集群的性能。    </p><p>注意：该部分操作将在系统重启后生效。</p><ol><li>检查THP是否启用<br>对于RHEL7系列Linux，查看方法如下所示：<br><code>cat /sys/kernel/mm/transparent_hugepage/enabled</code><br><code>cat /sys/kernel/mm/transparent_hugepage/defrag</code><br>输出<code>[always] never</code>意味着THP已启用，<code>always [never]</code>意味着THP未启用，下图就表示THP已启用：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/SHHCIWBLAUEg.png" alt="img"></li><li>禁用THP<br>编辑<code>/etc/rc.d/rc.local</code>文件，最下面添加两行配置： <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line">echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag</span><br></pre></td></tr></table></figure> <img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/f4uG0qMlswpK.png" alt="img"><br>然后赋予<code>/etc/rc.d/rc.local</code>文件可执行权限：<br><code>chmod +x /etc/rc.d/rc.local</code></li><li>修改GRUB配置<br>仅RHEL 7.x需要进行该项操作。<br>编辑<code>/etc/default/grub</code>文件，在<strong>GRUB_CMDLINE_LINUX</strong>项目后面添加一个参数：<code>transparent_hugepage=never</code>：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/HTawN2QTGJmW.png" alt="img"><br>然后执行命令：<code>grub2-mkconfig -o /boot/grub2/grub.cfg</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/uYEbM5lnfJSk.png" alt="img"></li></ol><h2 id="调整Linux内核参数"><a href="#调整Linux内核参数" class="headerlink" title="调整Linux内核参数"></a>调整Linux内核参数</h2><p>需要调整的参数为<code>vm.swappiness</code>，是一个0-100的值，用于控制应用数据从物理内存到磁盘上的虚拟内存的交换，值越高，交换越积极，值越小，交换的次数越少。    </p><p>在大多数Linux系统上，该参数默认值为60，这并不适用于Hadoop集群，因为即使有足够的内存，也可能会进行进程的交换，从而可能会影响Hadoop的性能和稳定性。    </p><p>CDH建议将该参数设置到<strong>1-10</strong>之间，最好设为<strong>1</strong>。    </p><ol><li>查看当前该项参数值：<br><code>cat /proc/sys/vm/swappiness</code></li><li>修改该项参数值（临时生效）：<br><code>sysctl -w vm.swappiness=1</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181201/DoMtnyZK3f6F.png" alt="img"></li><li>编辑<code>/etc/sysctl.conf</code>文件（重启后永久生效），添加一行<code>vm.swappiness=1</code>：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDH6/20181203/Z0DJuamFetP0.png" alt="img"></li></ol><h2 id="配置完毕！"><a href="#配置完毕！" class="headerlink" title="配置完毕！"></a>配置完毕！</h2>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> CDH </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kettle连接Hadoop集群</title>
      <link href="/2018/08/07/KettleConnectHadoop/"/>
      <url>/2018/08/07/KettleConnectHadoop/</url>
      
        <content type="html"><![CDATA[<p>其实在<strong>Kettle系列教程</strong>中第十章【<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-10/">对接大数据平台</a>】一文中已经介绍过了连接Hadoop集群需要的基本文件配置，但是呢，那种方式不能从表输入中直接输出数据到HDFS上，本章呢就介绍一下不经过【Hadoop Copy Files】如何直接输出数据到HDFS上。<br>可能你已经注意到，不管是转换还是作业，在Spoon界面左侧【主对象树】下面都有一个【Hadoop clusters】分组：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleConnectHadoop/20180807/4yvsRWj4RHs6.png" alt="img"><br>本章的主要内容就是如何在这里创建一个Hadoop集群连接！</p><h2 id="基础文件准备"><a href="#基础文件准备" class="headerlink" title="基础文件准备"></a>基础文件准备</h2><p>这一部分与<strong>Kettle系列教程</strong>中第十章【<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-10/#基础文件配置">对接大数据平台-基础文件配置</a>】中操作一样，这里不再赘述。    </p><h2 id="创建集群连接"><a href="#创建集群连接" class="headerlink" title="创建集群连接"></a>创建集群连接</h2><p>在【Hadoop clusters】分组图标右键菜单中点击【New Cluster】弹出集群配置窗口：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleConnectHadoop/20180807/C0qK9irTzXDI.png" alt="img"><br>首先给集群起个名字【Cluster name】；    </p><p>然后【Storage】选择<strong>HDFS</strong>；    </p><p>再然后配置【HDFS】连接信息：如果你的集群未开启<strong>NameNode HA</strong>，那么【Hostname】和【Port】如实填写即可，注意【Port】可不是50070这个web端口哈。如果开启了<strong>NameNode HA</strong>，那么【Hostname】这里就填写HDFS的Namespace（命名空间），命名空间即为<code>core-site.xml</code>中<code>fs.defaultFS</code>去掉<code>hdfs://</code>后的的属性值，【Port】一定要留空。集群未配置访问认证的话，【Username】和【Password】不用填写；    </p><p>接着配置【JobTracker】，其实应该改名叫【Yarn】了：与HDFS类似，如果ResourceManager未配置HA，则【Hostname】和【Port】如实填写。如果配置了HA，则【Hostname】这里需要将所有ResourceManager的主机地址都填写上，中间使用英文逗号分隔，【Port】一定要留空！    </p><p>再接着配置【Zookeeper】：【Hostname】这里需要将集群中所有的Zookeeper主机地址填写上，中间使用英文逗号分隔，【Port】如实填写；    </p><p>我的集群没有安装Oozie，故留空；    </p><p>最后配置【Kafka】：需要填写<code>bootstrap-server</code>所在主机地址以及运行端口，多个之间使用英文逗号分隔。未安装Kafka的话留空即可。    </p><p>配置完成以后，点击【测试】按钮可以测试一下集群连接，如果配置无误的话，可以看到全是绿色的对勾：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleConnectHadoop/20180807/RufmFTrJ3ltR.png" alt="img">    </p><h2 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q&amp;A"></a>Q&amp;A</h2><p>这一小节就对集群连接测试时容易出现的报错或者警告进行一下解答：    </p><ul><li>【Active Shim Load】出现报错或者警告，需要检查是否在<code>Spoon工具栏 -&gt; 工具 -&gt; Hadoop Distribution</code>中设置了对应的Hadoop平台；</li><li>【Shim Configuration Verification】报出警告：<code>The Hadoop File System URL does not match the URL in the shims core-site.xml</code>，这个时候就需要检查【HDFS】的【Hostname】是否与<code>core-site.xml</code>中<code>fs.defaultFS</code>属性值一致；</li><li>【User Home Directory Access】报错：<code>Could not read directory contents</code>，是因为Kettle是使用当前操作系统用户去访问HDFS的，如果HDFS上<code>/user/</code>目录下没有该用户的目录，则该项检测就会失败。解决办法：手动在HDFS上<code>/user/</code>目录下创建以当前操作系统用户名命名的文件夹即可。</li><li>【Root Directory Access】报错，是因为Kettle访问HDFS的用户没有读写HDFS跟目录的权限，可通过修改集群配置文件解决：在<code>hdfs-site.xml</code>文件中增加一个属性配置，重启集群生效：    <pre><code class="xml"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span><span class="tag">&lt;/<span class="name">property</span>&gt;</span></code></pre></li></ul><h2 id="Hadoop-File-Output"><a href="#Hadoop-File-Output" class="headerlink" title="Hadoop File Output"></a>Hadoop File Output</h2><p>创建完成集群连接以后，就可以直接输出数据到HDFS上了，本小节使用的是转换中【Big Data】分组下的【Hadoop File Output】组件：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleConnectHadoop/20180807/4dKzsRvxBgVf.png" alt="img"><br>直接看【Hadoop File Output】的配置项，其实与【文本文件输出】类似，只不过输出位置从本地变成了HDFS：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleConnectHadoop/20180807/SOhAYhStFDx7.png" alt="img"><br>【内容】选项卡，设置字段分隔符，要注意选择<code>LF</code>换行格式，编码<code>UTF-8</code>：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleConnectHadoop/20180807/G6Lg6o8bJbkq.png" alt="img"><br>【字段】选项卡与【文本文件输出】配置方法相同，先【获取字段】，再【最小宽度】。    </p><p>保存，运行，重看结果：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleConnectHadoop/20180807/WHvOBmiYN0AK.png" alt="img"></p>]]></content>
      
      
      <categories>
          
          <category> Kettle </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
            <tag> Kettle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kettle中实现步骤循环操作</title>
      <link href="/2018/08/01/KettleLoop/"/>
      <url>/2018/08/01/KettleLoop/</url>
      
        <content type="html"><![CDATA[<p>本文介绍了如何使用Kettle实现循环执行某个流程操作。<br>注意：本流程在Kettle 7.1版本下可以正常运行，但是在Kettle 8.1版本下无法正常运行，【执行体】步骤【表输入】部分参数无法正确传入，可能是BUG？    </p><h2 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h2><p> 如下图所示，DB1,DB2,DB3,DB4,DB_INFO,TARGET_DB都是数据库，且都不在同一台服务器上，DB1-DB4数据库中含有相同的表及表结构，DB_INFO中有张表存放着需要操作的的数据库的连接信息，要使用Kettle实现：从DB_INFO中获取数据库连接信息，然后分别对获取到的数据库执行相同的数据抽取转换步骤并将结果写入到TARGET_DB中。另外任务是每天定时执行的，DB_INFO中的数据可能会有更新。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleLoop/20180615/YgFDIHGKOVa6.png" alt="img">    </p><p>DB_INFO表结构：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleLoop/20180615/OAApNNNv6jrs.png" alt="img">   </p><h2 id="需求实现"><a href="#需求实现" class="headerlink" title="需求实现"></a>需求实现</h2><p>整体作业流程很简单，只需要两个转换步骤：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleLoop/20180615/v3f4LIMiG2Y6.png" alt="img"><br>【获取db_info】转换步骤，就两个组件，即从数据库中查出数据库连接信息，然后复制记录到结果，配置如下图所示：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleLoop/20180801/ZPYYEjXCGUmw.png" alt="img"><br>【循环读取db_info】转换步骤，也是两个组件，首先是获取上一步骤结果记录，然后将结果记录传递给下一个转换步骤，组件配置如下图所示：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleLoop/20180801/4qRoyGuLq8rT.png" alt="img"><br>另外，在【循环读取db_info】步骤配置窗口一定要勾选【执行每一个输入行】，该选项是实现循环执行的必需项：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleLoop/20180801/xkMCTrRTOxBu.png" alt="img"><br>最后是嵌套在【循环读取db_info】中的【执行体】转换流程，表输入部分数据库连接全部配置成参数即可，参数名需与【循环读取db_info】转换中【执行体】步骤配置的一致：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleLoop/20180801/T85AP5ISX8hv.png" alt="img"><br>至此，即可实现循环执行步骤的需求。    </p>]]></content>
      
      
      <categories>
          
          <category> Kettle </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kettle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kettle系列教程-第十二章：使用Java执行Kettle作业</title>
      <link href="/2018/07/30/KettleDoc-12/"/>
      <url>/2018/07/30/KettleDoc-12/</url>
      
        <content type="html"><![CDATA[<p>本系列教程基于Kettle 8.1（pdi-ce-8.1.0.0-365）。大部分内容同样适用于Kettle 7.x版本。<br>章节目录：    </p><ul><li>一、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-1/">运行环境配置</a><ul><li>JDK</li><li>JVM参数</li><li>KETTLE_HOME</li><li>依赖包导入</li></ul></li><li>二、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-2/">转换与作业</a><ul><li>转换流程</li><li>作业流程</li></ul></li><li>三、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-3/">数据库连接配置</a><ul><li>创建数据库连接</li><li>共享数据库连接</li><li>数据库连接参数</li></ul></li><li>四、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-4/">资源库（数据库存储方式）</a><ul><li>创建资源库</li><li>保存流程到资源库</li><li>从资源库打开流程</li></ul></li><li>五、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-5/">变量/参数</a><ul><li>参数的配置与使用</li><li>变量的配置与使用</li></ul></li><li>六、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-6/">转换流程-输入组件</a><ul><li>Excel输入</li><li>表输入</li></ul></li><li>七、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-7/">转换流程-输出组件</a><ul><li>Excel输出</li><li>文本文件输出</li><li>表输出</li></ul></li><li>八、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-8/">转换流程-转换组件</a></li><li>九、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-9/">脚本组件</a><ul><li>转换-Java代码组件</li><li>作业-SQL组件</li><li>作业Shell组件</li></ul></li><li>十、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-10/">对接大数据平台</a><ul><li>基础文件配置</li><li>上传文件到HDFS</li><li>连接Hive</li></ul></li><li>十一、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-11/">使用Windows计划任务定时执行Kettle作业</a><ul><li>命令说明</li><li>编写批处理脚本执行Kettle作业</li><li>创建计划任务定时执行Kettle作业</li></ul></li><li>十二、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-12/">使用Java执行Kettle作业</a>    <ul><li>搭建Kettle运行环境</li><li>代码示例（作业、转换、资源库）    </li></ul></li></ul><h3 id="本章说明"><a href="#本章说明" class="headerlink" title="本章说明"></a>本章说明</h3><p>Kettle是提供了一些api的，我们可以通过这些api去执行Kettle作业、转换。除了执行作业Kettle还有其他很多api可供使用，本章只介绍作业的执行，其他api有兴趣的可以去探索探索。    </p><h3 id="搭建Kettle运行环境"><a href="#搭建Kettle运行环境" class="headerlink" title="搭建Kettle运行环境"></a>搭建Kettle运行环境</h3><p>首先需要搭建一个Kettle运行环境，很简单，就是从<code>data-integration\lib\</code>目录下复制部分核心jar包出来，导入到java项目（jdk1.8）中，本章节所需jar包如下（不要忘了数据库连接驱动）：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/ZQikFNY9MXtN.png" alt="img">    </p><h3 id="代码示例（作业、转换、资源库）"><a href="#代码示例（作业、转换、资源库）" class="headerlink" title="代码示例（作业、转换、资源库）"></a>代码示例（作业、转换、资源库）</h3><p>这里就直接放代码了，包含作业文件、转换文件、资源库作业的执行示例。    </p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.staroon.kettle.exec;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.pentaho.di.core.KettleEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.pentaho.di.core.database.DatabaseMeta;</span><br><span class="line"><span class="keyword">import</span> org.pentaho.di.core.logging.LogLevel;</span><br><span class="line"><span class="keyword">import</span> org.pentaho.di.core.util.EnvUtil;</span><br><span class="line"><span class="keyword">import</span> org.pentaho.di.job.Job;</span><br><span class="line"><span class="keyword">import</span> org.pentaho.di.job.JobMeta;</span><br><span class="line"><span class="keyword">import</span> org.pentaho.di.repository.RepositoryDirectoryInterface;</span><br><span class="line"><span class="keyword">import</span> org.pentaho.di.repository.kdr.KettleDatabaseRepository;</span><br><span class="line"><span class="keyword">import</span> org.pentaho.di.repository.kdr.KettleDatabaseRepositoryMeta;</span><br><span class="line"><span class="keyword">import</span> org.pentaho.di.trans.Trans;</span><br><span class="line"><span class="keyword">import</span> org.pentaho.di.trans.TransMeta;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RunKettleJob</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 参数列表</span></span><br><span class="line">        Map&lt;String, String&gt; params = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">        params.put(<span class="string">&quot;filename&quot;</span>, <span class="string">&quot;runjob&quot;</span>);</span><br><span class="line">        params.put(<span class="string">&quot;extend&quot;</span>, <span class="string">&quot;txt&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="type">String</span> <span class="variable">kjbPath</span> <span class="operator">=</span> <span class="string">&quot;D:/kettle/jobs/Kettledoc/常规作业示例.kjb&quot;</span>;</span><br><span class="line">        <span class="type">String</span> <span class="variable">ktrPath</span> <span class="operator">=</span> <span class="string">&quot;D:/kettle/jobs/Kettledoc/转换任务.ktr&quot;</span>;</span><br><span class="line"><span class="comment">//        runJob(params, kjbPath);</span></span><br><span class="line"><span class="comment">//        runTrans(params, ktrPath);</span></span><br><span class="line">        runRepoJob(params);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 运行资源库中的作业</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> params 作业参数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">runRepoJob</span><span class="params">(Map&lt;String, String&gt; params)</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            KettleEnvironment.init();</span><br><span class="line">            <span class="type">KettleDatabaseRepository</span> <span class="variable">repository</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">KettleDatabaseRepository</span>();</span><br><span class="line">            <span class="comment">// 配置资源库数据库连接信息</span></span><br><span class="line">            <span class="type">DatabaseMeta</span> <span class="variable">databaseMeta</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DatabaseMeta</span>(</span><br><span class="line">                    <span class="string">&quot;kettle&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;mysql&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;jdbc&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;127.0.0.1&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;kettle&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;3308&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;root&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;lwsjfwq&quot;</span></span><br><span class="line">            );</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 配置连接参数，指定连接编码为UTF8，若不指定则不能读取中文目录或者中文名作业</span></span><br><span class="line">            databaseMeta.getAttributes().put(<span class="string">&quot;EXTRA_OPTION_MYSQL.characterEncoding&quot;</span>, <span class="string">&quot;utf8&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 连接测试</span></span><br><span class="line">            <span class="keyword">if</span> (databaseMeta.testConnection().startsWith(<span class="string">&quot;正确&quot;</span>)) &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;数据库连接成功&quot;</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;数据库连接失败&quot;</span>);</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 配置资源库</span></span><br><span class="line">            <span class="type">KettleDatabaseRepositoryMeta</span> <span class="variable">repositoryMeta</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">KettleDatabaseRepositoryMeta</span>(</span><br><span class="line">                    <span class="string">&quot;kettle&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;kettle&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;Kettle Repository&quot;</span>,</span><br><span class="line">                    databaseMeta</span><br><span class="line">            );</span><br><span class="line">            repository.init(repositoryMeta);</span><br><span class="line">            <span class="comment">// 连接资源库</span></span><br><span class="line">            repository.connect(<span class="string">&quot;admin&quot;</span>, <span class="string">&quot;admin&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 指定job或者trans所在的目录</span></span><br><span class="line">            <span class="type">RepositoryDirectoryInterface</span> <span class="variable">dir</span> <span class="operator">=</span> repository.findDirectory(<span class="string">&quot;/批处理/&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 选择资源库中的作业</span></span><br><span class="line">            <span class="type">JobMeta</span> <span class="variable">jobMeta</span> <span class="operator">=</span> repository.loadJob(<span class="string">&quot;资源库作业示例&quot;</span>, dir, <span class="literal">null</span>, <span class="literal">null</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 配置作业参数</span></span><br><span class="line">            <span class="keyword">for</span> (String param : params.keySet()) &#123;</span><br><span class="line">                jobMeta.setParameterValue(param, params.get(param));</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Job</span>(repository, jobMeta);</span><br><span class="line">            job.setLogLevel(LogLevel.DEBUG);</span><br><span class="line">            <span class="comment">//执行作业</span></span><br><span class="line">            job.start();</span><br><span class="line">            <span class="comment">//等待作业执行结束</span></span><br><span class="line">            job.waitUntilFinished();</span><br><span class="line">            <span class="keyword">if</span> (job.getErrors() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">Exception</span>(<span class="string">&quot;作业执行出错&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 运行转换文件</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> params  转换参数</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> ktrPath 转换文件的路径，后缀ktr</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">runTrans</span><span class="params">(Map&lt;String, String&gt; params, String ktrPath)</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 初始化</span></span><br><span class="line">            KettleEnvironment.init();</span><br><span class="line">            EnvUtil.environmentInit();</span><br><span class="line">            <span class="type">TransMeta</span> <span class="variable">transMeta</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TransMeta</span>(ktrPath);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 配置参数</span></span><br><span class="line">            <span class="keyword">for</span> (String param : params.keySet()) &#123;</span><br><span class="line">                transMeta.setParameterValue(param, params.get(param));</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="type">Trans</span> <span class="variable">trans</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Trans</span>(transMeta);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 设置日志级别</span></span><br><span class="line">            trans.setLogLevel(LogLevel.DEBUG);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 执行转换</span></span><br><span class="line">            trans.execute(<span class="literal">null</span>);</span><br><span class="line">            <span class="comment">// 等待转换执行结束</span></span><br><span class="line">            trans.waitUntilFinished();</span><br><span class="line">            <span class="comment">// 抛出异常</span></span><br><span class="line">            <span class="keyword">if</span> (trans.getErrors() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">Exception</span>(<span class="string">&quot;转换执行出错&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 运行作业文件</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> params  作业参数</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> kjbPath 作业文件路径，后缀kjb</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">runJob</span><span class="params">(Map&lt;String, String&gt; params, String kjbPath)</span> &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            KettleEnvironment.init();</span><br><span class="line">            <span class="type">JobMeta</span> <span class="variable">jobMeta</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JobMeta</span>(kjbPath, <span class="literal">null</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 配置作业参数</span></span><br><span class="line">            <span class="keyword">for</span> (String param : params.keySet()) &#123;</span><br><span class="line">                jobMeta.setParameterValue(param, params.get(param));</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 配置变量</span></span><br><span class="line">            <span class="comment">// jobMeta.setVariable(&quot;name&quot;,&quot;value&quot;);</span></span><br><span class="line"></span><br><span class="line">            <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Job</span>(<span class="literal">null</span>, jobMeta);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 设置日志级别</span></span><br><span class="line">            job.setLogLevel(LogLevel.DEBUG);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 启动作业</span></span><br><span class="line">            job.start();</span><br><span class="line">            <span class="comment">// 等待作业执行完毕</span></span><br><span class="line">            job.waitUntilFinished();</span><br><span class="line">            <span class="keyword">if</span> (job.getErrors() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">Exception</span>(<span class="string">&quot;作业执行出错&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>本章完！    </p>]]></content>
      
      
      <categories>
          
          <category> Kettle </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kettle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kettle系列教程-第十一章：使用Windows计划任务定时执行Kettle作业</title>
      <link href="/2018/07/30/KettleDoc-11/"/>
      <url>/2018/07/30/KettleDoc-11/</url>
      
        <content type="html"><![CDATA[<p>本系列教程基于Kettle 8.1（pdi-ce-8.1.0.0-365）。大部分内容同样适用于Kettle 7.x版本。<br>章节目录：    </p><ul><li>一、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-1/">运行环境配置</a><ul><li>JDK</li><li>JVM参数</li><li>KETTLE_HOME</li><li>依赖包导入</li></ul></li><li>二、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-2/">转换与作业</a><ul><li>转换流程</li><li>作业流程</li></ul></li><li>三、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-3/">数据库连接配置</a><ul><li>创建数据库连接</li><li>共享数据库连接</li><li>数据库连接参数</li></ul></li><li>四、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-4/">资源库（数据库存储方式）</a><ul><li>创建资源库</li><li>保存流程到资源库</li><li>从资源库打开流程</li></ul></li><li>五、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-5/">变量/参数</a><ul><li>参数的配置与使用</li><li>变量的配置与使用</li></ul></li><li>六、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-6/">转换流程-输入组件</a><ul><li>Excel输入</li><li>表输入</li></ul></li><li>七、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-7/">转换流程-输出组件</a><ul><li>Excel输出</li><li>文本文件输出</li><li>表输出</li></ul></li><li>八、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-8/">转换流程-转换组件</a></li><li>九、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-9/">脚本组件</a><ul><li>转换-Java代码组件</li><li>作业-SQL组件</li><li>作业Shell组件</li></ul></li><li>十、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-10/">对接大数据平台</a><ul><li>基础文件配置</li><li>上传文件到HDFS</li><li>连接Hive</li></ul></li><li>十一、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-11/">使用Windows计划任务定时执行Kettle作业</a><ul><li>命令说明</li><li>编写批处理脚本执行Kettle作业</li><li>创建计划任务定时执行Kettle作业</li></ul></li><li>十二、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-12/">使用Java执行Kettle作业</a>    <ul><li>搭建Kettle运行环境</li><li>代码示例（作业、转换、资源库）    </li></ul></li></ul><h3 id="本章说明"><a href="#本章说明" class="headerlink" title="本章说明"></a>本章说明</h3><p>对于使用Windows计划任务去执行Kettle作业这种方式，其实是分为两步的，首先是编写一个批处理脚本，脚本中写着执行Kettle作业的内容，然后是创建一个计划任务去执行这个批处理脚本。所以这一章主要是介绍批处理脚本的编写。    </p><h3 id="命令说明"><a href="#命令说明" class="headerlink" title="命令说明"></a>命令说明</h3><p>Kettle的作业和转换都可以通过批处理脚本去执行，命令文件不一样，但是都在<code>data-integration</code>目录下。<br>执行作业使用的命令文件是<code>Kitchen.bat</code>。<br>执行转换使用的命令文件是<code>Pan.bat</code>。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/4RkVw1xjg1ia.png" alt="img"><br>两个命令文件的配置项类似，其中<code>Kitchen.bat</code>配置项如下：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/7iPCXsFAXsge.png" alt="img"><br><code>Pan.bat</code>配置项如下：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/zIq5nJwHM0x9.png" alt="img">    </p><h3 id="编写批处理脚本去执行Kettle作业"><a href="#编写批处理脚本去执行Kettle作业" class="headerlink" title="编写批处理脚本去执行Kettle作业"></a>编写批处理脚本去执行Kettle作业</h3><p>本章只介绍批处理执行Kettle作业的配置说明，执行转换的配置与作业类似，故不再介绍。<br>作业流程如下图，一个简单的写入文件作业，文件名和扩展名都使用了参数：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/xvKSlgt5zCU4.png" alt="img"><br>对于是否使用资源库，脚本内容不太一样，这里就分开来说。    </p><h4 id="执行普通作业（非资源库中的）"><a href="#执行普通作业（非资源库中的）" class="headerlink" title="执行普通作业（非资源库中的）"></a>执行普通作业（非资源库中的）</h4><p>脚本内容：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/QvUwjNjDagIx.png" alt="img"></p><figure class="highlight bat"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"></span><br><span class="line">:: 进入脚本所在目录</span><br><span class="line"><span class="built_in">cd</span> /D %~dp0</span><br><span class="line"></span><br><span class="line">:: 执行Kettle作业的脚本内容</span><br><span class="line">:: 指定作业文件位置，为防止路径中出现空格，路径两侧需要使用双引号包围</span><br><span class="line">&quot;D:\Program Files\pdi-ce-<span class="number">8</span>.<span class="number">1</span>.<span class="number">0</span>.<span class="number">0</span>-<span class="number">365</span>\data-integration\Kitchen.bat&quot; -file &quot;D:\kettle\jobs\Kettledoc\常规作业示例.kjb&quot; ^</span><br><span class="line">-level=Debug ^</span><br><span class="line">-logfile &quot;D:\Program Files\pdi-ce-<span class="number">8</span>.<span class="number">1</span>.<span class="number">0</span>.<span class="number">0</span>-<span class="number">365</span>\log\kettlelog.log&quot; ^</span><br><span class="line">-param:&quot;filename=hellokettle&quot; ^</span><br><span class="line">-param:&quot;extend=txt&quot;</span><br></pre></td></tr></table></figure><p>执行该批处理文件，运行成功，传参成功，日志写入成功。如果脚本中没有指定参数，则会使用默认参数值去执行作业（<code>注意：Kettle7.x必须要指定所有参数，不会使用默认参数值</code>）：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/sKGgY1kXLrmW.png" alt="img"><br>注意：日志写入是追加方式，不是覆盖写入。    </p><h4 id="执行资源库中的作业"><a href="#执行资源库中的作业" class="headerlink" title="执行资源库中的作业"></a>执行资源库中的作业</h4><p>脚本内容：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/eG75OSSADTqK.png" alt="img"></p><figure class="highlight bat"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"></span><br><span class="line">:: 进入脚本所在目录</span><br><span class="line"><span class="built_in">cd</span> /D %~dp0</span><br><span class="line"></span><br><span class="line">:: 执行Kettle作业的脚本内容</span><br><span class="line">:: 指定命令文件位置，为防止路径中出现空格，路径两侧需要使用双引号包围</span><br><span class="line">&quot;D:\Program Files\pdi-ce-<span class="number">8</span>.<span class="number">1</span>.<span class="number">0</span>.<span class="number">0</span>-<span class="number">365</span>\data-integration\Kitchen.bat&quot; ^</span><br><span class="line">-rep mysql-repo ^</span><br><span class="line">-user admin ^</span><br><span class="line">-pass admin ^</span><br><span class="line">-<span class="built_in">dir</span> /批处理 ^</span><br><span class="line">-job 资源库作业示例 ^</span><br><span class="line">-level=Debug ^</span><br><span class="line">-logfile &quot;D:\Program Files\pdi-ce-<span class="number">8</span>.<span class="number">1</span>.<span class="number">0</span>.<span class="number">0</span>-<span class="number">365</span>\log\kettle-repo-log.log&quot; ^</span><br><span class="line">-param:&quot;filename=kettle-repo&quot; ^</span><br><span class="line">-param:&quot;extend=data&quot;</span><br></pre></td></tr></table></figure><p>执行批处理文件，运行成功，传参成功，日志写入成功：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/umqJKdow2Lpv.png" alt="img">    </p><h3 id="创建计划任务定时执行Kettle作业"><a href="#创建计划任务定时执行Kettle作业" class="headerlink" title="创建计划任务定时执行Kettle作业"></a>创建计划任务定时执行Kettle作业</h3><p>这个就比较简单了，完全是Windows操作方面，打开计划任务窗口，点击创建任务，【常规】选项卡，填写任务名称，运行用户选择<code>SYSTEM</code>（使用<code>SYSTEM</code>用户会在后台默认运行，不弹出CMD窗口），勾选【使用最高权限运行】：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/mXErRPjNJKlF.png" alt="img"><br>【触发器】选项卡，根据需要配置：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/tqWTAkp8esn6.png" alt="img"><br>【操作】选项卡，配置成要运行的批处理文件：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/TbStjvuXRvKb.png" alt="img"><br>其他配置项按需配置，保存即可。<br>计划任务创建完成后，可以手动运行一下，测试作业是否可以正常运行：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/XLFpEUjqYQVa.png" alt="img">    </p><p>本章完！<br>下一章：<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-12/">使用Java执行Kettle作业</a></p>]]></content>
      
      
      <categories>
          
          <category> Kettle </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kettle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kettle系列教程-第十章：对接大数据平台</title>
      <link href="/2018/07/30/KettleDoc-10/"/>
      <url>/2018/07/30/KettleDoc-10/</url>
      
        <content type="html"><![CDATA[<p>本系列教程基于Kettle 8.1（pdi-ce-8.1.0.0-365）。大部分内容同样适用于Kettle 7.x版本。<br>章节目录：    </p><ul><li>一、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-1/">运行环境配置</a><ul><li>JDK</li><li>JVM参数</li><li>KETTLE_HOME</li><li>依赖包导入</li></ul></li><li>二、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-2/">转换与作业</a><ul><li>转换流程</li><li>作业流程</li></ul></li><li>三、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-3/">数据库连接配置</a><ul><li>创建数据库连接</li><li>共享数据库连接</li><li>数据库连接参数</li></ul></li><li>四、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-4/">资源库（数据库存储方式）</a><ul><li>创建资源库</li><li>保存流程到资源库</li><li>从资源库打开流程</li></ul></li><li>五、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-5/">变量/参数</a><ul><li>参数的配置与使用</li><li>变量的配置与使用</li></ul></li><li>六、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-6/">转换流程-输入组件</a><ul><li>Excel输入</li><li>表输入</li></ul></li><li>七、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-7/">转换流程-输出组件</a><ul><li>Excel输出</li><li>文本文件输出</li><li>表输出</li></ul></li><li>八、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-8/">转换流程-转换组件</a></li><li>九、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-9/">脚本组件</a><ul><li>转换-Java代码组件</li><li>作业-SQL组件</li><li>作业Shell组件</li></ul></li><li>十、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-10/">对接大数据平台</a><ul><li>基础文件配置</li><li>上传文件到HDFS</li><li>连接Hive</li></ul></li><li>十一、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-11/">使用Windows计划任务定时执行Kettle作业</a><ul><li>命令说明</li><li>编写批处理脚本执行Kettle作业</li><li>创建计划任务定时执行Kettle作业</li></ul></li><li>十二、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-12/">使用Java执行Kettle作业</a>    <ul><li>搭建Kettle运行环境</li><li>代码示例（作业、转换、资源库）    </li></ul></li></ul><h3 id="本章说明"><a href="#本章说明" class="headerlink" title="本章说明"></a>本章说明</h3><p>Kettle是一个很强大的ETL工具，除了与传统关系型数据库对接，还可与Hadoop平台分布式存储库对接。可能你已经注意到，不管是作业还是转换，都有一个【Big Data】分组，分组下的各个组件都是与Hadoop平台做对接的。Kettle可与多种大数据平台做对接，比如CDH、HDP等。    </p><h3 id="基础文件配置"><a href="#基础文件配置" class="headerlink" title="基础文件配置"></a>基础文件配置</h3><p>在使用【Big Data】插件之前，需要先进行一些配置。以CDH为例，首先需要准备下面这些集群配置文件：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/nBiZW166smrE.png" alt="img"><br>然后将这些配置文件覆盖到<code>data-integration\plugins\pentaho-big-data-plugin\hadoop-configurations\cdh513\</code>目录下：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/2q1lwP236B2S.png" alt="img"><br>再然后，配置一下本机的<strong>hosts</strong>文件，因为这些配置文件使用的都是hostname，不是ip地址。当然你也可以手动把这些配置文件中的hostname全部修改为ip地址：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/cy7sXkDHItKA.png" alt="img"><br>上面这些配置完成后，重新打开Spoon，点击左上角<code>工具栏 -&gt; 工具 -&gt; Hadoop Distribution</code>弹出集群类型选择窗口，我们上一步配置的是CDH，所以这里选择【Cloudera CDH】，然后点击【OK】即可。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/9HsYPtqdrYxz.png" alt="img"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/ykwC5CksZvKV.png" alt="img">    </p><h3 id="上传文件到HDFS"><a href="#上传文件到HDFS" class="headerlink" title="上传文件到HDFS"></a>上传文件到HDFS</h3><p>经过上面一小节的配置后，就可以上传文件到HDFS上了。这里使用的是作业中【Big Data】分组下的【Hadoop Copy Files】组件：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/lZpGplmjZy8q.png" alt="img"><br>配置组件，【Source Environment】选择<code>Local</code>；【源文件/目录】用于指定要上传的文件位置，如果直接指定到了具体文件名，就只上传该文件，如果这里填写的是一个目录，则可以通过【通配符】去过滤要上传的文件；【Destination Environment】选择<code>&lt;Static&gt;</code>；【目标文件/目录】，填写HDFS上目标位置，特别要注意下图<strong>蓝底文字</strong>部分，一定要与集群配置文件<code>core-site.xml</code>文件中<code>fs.defaultFS</code>属性保持一致：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/SvhIkhs10P80.png" alt="img"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/gqVwBF8SOFZQ.png" alt="img"><br>【设置】标签页，可以配置一些其他选项，根据需要配置即可：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/sHh5pjMvTKV4.png" alt="img"><br>配置完成后，保存，运行，查看结果：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/DlIpscT09oAE.png" alt="img">    </p><h3 id="连接Hive"><a href="#连接Hive" class="headerlink" title="连接Hive"></a>连接Hive</h3><p>可以把Hive当成普通的数据库去使用，比如执行DDL语句，查询语句，可以在【表输入】组件使用，但是不能在【表输出】组件中使用。<br>配置数据库连接如下，连接类型选择【Hadoop Hive 2】，主机地址为集群中HiveServer2服务所在主机，端口号为HiveServer2服务的运行端口。如果Hive开启了身份验证LDAP，则需要配置用户名和密码，否则不需要配置：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/TsVEDKXHEMAw.png" alt="img"><br>测试数据库连接：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/O0FdLe0kk3dk.png" alt="img">    </p><p>本章完！<br>下一章：<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-11/">使用Windows计划任务定时执行Kettle作业</a></p>]]></content>
      
      
      <categories>
          
          <category> Kettle </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kettle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kettle系列教程-第九章：脚本组件</title>
      <link href="/2018/07/30/KettleDoc-9/"/>
      <url>/2018/07/30/KettleDoc-9/</url>
      
        <content type="html"><![CDATA[<p>本系列教程基于Kettle 8.1（pdi-ce-8.1.0.0-365）。大部分内容同样适用于Kettle 7.x版本。<br>章节目录：    </p><ul><li>一、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-1/">运行环境配置</a><ul><li>JDK</li><li>JVM参数</li><li>KETTLE_HOME</li><li>依赖包导入</li></ul></li><li>二、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-2/">转换与作业</a><ul><li>转换流程</li><li>作业流程</li></ul></li><li>三、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-3/">数据库连接配置</a><ul><li>创建数据库连接</li><li>共享数据库连接</li><li>数据库连接参数</li></ul></li><li>四、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-4/">资源库（数据库存储方式）</a><ul><li>创建资源库</li><li>保存流程到资源库</li><li>从资源库打开流程</li></ul></li><li>五、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-5/">变量/参数</a><ul><li>参数的配置与使用</li><li>变量的配置与使用</li></ul></li><li>六、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-6/">转换流程-输入组件</a><ul><li>Excel输入</li><li>表输入</li></ul></li><li>七、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-7/">转换流程-输出组件</a><ul><li>Excel输出</li><li>文本文件输出</li><li>表输出</li></ul></li><li>八、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-8/">转换流程-转换组件</a></li><li>九、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-9/">脚本组件</a><ul><li>转换-Java代码组件</li><li>作业-SQL组件</li><li>作业Shell组件</li></ul></li><li>十、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-10/">对接大数据平台</a><ul><li>基础文件配置</li><li>上传文件到HDFS</li><li>连接Hive</li></ul></li><li>十一、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-11/">使用Windows计划任务定时执行Kettle作业</a><ul><li>命令说明</li><li>编写批处理脚本执行Kettle作业</li><li>创建计划任务定时执行Kettle作业</li></ul></li><li>十二、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-12/">使用Java执行Kettle作业</a>    <ul><li>搭建Kettle运行环境</li><li>代码示例（作业、转换、资源库）    </li></ul></li></ul><h3 id="本章说明"><a href="#本章说明" class="headerlink" title="本章说明"></a>本章说明</h3><p>本章主要介绍一下转换中的【Java代码】组件和作业中的【SQL】和【Shell】组件。    </p><h3 id="转换-Java代码组件"><a href="#转换-Java代码组件" class="headerlink" title="转换-Java代码组件"></a>转换-Java代码组件</h3><p>在制作ETL流程的过程中，很有可能会遇到Kettle内置的组件无法满足使用的情况，这个时候就可以利用【Java代码组件】来满足我们的特殊需求，相当于自定义插件。比如我们需要一个将中文字符串转为拼音的功能，很显然，Kettle没有这个功能，我们就可以自己编写代码来实现这个功能。<br>使用上一章的那个流程，将【字段拆分】步骤去掉，换成【Java代码】组件：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/fVVGizTDoOB2.png" alt="img"><br>双击【Java代码】组件，打开配置窗口，展开左侧【Code Snippits】 -&gt; 【Common use】，双击【Main】，即可自动生成一个Java代码模板：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/DfNFXVyrc1k5.png" alt="img"><br>我这里有写好的中文转拼音的代码：    </p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.hnzs;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> net.sourceforge.pinyin4j.PinyinHelper;</span><br><span class="line"><span class="keyword">import</span> net.sourceforge.pinyin4j.format.HanyuPinyinOutputFormat;</span><br><span class="line"><span class="keyword">import</span> net.sourceforge.pinyin4j.format.HanyuPinyinToneType;</span><br><span class="line"><span class="keyword">import</span> net.sourceforge.pinyin4j.format.exception.BadHanyuPinyinOutputFormatCombination;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Created with IntelliJ IDEA.</span></span><br><span class="line"><span class="comment"> * User: Staroon</span></span><br><span class="line"><span class="comment"> * Date: 2018-07-23</span></span><br><span class="line"><span class="comment"> * Time: 16:33:41</span></span><br><span class="line"><span class="comment"> * To change this template use File | Settings | File Templates.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ToPinYin</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        System.out.println(getPinYin(<span class="string">&quot;中国&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> String <span class="title function_">getPinYin</span><span class="params">(String CName)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 中文转为拼音</span></span><br><span class="line">        <span class="type">HanyuPinyinOutputFormat</span> <span class="variable">format</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">HanyuPinyinOutputFormat</span>();</span><br><span class="line">        format.setToneType(HanyuPinyinToneType.WITHOUT_TONE);</span><br><span class="line">        <span class="type">StringBuffer</span> <span class="variable">sb</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringBuffer</span>();</span><br><span class="line">        String[] tmpStr = <span class="literal">null</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; CName.length(); i++) &#123;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                tmpStr = PinyinHelper.toHanyuPinyinStringArray(CName.charAt(i), format);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (BadHanyuPinyinOutputFormatCombination e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (tmpStr == <span class="literal">null</span>) &#123;</span><br><span class="line">                <span class="comment">//非汉字直接拼接</span></span><br><span class="line">                sb.append(CName.charAt(i));</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                sb.append(tmpStr[<span class="number">0</span>]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> sb.toString();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后就是改造一下Kettle提供的Java模板，将<code>getPinYin</code>方法整块复制到<code>processRow</code>方法后面：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/X3Z55jjxx7Ec.png" alt="img"><br>然后修改<code>processRow</code>方法里面的<code>/* TODO:</code>部分，<code>get(Fields.In, &quot;name&quot;).getString(r)</code>表示获取数据流中指定的字段数据；<code>get(Fields.Out, &quot;ename&quot;).setValue(r, ename)</code>用于设置输出字段。还要在最上面导入相关类，具体代码如下：    </p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> net.sourceforge.pinyin4j.PinyinHelper;</span><br><span class="line"><span class="keyword">import</span> net.sourceforge.pinyin4j.format.HanyuPinyinOutputFormat;</span><br><span class="line"><span class="keyword">import</span> net.sourceforge.pinyin4j.format.HanyuPinyinToneType;</span><br><span class="line"><span class="keyword">import</span> net.sourceforge.pinyin4j.format.exception.BadHanyuPinyinOutputFormatCombination;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">processRow</span><span class="params">(StepMetaInterface smi, StepDataInterface sdi)</span> <span class="keyword">throws</span> KettleException &#123;</span><br><span class="line">  <span class="keyword">if</span> (first) &#123;</span><br><span class="line">    first = <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  Object[] r = getRow();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (r == <span class="literal">null</span>) &#123;</span><br><span class="line">    setOutputDone();</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  r = createOutputRow(r, data.outputRowMeta.size());</span><br><span class="line">  <span class="comment">// Get the value from an input field</span></span><br><span class="line">  <span class="type">String</span> <span class="variable">cname</span> <span class="operator">=</span> get(Fields.In, <span class="string">&quot;name&quot;</span>).getString(r);</span><br><span class="line">  <span class="type">String</span> <span class="variable">ename</span> <span class="operator">=</span> getPinYin(cname);</span><br><span class="line">  <span class="comment">// Set a value in a new output field</span></span><br><span class="line">  get(Fields.Out, <span class="string">&quot;ename&quot;</span>).setValue(r, ename);</span><br><span class="line"></span><br><span class="line">  putRow(data.outputRowMeta, r);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接着还要在最下面配置一下输出字段信息，有几个输出字段就需要配置几行：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/mFDbbNVCtdKg.png" alt="img"><br>保存，完事！真的完了吗？还没有！还需要导入依赖包，可以从代码中看出中文转拼音我是用的<code>pinyin4j</code>，向kettle lib目录下放入<code>pinyin4j</code>的jar包，然后重新启动<code>Spoon</code>：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/KYdfuFq0qw6R.png" alt="img"><br>最后调整一下【字段选择】：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/rYbuAUvjd1Hz.png" alt="img"><br>保存，运行，查看结果：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/N6BsAtTSrRMw.png" alt="img">    </p><h3 id="作业-SQL组件"><a href="#作业-SQL组件" class="headerlink" title="作业-SQL组件"></a>作业-SQL组件</h3><p>作业中的SQL组件通常是用来执行DDL语句的，比较简单，与转换中的【表输入组件】类似，但没有数据输出。<br>新建一个作业，拖出【脚本】分组下的【SQL】组件，组成一个小流程：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/HEtP77vR8kPW.png" alt="img"><br>编辑【SQL】组件，选择目标数据库连接，写上SQL内容，多个SQL使用英文分号分隔开，如果使用了参数变量记得勾选【使用变量替换】：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/nbZKNKu9FMLY.png" alt="img"><br>保存，运行，查看结果：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/1suFTHjxhJvw.png" alt="img"><br>注：转换-脚本分组下也有两个【执行SQL脚本】的组件，有兴趣的可以去研究研究，我这里就不再介绍了。    </p><h3 id="作业-Shell组件"><a href="#作业-Shell组件" class="headerlink" title="作业-Shell组件"></a>作业-Shell组件</h3><p>【Shell】组件是用来执行Windows下的批处理脚本的，也就是后缀为bat的脚本。<br>新建一个作业，拖出【Shell】组件，组成流程：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/0H3HaANOJ9zw.png" alt="img"><br>打开【Shell】组件配置窗口，第一项，勾选【插入脚本】表示在该组件中写脚本，右侧的【脚本】选项卡即是写脚本的位置，若不勾选【插入脚本】，则是通过执行指定脚本文件的方式。不建议勾选【插入脚本】选项，因为勾选【插入脚本】后，Kettle运行Shell的时候会先将脚本内容写到一个临时批处理文件中再去执行，很容易出现中文乱码情况。<br>【脚本文件名】配置项，用于指定批处理脚本文件位置，勾选【插入脚本】后，该项不可配置。<br>【工作路径】配置项，用于指定脚本工作路径，通俗的说，就是在哪个目录下运行这个脚本。<br>最下面的【字段】列表，用于配置脚本入参，可以使用参数变量。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/Z3AO1MmKGdbS.png" alt="img"><br>这是脚本内容：    </p><figure class="highlight bat"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"></span><br><span class="line">::进入脚本所在目录</span><br><span class="line"><span class="built_in">cd</span> /D %~dp0</span><br><span class="line"></span><br><span class="line">::在当前目录创建文件夹ShellTest</span><br><span class="line"><span class="built_in">mkdir</span> ShellTest</span><br><span class="line"></span><br><span class="line">::复制脚本文件到ShellTest目录</span><br><span class="line"><span class="built_in">copy</span> Shell-test.bat ShellTest</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> %<span class="number">1</span> &gt; ShellTest\hello.txt</span><br></pre></td></tr></table></figure><p>保存，运行，查看结果：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/royT6cYpbQxA.png" alt="img"><br>运行日志：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/Q3w2J71o60yg.png" alt="img"><br>转换-应用分组下有一个【运行SSH命令】的组件，是向Linux操作系统下远程执行Linux Shell的，有兴趣的可以去看看。    </p><p>本章完！<br>下一章：<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-10/">对接大数据平台</a></p>]]></content>
      
      
      <categories>
          
          <category> Kettle </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kettle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kettle系列教程-第八章：转换流程-转换组件</title>
      <link href="/2018/07/30/KettleDoc-8/"/>
      <url>/2018/07/30/KettleDoc-8/</url>
      
        <content type="html"><![CDATA[<p>本系列教程基于Kettle 8.1（pdi-ce-8.1.0.0-365）。大部分内容同样适用于Kettle 7.x版本。<br>章节目录：    </p><ul><li>一、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-1/">运行环境配置</a><ul><li>JDK</li><li>JVM参数</li><li>KETTLE_HOME</li><li>依赖包导入</li></ul></li><li>二、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-2/">转换与作业</a><ul><li>转换流程</li><li>作业流程</li></ul></li><li>三、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-3/">数据库连接配置</a><ul><li>创建数据库连接</li><li>共享数据库连接</li><li>数据库连接参数</li></ul></li><li>四、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-4/">资源库（数据库存储方式）</a><ul><li>创建资源库</li><li>保存流程到资源库</li><li>从资源库打开流程</li></ul></li><li>五、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-5/">变量/参数</a><ul><li>参数的配置与使用</li><li>变量的配置与使用</li></ul></li><li>六、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-6/">转换流程-输入组件</a><ul><li>Excel输入</li><li>表输入</li></ul></li><li>七、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-7/">转换流程-输出组件</a><ul><li>Excel输出</li><li>文本文件输出</li><li>表输出</li></ul></li><li>八、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-8/">转换流程-转换组件</a></li><li>九、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-9/">脚本组件</a><ul><li>转换-Java代码组件</li><li>作业-SQL组件</li><li>作业Shell组件</li></ul></li><li>十、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-10/">对接大数据平台</a><ul><li>基础文件配置</li><li>上传文件到HDFS</li><li>连接Hive</li></ul></li><li>十一、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-11/">使用Windows计划任务定时执行Kettle作业</a><ul><li>命令说明</li><li>编写批处理脚本执行Kettle作业</li><li>创建计划任务定时执行Kettle作业</li></ul></li><li>十二、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-12/">使用Java执行Kettle作业</a>    <ul><li>搭建Kettle运行环境</li><li>代码示例（作业、转换、资源库）    </li></ul></li></ul><h3 id="本章说明"><a href="#本章说明" class="headerlink" title="本章说明"></a>本章说明</h3><p>本章介绍一下转换分类下几个简单的组件：排序记录、去除重复记录、拆分字段、字段选择。其中在使用【去除重复记录】组件之前一定要对去重的字段进行排序：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/USBR9oUgmFP7.png" alt="img"><br>本章使用一个小示例来介绍这几个组件的使用，数据准备如下：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/GA40jzXhDFv4.png" alt="img"><br>要求目标表数据如下，即需要把原数据中name列不规范的数据处理掉并进行去重：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/CGRN0ksnxahn.png" alt="img"><br>有人可能会说了，这个需求一个简单的SQL就可以做到，干嘛还要借助其他工具？首先，我只是用一个小示例来介绍这些组件的使用；其次Kettle是个专业的数据处理工具，在复杂处理逻辑下，最好是将这些处理步骤交给Kettle来做，而不是全部扔给数据库去做；另外，如果数据源是Excel或者文本文件的话，还能写SQL吗？<br>拖出如下组件构成一个完整的转换流程：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/Gat1PeH521hS.png" alt="img"><br>【排序记录】，以id字段进行排序：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/wIpXSfyWw0u2.png" alt="img"><br>【去除重复记录】，同样选择id字段：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/9NWEXDcYUl0K.png" alt="img"><br>【拆分字段】，选择需要拆分的字段<code>name</code>，指定分隔符”<code>,</code>“，分析原数据得知字段拆分后会有两个新字段，分别指定两个新字段相关信息（字段名、字段类型、去除空格类型）：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/YKKuKTnmP36M.png" alt="img"><br>【字段选择】，第一个选项卡【选择和修改】，用于选择需要保留的字段和修改字段名；【移除】选项卡用于移除不需要的字段；【元数据】选项卡用于修改数据流的元数据，比如数据类型、数据格式、字符集编码等。【选择和修改】与【移除】这两个选项卡只需要配置其中一个即可。这里我们移除掉<code>name2</code>字段并修改<code>name1</code>字段名为<code>new_name</code>：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/0uEV22Rba3bs.png" alt="img"><br>最后再修改下表输出配置，勾选上【裁剪表】选项，用于清空旧数据，并指定数据库字段，修改字段映射关系如下：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/lhTyzLOd6gq6.png" alt="img"><br>配置完成，保存，执行，查看结果：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/U5ZZnOKWU0T4.png" alt="img">    </p><p>本章完！<br>下一章：<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-9/">脚本组件</a></p>]]></content>
      
      
      <categories>
          
          <category> Kettle </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kettle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kettle系列教程-第七章：转换流程-输出组件</title>
      <link href="/2018/07/30/KettleDoc-7/"/>
      <url>/2018/07/30/KettleDoc-7/</url>
      
        <content type="html"><![CDATA[<p>本系列教程基于Kettle 8.1（pdi-ce-8.1.0.0-365）。大部分内容同样适用于Kettle 7.x版本。<br>章节目录：    </p><ul><li>一、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-1/">运行环境配置</a><ul><li>JDK</li><li>JVM参数</li><li>KETTLE_HOME</li><li>依赖包导入</li></ul></li><li>二、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-2/">转换与作业</a><ul><li>转换流程</li><li>作业流程</li></ul></li><li>三、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-3/">数据库连接配置</a><ul><li>创建数据库连接</li><li>共享数据库连接</li><li>数据库连接参数</li></ul></li><li>四、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-4/">资源库（数据库存储方式）</a><ul><li>创建资源库</li><li>保存流程到资源库</li><li>从资源库打开流程</li></ul></li><li>五、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-5/">变量/参数</a><ul><li>参数的配置与使用</li><li>变量的配置与使用</li></ul></li><li>六、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-6/">转换流程-输入组件</a><ul><li>Excel输入</li><li>表输入</li></ul></li><li>七、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-7/">转换流程-输出组件</a><ul><li>Excel输出</li><li>文本文件输出</li><li>表输出</li></ul></li><li>八、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-8/">转换流程-转换组件</a></li><li>九、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-9/">脚本组件</a><ul><li>转换-Java代码组件</li><li>作业-SQL组件</li><li>作业Shell组件</li></ul></li><li>十、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-10/">对接大数据平台</a><ul><li>基础文件配置</li><li>上传文件到HDFS</li><li>连接Hive</li></ul></li><li>十一、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-11/">使用Windows计划任务定时执行Kettle作业</a><ul><li>命令说明</li><li>编写批处理脚本执行Kettle作业</li><li>创建计划任务定时执行Kettle作业</li></ul></li><li>十二、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-12/">使用Java执行Kettle作业</a>    <ul><li>搭建Kettle运行环境</li><li>代码示例（作业、转换、资源库）    </li></ul></li></ul><h3 id="本章说明"><a href="#本章说明" class="headerlink" title="本章说明"></a>本章说明</h3><p>输出就是数据流向的目的地。本章只介绍常用的Excel输出、文本文件输出和表输出三种输出组件。    </p><h3 id="Excel输出"><a href="#Excel输出" class="headerlink" title="Excel输出"></a>Excel输出</h3><p>Excel输出就是将数据写入到Excel表中。输出组件中有两个Excel输出组件:【Excel输出】、【Microsoft Excel输出】。【Excel输出】只能输出为Excel 2007之前（xls）格式的Excel，而【Microsoft Excel输出】可以支持Excel 2007之后（xlsx）格式的Excel，故写入数据到Excel推荐使用【Microsoft Excel输出】这个组件。<br>本小节以【Microsoft Excel输出】为例。<br>输出之前肯定要有一个数据源，转换流程如下图：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/8y6pwdZHIx81.png" alt="img"><br>【表输入】组件这里就不再说怎么配置了，直接看输出组件的配置，【文件&amp;工作表】选项卡下，【文件名】配置项用于指定文件<code>输出路径与文件名</code>（不含后缀），【扩展名】选项指定后缀名（Excel版本），当数据量很大的时候，需要勾选【Stream XSLX data】选项：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/F8sCZGXkbK9F.png" alt="img"><br>切换到【内容】选项卡，先点击【获取字段】，再点击【最小宽度】，其他配置项按需配置，即可完成配置：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/8zC3lnXGoWLG.png" alt="img"><br>保存转换，点击执行，查看执行结果：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/x9gInEFmzIfd.png" alt="img">    </p><h3 id="文本文件输出"><a href="#文本文件输出" class="headerlink" title="文本文件输出"></a>文本文件输出</h3><p>流程与上一流程类似，只需要把输出步骤换成【文本文件输出】，打开【文本文件输出】配置窗口，第一个选项卡内容，【文件名称】选项指定目标文件路径与名称（不含后缀），【扩展名】配置项指定文件后缀：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/KLD8n8Q5SmvH.png" alt="img"><br>切换到【内容】选项卡，通常需要配置的有7项。1：默认为覆盖写入文件，若勾选【追加方式】，则追加写入；2：【分隔符】，指定字段之间的分隔符，我这里配成了中竖线”<code>|</code>“，右侧【插入TAB】按钮用于插入制表符”<code>\t</code>“；3：【封闭符】，当某个字段中的数据中含有<code>指定的分隔符</code>字符串时，在该数据两侧加上封闭符，表示这是一个字段中的数据。根据需要配置；4：默认勾选【头部】，会在结果文件中首行添加字段名，通常去掉勾选；5：【格式】，指定结果文件换行格式，根据需要选择；6：【压缩】，是否进行数据压缩，默认不压缩；7：【编码】，指定结果文件编码，通常指定为UTF-8。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/zLQZrFplce9T.png" alt="img"><br>上一步配置完成，切换到【字段】选项卡，先点击【获取字段】，再点击【最小宽度】，完成配置：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/xojJ5SR361ok.png" alt="img"><br>执行，查看运行结果：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/iAPNLrdDVylI.png" alt="img">    </p><h3 id="表输出"><a href="#表输出" class="headerlink" title="表输出"></a>表输出</h3><p>新建一个转换，复制上一个转换中的步骤，把输出步骤换成【表输出】，打开【表输出】配置窗口，1：【数据库连接】，配置目标数据库连接；2：【目标模式】，配置目标数据库Schema（MySQL没有，不需要配置）；3：【目标表】，填写目标表，该表需要已存在；4：【提交记录数量】，每次事务提交记录的行数，默认1000，表示每1000行提交一次事务；5：【裁剪表】，勾选表示写入数据之前先<strong>清空</strong>表内已有数据；6：【指定数据库字段】，若流数据字段与目标表字段名字不相同，则需要手动指定字段对应关系。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/z8KZrTaBxNKA.png" alt="img"><br>若目标表不存在，可以点击右下方的【SQL】按钮，会自动生成建表语句，然后点击【执行】，即可自动在目标数据库中创建目标表：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/x07lcpkfMZk6.png" alt="img"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/UoyIwGjXiwYK.png" alt="img"><br>勾选【指定数据库字段】后，需要在下方的【数据库字段】标签页中配置字段对应关系，点击【获取字段】按钮，可以自动读取到流数据和目标表中的字段信息。可以直接在此窗口配置字段对应关系，也可以通过【输入字段映射】按钮配置字段映射关系：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/cCH2eWx4sgAy.png" alt="img"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/EqLQnlUQbrMD.png" alt="img"><br>配置完成，保存，运行，查看目标表数据，出现了中文乱码，是因为未配置数据库连接参数，如何配置，这个在前面的章节中有说明：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/NISGUvBG2wa6.png" alt="img">    </p><p>本章完！<br>下一章：<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-8/">转换流程-转换组件</a></p>]]></content>
      
      
      <categories>
          
          <category> Kettle </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kettle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kettle系列教程-第六章：转换流程-输入组件</title>
      <link href="/2018/07/30/KettleDoc-6/"/>
      <url>/2018/07/30/KettleDoc-6/</url>
      
        <content type="html"><![CDATA[<p>本系列教程基于Kettle 8.1（pdi-ce-8.1.0.0-365）。大部分内容同样适用于Kettle 7.x版本。<br>章节目录：    </p><ul><li>一、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-1/">运行环境配置</a><ul><li>JDK</li><li>JVM参数</li><li>KETTLE_HOME</li><li>依赖包导入</li></ul></li><li>二、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-2/">转换与作业</a><ul><li>转换流程</li><li>作业流程</li></ul></li><li>三、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-3/">数据库连接配置</a><ul><li>创建数据库连接</li><li>共享数据库连接</li><li>数据库连接参数</li></ul></li><li>四、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-4/">资源库（数据库存储方式）</a><ul><li>创建资源库</li><li>保存流程到资源库</li><li>从资源库打开流程</li></ul></li><li>五、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-5/">变量/参数</a><ul><li>参数的配置与使用</li><li>变量的配置与使用</li></ul></li><li>六、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-6/">转换流程-输入组件</a><ul><li>Excel输入</li><li>表输入</li></ul></li><li>七、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-7/">转换流程-输出组件</a><ul><li>Excel输出</li><li>文本文件输出</li><li>表输出</li></ul></li><li>八、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-8/">转换流程-转换组件</a></li><li>九、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-9/">脚本组件</a><ul><li>转换-Java代码组件</li><li>作业-SQL组件</li><li>作业Shell组件</li></ul></li><li>十、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-10/">对接大数据平台</a><ul><li>基础文件配置</li><li>上传文件到HDFS</li><li>连接Hive</li></ul></li><li>十一、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-11/">使用Windows计划任务定时执行Kettle作业</a><ul><li>命令说明</li><li>编写批处理脚本执行Kettle作业</li><li>创建计划任务定时执行Kettle作业</li></ul></li><li>十二、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-12/">使用Java执行Kettle作业</a>    <ul><li>搭建Kettle运行环境</li><li>代码示例（作业、转换、资源库）    </li></ul></li></ul><h3 id="本章说明"><a href="#本章说明" class="headerlink" title="本章说明"></a>本章说明</h3><p>输入组件即是数据的入口，本章简单介绍一下转换流程【输入】分组下的常用的几个数据输入组件：Excel输入和表输入。    </p><h3 id="Excel输入"><a href="#Excel输入" class="headerlink" title="Excel输入"></a>Excel输入</h3><p>新建一个转换，从左侧【输入】分组下拖出【Excel输入】组件，并打开该组件配置页面，可以看到三个标有<code>叹号</code>的标签页，表示这三个标签页为<strong>必填项</strong>：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/oYp4fSSyBN7B.png" alt="img"><br>首先选择【表格类型】，根据Excel文件后缀区分即可，我这里准备了一个Excel 2016的文件，后缀是<code>XLSX</code>，故可以选择第二项或者第三项：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/IAeBzfQgtCy5.png" alt="img"><br>然后添加Excel文件，先点击【浏览】按钮选择目标Excel文件，然后点击【添加】按钮将文件添加到【选中的文件】列表中：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/fAZgDcJUbhfC.png" alt="img"><br>接着切换到【工作表】标签页，将数据所在工作表添加到列表中：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/vHrwIp3cwRDu.png" alt="img"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/XyMCz3TIfxI0.png" alt="img"><br>最后切换到【字段】选项卡，点击【获取来自头部数据的字段…】，会自动读取出表头字段信息，根据需要可以修改字段类型等属性：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/5oPMsmnHRWRG.png" alt="img"><br>然后就可以【预览记录】了：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/ha6nL2JWKUKn.png" alt="img">    </p><h3 id="表输入"><a href="#表输入" class="headerlink" title="表输入"></a>表输入</h3><p>表输入组件其实在前面的介绍中已经大致介绍过了，这里再介绍一下具体细节。新建一个转换，拖出【表输入】组件，打开【表输入】配置页面，数据库连接那里时可以选择已创建或者已共享的数据库连接的：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/HopuR28UPEnC.png" alt="img"><br>【数据库连接】右侧三个按钮分别是编辑当前连接、新建连接、创建连接向导。<br>【获取SQL查询语句】按钮可以查看该数据库连接下的所有表并快速生成SQL查询语句：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/PRp7UFGRqfRo.png" alt="img"><br>然后双击要查询的表，即可自动生成SQL语句，同时会弹出窗口询问是否展示出字段，点击是即可自动获取到字段：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/RwEiHqx7xNwl.png" alt="img"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/lk4avG6OLjh5.png" alt="img">    </p><p>本章完！<br>下一章：<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-7/">转换流程-输出组件</a></p>]]></content>
      
      
      <categories>
          
          <category> Kettle </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kettle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kettle系列教程-第五章：变量/参数</title>
      <link href="/2018/07/30/KettleDoc-5/"/>
      <url>/2018/07/30/KettleDoc-5/</url>
      
        <content type="html"><![CDATA[<p>本系列教程基于Kettle 8.1（pdi-ce-8.1.0.0-365）。大部分内容同样适用于Kettle 7.x版本。<br>章节目录：    </p><ul><li>一、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-1/">运行环境配置</a><ul><li>JDK</li><li>JVM参数</li><li>KETTLE_HOME</li><li>依赖包导入</li></ul></li><li>二、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-2/">转换与作业</a><ul><li>转换流程</li><li>作业流程</li></ul></li><li>三、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-3/">数据库连接配置</a><ul><li>创建数据库连接</li><li>共享数据库连接</li><li>数据库连接参数</li></ul></li><li>四、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-4/">资源库（数据库存储方式）</a><ul><li>创建资源库</li><li>保存流程到资源库</li><li>从资源库打开流程</li></ul></li><li>五、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-5/">变量/参数</a><ul><li>参数的配置与使用</li><li>变量的配置与使用</li></ul></li><li>六、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-6/">转换流程-输入组件</a><ul><li>Excel输入</li><li>表输入</li></ul></li><li>七、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-7/">转换流程-输出组件</a><ul><li>Excel输出</li><li>文本文件输出</li><li>表输出</li></ul></li><li>八、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-8/">转换流程-转换组件</a></li><li>九、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-9/">脚本组件</a><ul><li>转换-Java代码组件</li><li>作业-SQL组件</li><li>作业Shell组件</li></ul></li><li>十、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-10/">对接大数据平台</a><ul><li>基础文件配置</li><li>上传文件到HDFS</li><li>连接Hive</li></ul></li><li>十一、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-11/">使用Windows计划任务定时执行Kettle作业</a><ul><li>命令说明</li><li>编写批处理脚本执行Kettle作业</li><li>创建计划任务定时执行Kettle作业</li></ul></li><li>十二、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-12/">使用Java执行Kettle作业</a>    <ul><li>搭建Kettle运行环境</li><li>代码示例（作业、转换、资源库）    </li></ul></li></ul><h3 id="本章说明"><a href="#本章说明" class="headerlink" title="本章说明"></a>本章说明</h3><p>Kettle的参数、变量功能是一个很强大也很好用的一个功能，没有使用这个功能的流程都是死的，是没有灵魂的，因为没有通用性。比如我们可以把数据库连接信息配置成参数，在调用作业的时候动态传入，即可做到在只有一个作业流程的情况下对多个同类数据库执行同样的数据处理流程。<br>启动作业或者转换时初始化的叫做参数，是在调用作业或者转换的时候传入的；作业或者转换执行过程中数值会变动的某些数据，就叫做变量，是在流程内部配置的。    </p><h3 id="参数的配置与使用"><a href="#参数的配置与使用" class="headerlink" title="参数的配置与使用"></a>参数的配置与使用</h3><p>作业、转换的参数用法相同，以转换为例，参数的配置是在<code>转换设置 -&gt; 命名参数</code>标签页配置的。转换设计器<code>空白处双击鼠标左键</code>或者<code>右键菜单 -&gt; 转换设置</code>或者快捷键<code>Ctrl + T</code>即可打开转换设置窗口。这里我们把数据库连接信息配置成参数，并填上默认值：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/cPi89ADJhTtc.png" alt="img"><br>然后拖出一个<code>表输入</code>组件，双击<code>表输入</code>组件图标即可配置表输入信息：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/sR7TJYQvUyDN.png" alt="img"><br>这里选择<code>新建</code>数据库连接，连接信息配置如下（详细看图）：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/3xOEwGFIodbQ.png" alt="img"><br>配置完成以后，点击<code>测试</code>按钮，连接成功，说明参数配置使用成功：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/1kwPlERORecJ.png" alt="img"><br>测试SQL执行：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/Z7HURrQJj1k5.png" alt="img"><br>可以看到，SQL语句中也是可以使用参数的，但是必须要<code>勾选</code>下面的<code>替换SQL语句中的变量</code>选项，这里我们在转换参数中添加一个参数[<code>table_name</code>]:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/3Oc0MfXKnsjK.png" alt="img"><br>回到<code>表输入</code>组件，写上SQL，预览：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/wKUJmYgLekHI.png" alt="img"><br>执行转换时传参：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/yTZWn19dfT7A.png" alt="img">    </p><h3 id="变量的配置与使用"><a href="#变量的配置与使用" class="headerlink" title="变量的配置与使用"></a>变量的配置与使用</h3><p>首先把上面的【转换参数示例】修改一下，就改一下表输入中的SQL语句，查询出mysql中已创建的用户名，【记录数量限制】填为1表示只取第一条数据：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/Qjggk2Tfn3Sx.png" alt="img"><br>然后从【作业】分类下面拖出【设置变量】组件，连接到表输入后面，双击打开：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/h7IszYu8dCOn.png" alt="img"><br>点击右下角的【获取字段】按钮，会自动读取到【表输入】步骤传过来的字段，<code>变量活动类型</code>默认为<code>在跟作业中有效</code>：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/rWX8rrkfs4S8.png" alt="img"><br>点击【确定】的时候会弹出一个提示，意思是设置的变量在当前转换中是不能使用的，只能在后面的步骤中使用：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/px7JpCOARlZx.png" alt="img"><br>变量设置完成，保存该转换，新建一个作业【作业变量示例】，组成下图中的流程：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/8uHJSl5B6Ug5.png" alt="img"><br>双击【转换】组件，配置转换步骤：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/auHTOkSFzmjs.png" alt="img"><br>双击【写入文件】组件，配置该步骤，其中文件名使用了变量<code>USER</code>，变量的使用方式与参数相同，也是<code>$&#123;变量名&#125;</code>，英文半角字符：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/F6dz5tUz6Eyk.png" alt="img"><br>保存作业，运行查看效果，可以看到桌面上多出了一个<code>root.txt</code>文件，文件内容与我们配置的相同：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/QCeAIECJ2OUp.png" alt="img"><br>查看下面的运行日志，还可以看到设置变量时的日志记录：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180730/DFiBXTeQTle5.png" alt="img">    </p><p>本章完！<br>下一章：<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-6/">转换流程-输入组件</a></p>]]></content>
      
      
      <categories>
          
          <category> Kettle </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kettle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kettle系列教程-第四章：资源库（数据库存储方式）</title>
      <link href="/2018/07/18/KettleDoc-4/"/>
      <url>/2018/07/18/KettleDoc-4/</url>
      
        <content type="html"><![CDATA[<p>本系列教程基于Kettle 8.1（pdi-ce-8.1.0.0-365）。大部分内容同样适用于Kettle 7.x版本。<br>章节目录：    </p><ul><li>一、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-1/">运行环境配置</a><ul><li>JDK</li><li>JVM参数</li><li>KETTLE_HOME</li><li>依赖包导入</li></ul></li><li>二、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-2/">转换与作业</a><ul><li>转换流程</li><li>作业流程</li></ul></li><li>三、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-3/">数据库连接配置</a><ul><li>创建数据库连接</li><li>共享数据库连接</li><li>数据库连接参数</li></ul></li><li>四、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-4/">资源库（数据库存储方式）</a><ul><li>创建资源库</li><li>保存流程到资源库</li><li>从资源库打开流程</li></ul></li><li>五、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-5/">变量/参数</a><ul><li>参数的配置与使用</li><li>变量的配置与使用</li></ul></li><li>六、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-6/">转换流程-输入组件</a><ul><li>Excel输入</li><li>表输入</li></ul></li><li>七、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-7/">转换流程-输出组件</a><ul><li>Excel输出</li><li>文本文件输出</li><li>表输出</li></ul></li><li>八、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-8/">转换流程-转换组件</a></li><li>九、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-9/">脚本组件</a><ul><li>转换-Java代码组件</li><li>作业-SQL组件</li><li>作业Shell组件</li></ul></li><li>十、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-10/">对接大数据平台</a><ul><li>基础文件配置</li><li>上传文件到HDFS</li><li>连接Hive</li></ul></li><li>十一、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-11/">使用Windows计划任务定时执行Kettle作业</a><ul><li>命令说明</li><li>编写批处理脚本执行Kettle作业</li><li>创建计划任务定时执行Kettle作业</li></ul></li><li>十二、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-12/">使用Java执行Kettle作业</a>    <ul><li>搭建Kettle运行环境</li><li>代码示例（作业、转换、资源库）    </li></ul></li></ul><h3 id="本章说明"><a href="#本章说明" class="headerlink" title="本章说明"></a>本章说明</h3><p>本篇内容为第四章：资源库（数据库存储方式）。<br>由于默认的转换、作业流程存储方式为单个文件存储，当有很多个转换、作业文件的时候，管理起来会很麻烦，所以这个时候就需要用到资源库了，用于统一管理转换、作业流程。资源库有两种存储方式：<strong>数据库存储</strong>和<strong>文件存储</strong>，本章只讲解<strong>数据库存储</strong>方式。</p><h3 id="创建资源库"><a href="#创建资源库" class="headerlink" title="创建资源库"></a>创建资源库</h3><p>首先需要创建一个字符集编码为<code>UTF8</code>的空白数据库（为什么指定编码为<code>UTF8</code>？因为不指定编码可能会出现中文乱码情况）。还是以MySQL为例，创建一个数据库名为<code>kettle</code>的空白数据库，并指定字符集编码：<code>CREATE DATABASE kettle DEFAULT CHARSET=UTF8;</code>。<br>然后点击Spoon界面右上角的<code>Connect</code>按钮，在弹出的窗口中点击<code>Other Repositories</code>：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/Jo9RSgaMFNbB.png" alt="img"><br>然后选中<code>Database Repository</code>，点击<code>Get Started</code>：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/EZreriA004WL.png" alt="img"><br>给资源库起个名字，再点击<em>None</em>：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/RNXvLPeNHX9N.png" alt="img"><br>弹出的窗口中点击<code>Create New Connection</code>:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/v0Oipld6JT83.png" alt="img"><br>配置一下刚创建的kettle数据库的连接信息：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/AfZWTscKj27v.png" alt="img"><br>再配置一下连接参数：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/o5N6cYwoHcgK.png" alt="img"><br>测试通过后，即可保存。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/eijtS9aasIuY.png" alt="img"><br>然后选中刚创建的数据库连接<code>mysql-repo</code>，再点击<code>Back</code>：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/MISKU8SGiSlR.png" alt="img"><br>确认配置无误后，点击<code>Finish</code>：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/tr0NyKI2PAx7.png" alt="img"><br>初始化数据库，稍等一会即可：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/FxI8gvdWiXOa.png" alt="img"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/4u67q8araddj.png" alt="img"><br>初始化完成，点击<code>Connect Now</code>，输入<code>admin/admin</code>，然后点击<code>Connect</code>即可连接到资源库。有兴趣的话可以去看下资源库的表结构：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/IBhuzwh5sAOx.png" alt="img"><br>此时Spoon界面右上角会变成这样：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/xBbythB976mT.png" alt="img"></p><h3 id="保存转换、作业流程到资源库"><a href="#保存转换、作业流程到资源库" class="headerlink" title="保存转换、作业流程到资源库"></a>保存转换、作业流程到资源库</h3><p>这一部分Kettle 8.1与Kettle 7.x差别较大。<br>新建一个转换或者作业，<code>Ctrl + S</code>保存，如果已经连接了资源库，则默认保存到资源库中：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/waT5vTpiVljA.png" alt="img"><br>右上角可以新建目录：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/H1YcPV42lLgo.png" alt="img"><br>选中保存位置，填写转换或者作业名称，点击<code>Save</code>即可保存到资源库。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/ifoqRh8gMjtw.png" alt="img"></p><h3 id="从资源库打开转换、作业流程"><a href="#从资源库打开转换、作业流程" class="headerlink" title="从资源库打开转换、作业流程"></a>从资源库打开转换、作业流程</h3><ul><li>打开单个流程：<br><code>Ctrl + O</code>或者左上角 <code>文件 -&gt; 打开</code>，选中要打开的流程，<code>Open</code>即可：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/85zBswd9EtZT.png" alt="img">    </li><li>批量打开多个流程：<br><code>Ctrl + E</code>或者 <code>菜单栏 -&gt; 工具 -&gt; 资源库 -&gt; 探索资源库</code>，同时选中多个流程，然后按<code>回车键</code>，即可批量打开多个流程：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/SRzozZpTt8pn.png" alt="img">    <h3 id="管理资源库"><a href="#管理资源库" class="headerlink" title="管理资源库"></a>管理资源库</h3><code>Ctrl + E</code>或者 <code>菜单栏 -&gt; 工具 -&gt; 资源库 -&gt; 探索资源库</code>，右键菜单可以对目录、流程进行删除或者重命名等操作：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/iSE6Pl6ykqMm.png" alt="img">    </li></ul><p>本章完！<br>下一章：<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-5/">变量/参数</a></p>]]></content>
      
      
      <categories>
          
          <category> Kettle </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kettle </tag>
            
            <tag> 资源库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kettle系列教程-第三章：数据库连接配置</title>
      <link href="/2018/07/18/KettleDoc-3/"/>
      <url>/2018/07/18/KettleDoc-3/</url>
      
        <content type="html"><![CDATA[<p>本系列教程基于Kettle 8.1（pdi-ce-8.1.0.0-365）。大部分内容同样适用于Kettle 7.x版本。<br>章节目录：    </p><ul><li>一、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-1/">运行环境配置</a><ul><li>JDK</li><li>JVM参数</li><li>KETTLE_HOME</li><li>依赖包导入</li></ul></li><li>二、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-2/">转换与作业</a><ul><li>转换流程</li><li>作业流程</li></ul></li><li>三、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-3/">数据库连接配置</a><ul><li>创建数据库连接</li><li>共享数据库连接</li><li>数据库连接参数</li></ul></li><li>四、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-4/">资源库（数据库存储方式）</a><ul><li>创建资源库</li><li>保存流程到资源库</li><li>从资源库打开流程</li></ul></li><li>五、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-5/">变量/参数</a><ul><li>参数的配置与使用</li><li>变量的配置与使用</li></ul></li><li>六、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-6/">转换流程-输入组件</a><ul><li>Excel输入</li><li>表输入</li></ul></li><li>七、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-7/">转换流程-输出组件</a><ul><li>Excel输出</li><li>文本文件输出</li><li>表输出</li></ul></li><li>八、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-8/">转换流程-转换组件</a></li><li>九、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-9/">脚本组件</a><ul><li>转换-Java代码组件</li><li>作业-SQL组件</li><li>作业Shell组件</li></ul></li><li>十、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-10/">对接大数据平台</a><ul><li>基础文件配置</li><li>上传文件到HDFS</li><li>连接Hive</li></ul></li><li>十一、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-11/">使用Windows计划任务定时执行Kettle作业</a><ul><li>命令说明</li><li>编写批处理脚本执行Kettle作业</li><li>创建计划任务定时执行Kettle作业</li></ul></li><li>十二、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-12/">使用Java执行Kettle作业</a>    <ul><li>搭建Kettle运行环境</li><li>代码示例（作业、转换、资源库）    </li></ul></li></ul><h3 id="本章说明"><a href="#本章说明" class="headerlink" title="本章说明"></a>本章说明</h3><p>本篇内容为第三章：数据库连接配置。<br>使用Kettle的时候，肯定要与数据库打交道，常用的是jdbc连接方式。</p><h3 id="创建数据库连接"><a href="#创建数据库连接" class="headerlink" title="创建数据库连接"></a>创建数据库连接</h3><p>新建一个作业或者转换，可以在<code>主对象树</code>下面看到<code>DB连接</code>选项，<strong>双击</strong><code>DB连接</code>或者<code>右键菜单</code>点击<code>新建</code>，打开创建数据库连接窗口。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/lFK1WQll6nTJ.png" alt="img"><br>选择数据库类型以及连接方式（默认JDBC），填写相应配置：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/rFPib3lPJNVs.png" alt="img"><br>配置完成后点击<code>测试</code>按钮测试一下数据库连接，如下图所示表示配置成功，然后就可以点击<code>确认</code>保存数据库连接了，新建的数据库连接会显示在<code>DB连接</code>分组下：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/O365X5qfls5L.png" alt="img"> -&gt; <img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/z8ZvSBRLxoDx.png" alt="img">    </p><h3 id="共享数据库连接"><a href="#共享数据库连接" class="headerlink" title="共享数据库连接"></a>共享数据库连接</h3><p>新建的数据库连接只能在当前转换或者作业中使用，好在Kettle提供了数据库连接共享功能，在<code>数据库连接名称</code>上鼠标<strong>右键</strong>，点击<code>共享</code>即可将该数据库连接共享给其他转换或者作业使用，共享成功后，数据库连接名称将<strong>加粗</strong>显示：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/t5V88qkPQLvl.png" alt="img"> -&gt; <img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/AnMZ6tf2eOKx.png" alt="img"><br>另外，数据库连接共享后还会在<code>.kettle</code>目录下生成一个<code>shared.xml</code>文件，文件中记录着被共享的数据库连接信息：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/GgHYIec5GeMc.png" alt="img"><br><strong>警告：如果数据库名为中文，则不能共享该连接，否则会报出异常，影响Spoon的正常使用：</strong><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/SvRn4DEvRZzv.png" alt="img"> -&gt; <img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/Px7As6kbyqhb.png" alt="img"><br>如果手误已经发生这种情况，则可以使用<strong>记事本</strong>打开<code>.kettle</code>目录下的<code>shared.xml</code>文件，手动删除掉<strong>database标签值为中文的connection标签</strong>即可：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/2gcqYXO0bUDy.png" alt="img"></p><h3 id="数据库连接参数"><a href="#数据库连接参数" class="headerlink" title="数据库连接参数"></a>数据库连接参数</h3><p>创建数据库连接的时候还可以配置一些连接参数，比如连接MySQL的时候可以添加连接编码：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/vMccz79IUZ2H.png" alt="img"><br>这种方式可以解决由于编码不一致导致的中文乱码问题（上图的这个参数配置的前提是数据库字符集也是UTF8）。</p><p>本章完！<br>下一章：<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-4/">资源库（数据库存储方式）</a></p>]]></content>
      
      
      <categories>
          
          <category> Kettle </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kettle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kettle系列教程-第二章：转换与作业</title>
      <link href="/2018/07/18/KettleDoc-2/"/>
      <url>/2018/07/18/KettleDoc-2/</url>
      
        <content type="html"><![CDATA[<p>本系列教程基于Kettle 8.1（pdi-ce-8.1.0.0-365）。大部分内容同样适用于Kettle 7.x版本。<br>章节目录：    </p><ul><li>一、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-1/">运行环境配置</a><ul><li>JDK</li><li>JVM参数</li><li>KETTLE_HOME</li><li>依赖包导入</li></ul></li><li>二、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-2/">转换与作业</a><ul><li>转换流程</li><li>作业流程</li></ul></li><li>三、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-3/">数据库连接配置</a><ul><li>创建数据库连接</li><li>共享数据库连接</li><li>数据库连接参数</li></ul></li><li>四、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-4/">资源库（数据库存储方式）</a><ul><li>创建资源库</li><li>保存流程到资源库</li><li>从资源库打开流程</li></ul></li><li>五、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-5/">变量/参数</a><ul><li>参数的配置与使用</li><li>变量的配置与使用</li></ul></li><li>六、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-6/">转换流程-输入组件</a><ul><li>Excel输入</li><li>表输入</li></ul></li><li>七、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-7/">转换流程-输出组件</a><ul><li>Excel输出</li><li>文本文件输出</li><li>表输出</li></ul></li><li>八、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-8/">转换流程-转换组件</a></li><li>九、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-9/">脚本组件</a><ul><li>转换-Java代码组件</li><li>作业-SQL组件</li><li>作业Shell组件</li></ul></li><li>十、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-10/">对接大数据平台</a><ul><li>基础文件配置</li><li>上传文件到HDFS</li><li>连接Hive</li></ul></li><li>十一、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-11/">使用Windows计划任务定时执行Kettle作业</a><ul><li>命令说明</li><li>编写批处理脚本执行Kettle作业</li><li>创建计划任务定时执行Kettle作业</li></ul></li><li>十二、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-12/">使用Java执行Kettle作业</a>    <ul><li>搭建Kettle运行环境</li><li>代码示例（作业、转换、资源库）    </li></ul></li></ul><h3 id="本章说明"><a href="#本章说明" class="headerlink" title="本章说明"></a>本章说明</h3><p>本篇内容为第二章：转换与作业。<br>经过第一章的学习，运行环境配置完成以后，就可以开始运行Kettle了，双击<code>data-integration</code>目录下的<code>Spoon.bat</code>文件，即可启动Kettle的任务设计器Spoon。启动速度较慢，可能会出现假死情况，耐心等待即可，<strong>不要连续多次双击</strong><code>Spoon.bat</code>文件。<br>Spoon主页：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/58LwsXEkyOFJ.png" alt="img"><br>Kettle有两种流程，转换流程和作业流程。<br>本章只介绍基本操作，不进行具体可执行流程设计。</p><h3 id="转换流程"><a href="#转换流程" class="headerlink" title="转换流程"></a>转换流程</h3><p>Kettle是个<strong>ETL</strong>工具嘛，转换流程就是主要进行数据转换（T）步骤设计的地方。当然也包含数据源（E）和目标（L）。<br>新建转换流程的方式有很多，比如左上角 <code>文件 -&gt; 新建 -&gt; 转换</code> ，或者点击欢迎页面WORK图标下的<code>New transforation</code>，亦可<code>双击左侧主对象树下的转换图标</code>，又可按快捷键<code>Ctrl + N</code>。<br>转换流程设计页面左侧<code>核心对象</code>下面是一个个的分类模块，每个分类下面又有许多个功能不同的组件，鼠标按住左侧组件图标拖拽到右侧流程设计面板即可增加一个步骤。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/VNaTpu1Z9jNY.png" alt="img"><br>步骤之间需要使用箭头连接，箭头方向表示步骤流向，按住Shift键的同时鼠标点住步骤图标向外拉即可拉出一条箭头（按住鼠标中键也可拉出箭头），将箭头拉向下一个步骤，即可形成一个简单的转换流程：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/Ap4s4RqfMXdv.png" alt="img"> -&gt; <img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/4eSh5bkcIzMG.png" alt="img"><br>需要注意的是步骤之间箭头的颜色，<strong>深色表示连接状态，浅色表示断开状态</strong>。比如下面这个转换流程，<strong>表输出</strong>步骤与上一步骤是断开连接的，执行流程的时候执行到<strong>去除重复记录</strong>这一步骤后就不会再往下执行了。单击箭头可以调整连接状态。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/RV0bXtVlWSno.png" alt="img"><br><code>Ctrl + S</code>保存，将保存为<code>ktr</code>后缀的文件。</p><h3 id="作业流程"><a href="#作业流程" class="headerlink" title="作业流程"></a>作业流程</h3><p>作业流程，即是对转换流程进行调度的。除了调度转换流程还可以做一些其他的工作，比如文件管理、条件判断、脚本执行等等，也可以调度其他作业流程。<br>新建作业流程与转换流程类似，快捷键是<code>Ctrl + Alt + N</code>。核心组件在<code>通用</code>分类下，一个作业流程必须包含<code>START</code>组件，可以没有<code>成功</code>组件。作业流程中可以嵌套转换流程和作业流程：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/k6rk5JXSm9lT.png" alt="img"><br>与转换流程不同的是，除了步骤之间有<code>连接状态</code>（箭头颜色深浅），还有<code>连接条件</code>（箭头上的图标，一共三种）。上图的这个作业中包含了所有连接条件：    </p><ul><li>小锁图标，表示不管上一步骤执行结果如何，都执行下一个步骤；</li><li>红叉图标，表示只有上一步骤执行出错或者返回FALSE，才执行下一步骤；</li><li>绿勾图标，表示只有上一步骤执行成功或者返回TRUE，才执行下一步骤。    </li></ul><p>单击连接条件图标可以调整连接条件，<code>START</code>步骤与下一步骤之间的连接条件不可修改。<br><code>START</code>组件标识着工作流的开始，也是配置定时任务的地方：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/nRGdpRf37ULI.png" alt="img"><br>定时调度功能还是很灵活的，只不过需要一直保持Spoon处于启动状态，一旦Spoon窗口被误关闭，定时任务就无效了，所以一般不使用Kettle自带的这个调度器。比较常用的是使用操作系统的定时任务功能，比如Windows的计划任务，或者可以编写Java程序进行调度，后面会有详细讲解，这里就不再细说。<br><code>Ctrl + S</code>保存，将保存为<code>kjb</code>后缀的文件。</p><p>本章完！<br>下一章：<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-3/">数据库连接配置</a></p>]]></content>
      
      
      <categories>
          
          <category> Kettle </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kettle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kettle系列教程-第一章：运行环境配置</title>
      <link href="/2018/07/18/KettleDoc-1/"/>
      <url>/2018/07/18/KettleDoc-1/</url>
      
        <content type="html"><![CDATA[<p>本系列教程基于Kettle 8.1（pdi-ce-8.1.0.0-365）。大部分内容同样适用于Kettle 7.x版本。<br>章节目录：    </p><ul><li>一、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-1/">运行环境配置</a><ul><li>JDK</li><li>JVM参数</li><li>KETTLE_HOME</li><li>依赖包导入</li></ul></li><li>二、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-2/">转换与作业</a><ul><li>转换流程</li><li>作业流程</li></ul></li><li>三、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-3/">数据库连接配置</a><ul><li>创建数据库连接</li><li>共享数据库连接</li><li>数据库连接参数</li></ul></li><li>四、<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-4/">资源库（数据库存储方式）</a><ul><li>创建资源库</li><li>保存流程到资源库</li><li>从资源库打开流程</li></ul></li><li>五、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-5/">变量/参数</a><ul><li>参数的配置与使用</li><li>变量的配置与使用</li></ul></li><li>六、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-6/">转换流程-输入组件</a><ul><li>Excel输入</li><li>表输入</li></ul></li><li>七、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-7/">转换流程-输出组件</a><ul><li>Excel输出</li><li>文本文件输出</li><li>表输出</li></ul></li><li>八、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-8/">转换流程-转换组件</a></li><li>九、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-9/">脚本组件</a><ul><li>转换-Java代码组件</li><li>作业-SQL组件</li><li>作业Shell组件</li></ul></li><li>十、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-10/">对接大数据平台</a><ul><li>基础文件配置</li><li>上传文件到HDFS</li><li>连接Hive</li></ul></li><li>十一、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-11/">使用Windows计划任务定时执行Kettle作业</a><ul><li>命令说明</li><li>编写批处理脚本执行Kettle作业</li><li>创建计划任务定时执行Kettle作业</li></ul></li><li>十二、<a href="https://blog.holoyoo.com/2018/07/30/KettleDoc-12/">使用Java执行Kettle作业</a>    <ul><li>搭建Kettle运行环境</li><li>代码示例（作业、转换、资源库）    </li></ul></li></ul><h3 id="本章说明"><a href="#本章说明" class="headerlink" title="本章说明"></a>本章说明</h3><ul><li>本篇内容为第一章：运行环境配置。</li><li>本章内容基于Windows平台，可能不适用于Linux下的环境配置。</li><li>本章所有操作都是重启Kettle后生效。    </li></ul><h3 id="JDK"><a href="#JDK" class="headerlink" title="JDK"></a>JDK</h3><p>Kettle 8.1要求jdk版本1.8以上，Windows下jdk环境的配置这里就不赘述了。只说一下其中一种可能的情况：系统已配置jdk环境，但不是jdk1.8，又不想升级已配置的jdk环境，即需要<strong>单独为Kettle配置jdk1.8环境</strong>。<br>操作如下：首先安装jdk1.8，不用修改系统环境变量。然后进入 <code>data-integration</code>目录找到<code>Spoon.bat</code>文件，右键使用<strong>除了记事本以外的文本编辑器</strong>打开（比如 VS Code、EditPlus、Notepad ++），在”<code>cd /D %~dp0</code>“下面添加一行（路径指向jdk1.8的目录，可以使用相对路径）：”<code>set JAVA_HOME=/path/to/jdk1.8</code>“即可。如图所示:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/xkOTRakGtwyB.png" alt="img"></p><h3 id="JVM参数"><a href="#JVM参数" class="headerlink" title="JVM参数"></a>JVM参数</h3><p>Kettle 8.1默认使用的最大jvm堆内存是2G，执行某些复杂作业可能会出现堆内存溢出错误（<code>OutOfMemoryError</code>），此时就需要调正Kettle的jvm参数。<br>依旧是<code>data-integration</code>目录下的<code>Spoon.bat</code>文件，找到</p><figure class="highlight bat"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> &quot;<span class="variable">%PENTAHO_DI_JAVA_OPTIONS%</span>&quot;==&quot;&quot; <span class="built_in">set</span> PENTAHO_DI_JAVA_OPTIONS=&quot;-Xms1024m&quot; &quot;-Xmx2048m&quot; &quot;-XX:MaxPermSize=<span class="number">256</span>m&quot;</span><br></pre></td></tr></table></figure><p>这一行，适当增大”<code>-Xmx</code>“参数值即可。<br>如果出现了栈溢出错误（<code>StackOverFlowError</code>）（一般不会出现），则需要再增加一个参数”<code>-Xss</code>“，数值需要根据本机内存配置适当填写。<br>如图所示：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/ygRaKzNIkhbA.png" alt="img"></p><h3 id="KETTLE-HOME"><a href="#KETTLE-HOME" class="headerlink" title="KETTLE_HOME"></a>KETTLE_HOME</h3><p>Kettle运行时会使用一个名叫”<code>.kettle</code>“的文件夹，里面存放着一些配置文件。默认该目录在C盘个人用户目录下：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/L7G3SZr9Qs5N.png" alt="img"><br>通常情况下没什么问题，但如果需要同时安装多个Kettle的话，最好还是单独配置一下<code>KETTLE_HOME</code>，这样的话，<code>.kettle</code>目录就会自动创建在配置的<code>KETTLE_HOME</code>目录下。<br>仍旧是<code>data-integration</code>目录下的<code>Spoon.bat</code>文件，在”<code>cd /D %~dp0</code>“下面添加一行”<code>set KETTLE_HOME=../</code>“，如图所示：<br> <img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/cLvuzC8sK7vc.png" alt="img"><br>这次使用了相对路径，启动Kettle后会在<strong>Spoon.bat所在目录的上一层目录</strong>下创建一个<code>.kettle</code>文件夹(当然也可以使用绝对路径)：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/InPwufFufS59.png" alt="img"></p><h3 id="依赖包导入"><a href="#依赖包导入" class="headerlink" title="依赖包导入"></a>依赖包导入</h3><p>Kettle是没有内置数据库jdbc连接驱动的，当测试数据库连接的时候报出未找到驱动错误，那肯定是忘记导入jdbc驱动了。因此需要提前把常用数据库的jdbc驱动放置到<code>data-integration/lib/</code>目录下，另外，若是在Java代码组件中使用了第三方依赖包，也需要依赖包放置到该目录下。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/eIW4tw8CDERU.png" alt="img"><br>不同版本的jdbc驱动对于不同版本的数据库可能会出现不兼容问题，导入驱动的时候需要对照下数据库版本。<br>不能把一个数据库的多个版本的jdbc驱动同时导入，会造成依赖冲突。</p><p>本章完！<br>下一章：<a href="https://blog.holoyoo.com/2018/07/18/KettleDoc-2/">Kettle转换与作业</a></p>]]></content>
      
      
      <categories>
          
          <category> Kettle </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kettle </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Gpg4win&amp;Kettle文件加密、解密组件的使用</title>
      <link href="/2018/05/06/KettleGPG/"/>
      <url>/2018/05/06/KettleGPG/</url>
      
        <content type="html"><![CDATA[<p>Kettle是一个很强大的开源的数据ETL工具，并且可以与大数据平台整合，直接将关系型数据库中的数据接入到Hadoop平台上。    </p><p>在对数据文件进行操作的时候有些场景可能需要对数据文件进行加密，以保证数据的安全性，而Kettle刚好提供了文件加密组件<strong>用PGP加密文件</strong>，这个组件在<strong>作业</strong>/<strong>文件加密</strong>模块下，使用的加密方式是GPG加密。    </p><p>所以在介绍Kettle加密文件之前，先介绍一下GPG这个软件:    </p><h3 id="GPG加密软件的使用"><a href="#GPG加密软件的使用" class="headerlink" title="GPG加密软件的使用"></a>GPG加密软件的使用</h3><p>GPG，全称GnuPG，根据<a href="https://www.gnupg.org/">GPG官网</a>的说法，是商业加密软件PGP的免费版，可以对数据和通信进行加密和签名，并具有多功能密钥管理系统。    </p><p>GPG提供了非对称加密的方式，即加密和解密使用的是不同的密钥（分别叫公钥、私钥），公钥只能用于加密，不能解密，私钥可以解密。顾名思义，公钥是可以共享给别人的密钥，而私钥则是需要自己好好保护的密钥。别人使用公钥对要发送给你的数据进行加密，你收到加密后的密文后就可以拿私钥对该密文进行解密，由于私钥只在自己手中，就算是黑客也没办法获取密文中的真实数据，可以保证信息的安全传输。    </p><h4 id="在Windows下安装GPG加密软件"><a href="#在Windows下安装GPG加密软件" class="headerlink" title="在Windows下安装GPG加密软件"></a>在Windows下安装GPG加密软件</h4><p>Windows下需要安装<a href="https://www.gpg4win.org/">Gpg4win</a>。<br>下载Gpg4win安装程序后，双击安装：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/dl3gHjbdAj.png" alt="mark"><br>只勾选第二个选项（注意：XP系统下第二个选项不可选，需要勾选第三个选项）：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/7fmB5dCFbF.png" alt="mark"><br>下一步，默认安装位置安装。    </p><p>安装完成，桌面上会多出一个图标（密钥管理器）：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/BBGg3Gd9c9.png" alt="mark"><br>双击这个图标打开<strong>密钥管理器</strong>：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/aGhdCA513A.png" alt="mark"><br>首先需要创建一个密钥对，点击<strong>新建密钥对</strong>按钮：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/d6Lg1f8FJf.png" alt="mark"><br>输入相关信息，下一步：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/d6Lg1f8FJf.png" alt="mark"><br>点击创建：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/H394HLlGmC.png" alt="mark"><br>然后会弹出一个输入框，需要给私钥设置一个保护密码：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/9cDea9beH4.png" alt="mark"><br>如果你设置的密码不够复杂的话，会弹出一个警告，点击Take this one anyway即可：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/I5eli5EE6c.png" alt="mark"><br>创建完成：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/HfcK07Dkfl.png" alt="mark"><br>可以在密钥列表中看到新建的密钥对：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/A7EEjkGimb.png" alt="mark">    </p><h4 id="密钥的导入与导出"><a href="#密钥的导入与导出" class="headerlink" title="密钥的导入与导出"></a>密钥的导入与导出</h4><ul><li>导出密钥<br>选中密钥对，鼠标右键即可弹出菜单，第一个<strong>导出</strong>只是导出公钥，如果想要导出私钥，需要选择下面的<strong>导出绝对密钥</strong>选项：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/7DK4ED844F.png" alt="mark">    </li><li>导入密钥<br>点击菜单栏的导入按钮（示例是一个绝对密钥文件的导入）:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/fdj2BH16DG.png" alt="mark"><br>点击<strong>是</strong>修改密钥的信任级别为<strong>无限制</strong>，关于信任级别的作用后面会有提到。    <h4 id="删除私钥保护密码"><a href="#删除私钥保护密码" class="headerlink" title="删除私钥保护密码"></a>删除私钥保护密码</h4>文件加密解密操作这里就不再介绍，密钥管理器界面上有操作按钮。<br>刚刚新建的密钥对是设置了私钥保护密码的，解密的时候就需要输入保护密码，为了方便操作，可以将保护密码去除掉。<br>右键要去掉私钥保护密码的密钥，选择更改密码句：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/J3jL04kkFc.png" alt="mark"><br>输入原密码：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/DmjI5l51cj.png" alt="mark"><br>留空，直接OK：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/kdC30C9Ike.png" alt="mark"><br>点击Yes：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/ih2GkJjFF6.png" alt="mark"><br>再次直接OK：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/kdC30C9Ike.png" alt="mark"><br>再次YES：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/ih2GkJjFF6.png" alt="mark"><br>密码去除成功：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/7ebbigAiEg.png" alt="mark"><br>此后再去解密文件就不需要输入保护密码了。    </li></ul><p>关于GPG软件的其它进阶操作这里就不再介绍。</p><h3 id="Kettle文件加密组件的使用"><a href="#Kettle文件加密组件的使用" class="headerlink" title="Kettle文件加密组件的使用"></a>Kettle文件加密组件的使用</h3><p>打开Kettle，新建一个作业[Ctrl + Alt + N]，将<strong>核心对象</strong>下的<strong>文件加密</strong>文件夹下的<strong>用PGP加密文件</strong>组件拖到右侧，组成一个简单的流程：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/mfl5H8e2df.png" alt="mark"><br>为了操作方便，先双击<strong>作业空白处</strong>配置两个参数（<strong>源文件夹</strong>和<strong>目标文件夹</strong>）：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/KEibA64JAD.png" alt="mark"><br>然后双击<strong>用PGP加密文件</strong>组件，打开配置页面：<br>最上面<strong>GPG文件路径</strong>，是设置<code>gpg.exe</code>这个文件路径的，如果是默认位置安装的话就是图示的这个位置；<br><strong>源文件/文件夹</strong>和<strong>目标文件/文件夹</strong>分别填写上刚刚设置的参数项；<br><strong>通配符</strong>设为<code>.*</code>表示对源文件夹的的所有文件都进行加密操作：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/HiG0FfAIJ9.png" alt="mark"><br>配置完以后，点击<strong>源文件/文件夹</strong>后面的<strong>添加</strong>按钮：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/kGad6I51fD.png" alt="mark"><br>然后需要填写<strong>用户ID</strong>，<strong>用户ID</strong>即为GPG<strong>密钥管理器</strong>密钥列表中的<strong>名称</strong>列：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/7FBlBm2I91.png" alt="mark"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/fHFege6EJj.png" alt="mark"><br>切换到<strong>目标文件</strong>选项卡，勾选上<strong>创建目标文件夹</strong>选项，这样如果目标文件夹不存在，Kettle会自动创建目标文件夹；下方还可以配置<strong>如果目标文件已存在</strong>的处理方式，这里我选择的是<strong>覆盖</strong>已存在文件。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/2lLCKdCJg3.png" alt="mark"><br>然后就可以测试文件加密了，向待加密文件夹里放几个文件：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/EdEKlaGKef.png" alt="mark"><br>跑一下加密流程：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/13iI3cKKdA.png" alt="mark"><br>看一下待解密文件夹：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/G0I0b5EBCm.png" alt="mark"><br>图片已经不可查看，文件加密成功！</p><h3 id="Kettle文件解密组件的使用"><a href="#Kettle文件解密组件的使用" class="headerlink" title="Kettle文件解密组件的使用"></a>Kettle文件解密组件的使用</h3><p>新建一个作业[Ctrl + Alt + N]，将<strong>核心对象</strong>下的<strong>文件加密</strong>文件夹下的<strong>用PGP解密文件</strong>组件拖到右侧，组成一个简单的流程：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/ebmiECi9a6.png" alt="mark"><br>同样的，为了操作方便，先双击<strong>作业空白处</strong>配置两个参数（<strong>源文件夹</strong>和<strong>目标文件夹</strong>）：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/15iaAA3cJh.png" alt="mark"><br>与加密类似，需要配置<strong>gpg文件路径</strong>，<strong>源路径</strong>和<strong>目标路径</strong>，<strong>密钥</strong>不用填写：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/2GiAk2hdJi.png" alt="mark"><br><strong>目标文件夹</strong>选项卡也与加密类似：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/HclG8Edd9H.png" alt="mark"><br>配置完成后，确定，保存，即可开始运行解密流程（如果未去除私钥保护密码，则第一次运行会弹出输入密码窗口）：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/9c63kE7m1C.png" alt="mark"><br>查看<strong>已解密文件</strong>文件夹：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/J7K10amE34.png" alt="mark"><br>文件解密成功！</p><h3 id="使用Kettle进行文件加密、解密注意事项"><a href="#使用Kettle进行文件加密、解密注意事项" class="headerlink" title="使用Kettle进行文件加密、解密注意事项"></a>使用Kettle进行文件加密、解密注意事项</h3><p>加密报错:<code>Error running command: gpg: B3CC28EC0344DA15: There is no assurance this key belongs to the named user</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/cmH1g35I2l.png" alt="mark"><br>则可能是因为该密钥信任级别较低，这个时候就需要修改一下密钥的信任级别或者进行认证。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/1k5Fg1ea5K.png" alt="mark">    </p><ul><li>方法一：使用密钥管理器可以右键要认证的密钥，点击认证，不过需要至少已经存在一个信任级别为5级的密钥才能认证。    </li><li>方法二：使用CMD命令修改密钥信任级别。打开cmd窗口，进入<strong>gpg.exe</strong>所在目录，执行<code>gpg --edit-key staroon</code>，<strong>staroon</strong>是想要修改信任级别的密钥的<strong>密钥ID</strong>，然后输入<strong>trust</strong>回车，再输入<strong>5</strong>回车，再输入<strong>y</strong>回车，最后输入<strong>save</strong>保存，即可：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/I4078iJeCb.png" alt="mark"><br>认证以后再回到密钥管理器就可以看到密钥的认证级别已变为<strong>认证的</strong>，Kettle就可以正常加密了：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/Kgdb08DeCG.png" alt="mark"></li></ul>]]></content>
      
      
      <categories>
          
          <category> Kettle </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kettle </tag>
            
            <tag> GPG </tag>
            
            <tag> ETL </tag>
            
            <tag> 文件加密 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CDH5高可用集群离线部署</title>
      <link href="/2018/02/08/CDH5Install/"/>
      <url>/2018/02/08/CDH5Install/</url>
      
        <content type="html"><![CDATA[<p>前几篇文章介绍了下原生Hadoop集群的部署过程，这篇文章就来介绍下CDH的部署过程，毕竟发行版Hadoop的部署、运维都很方便，稳定性也好，实际生产环境上用原生Hadoop的并不是很多。</p><p>推荐还是多看<a href="https://www.cloudera.com/documentation.html">CDH官方文档</a></p><p>CDH5各版本的部署过程应该都差不多，我这边测试的CDH5.10.2的和CDH5.9.0的部署过程一模一样，这篇文章就以CDH5.9.0为例。</p><h3 id="操作系统环境准备"><a href="#操作系统环境准备" class="headerlink" title="操作系统环境准备"></a>操作系统环境准备</h3><p>这个前面的文章已经介绍过，这里不再赘述。<br>包含<strong>操作系统的参数调整</strong>、<strong>MySQL安装</strong>、<strong>Jdk1.8安装</strong>等。<br>-&gt; <a href="https://blog.holoyoo.com/2017/11/05/SetEnv/">Hadoop集群搭建系统环境准备</a></p><p>注意: 这里操作系统参数不调整的话，后面安装CDH集群前进行主机检查的时候会发出告警。</p><h3 id="文件准备"><a href="#文件准备" class="headerlink" title="文件准备"></a>文件准备</h3><p>由于是离线部署，因此需要预先下载好需要的文件。<br>需要准备的文件有:    </p><ul><li>Cloudera Manager 5<br>文件名: cloudera-manager-centos7-cm5.9.0_x86_64.tar.gz<br>下载地址: <a href="https://archive.cloudera.com/cm5/cm/5/">https://archive.cloudera.com/cm5/cm/5/</a>    </li><li>CDH安装包（Parecls包）<br>版本号必须与Cloudera Manager相对应<br>下载地址: <a href="https://archive.cloudera.com/cdh5/parcels/5.9.0/">https://archive.cloudera.com/cdh5/parcels/5.9.0/</a><br>需要下载下面3个文件：    <ul><li>CDH-5.9.0-1.cdh5.9.0.p0.23-el7.parcel</li><li>CDH-5.9.0-1.cdh5.9.0.p0.23-el7.parcel.sha1</li><li>manifest.json</li></ul></li><li>MySQL jdbc驱动<br>文件名: mysql-connector-java-<em>.tar.gz<br>下载地址: <a href="https://dev.mysql.com/downloads/connector/j/">https://dev.mysql.com/downloads/connector/j/</a><br>解压出: mysql-connector-java-</em>bin.jar    </li></ul><h3 id="Cloudera-Manager安装"><a href="#Cloudera-Manager安装" class="headerlink" title="Cloudera Manager安装"></a>Cloudera Manager安装</h3><ol><li>所有节点上传cloudera-manager-centos7-cm5.9.0_x86_64.tar.gz文件并解压<br><code># tar -zxvf cloudera-manager-centos7-cm5.9.0_x86_64.tar.gz -C /opt</code></li><li>所有节点手动创建文件夹<br><code># mkdir /opt/cm-5.9.0/run/cloudera-scm-agent</code></li><li>所有节点创建<strong>cloudera-scm</strong>用户<br><code># useradd --system --home=/opt/cm-5.9.0/run/cloudera-scm-server --no-create-home --shell=/bin/false --comment &quot;Cloudera SCM User&quot; cloudera-scm</code></li><li>初始化数据库（只需要在Cloudera Manager Server节点执行）    <ul><li>首先需要将mysql jdbc驱动放入相应位置:<br><code># cp /path/to/mysql-connector-java-5.1.42-bin.jar /opt/cm-5.9.0/share/cmf/lib/</code></li><li>然后执行命令:<br><code># /opt/cm-5.9.0/share/cmf/schema/scm_prepare_database.sh mysql -h 192.168.0.201 -uroot -p123456 --scm-host 192.168.0.201 scm scm scm</code></li><li>脚本参数说明:<br>${<strong>数据库类型</strong>} -h ${<strong>数据库所在节点ip/hostname</strong>} -u${<strong>数据库用户名</strong>} -p${<strong>数据库密码</strong>} –scm-host ${<strong>Cloudera Manager Server节点ip/hostname</strong>} scm scm scm</li><li>提示下面这个说明执行成功:<br><code>All done, your SCM database is configured correctly!</code></li></ul></li><li>所有节点修改Agent配置<br><code># vim /opt/cm-5.9.0/etc/cloudera-scm-agent/config.ini</code><br>将其中的<strong>server_host</strong>参数修改为<strong>Cloudera Manager Server节点的主机名</strong></li><li>将如下文件放到<strong>Server节点</strong>的<code>/opt/cloudera/parcel-repo/</code>目录中:    <ul><li>CDH-5.9.0-1.cdh5.9.0.p0.23-el7.parcel</li><li>CDH-5.9.0-1.cdh5.9.0.p0.23-el7.parcel.sha1</li><li>manifest.json</li></ul></li><li>重命名sha1文件<br><code># mv CDH-5.9.0-1.cdh5.9.0.p0.23-el7.parcel.sha1 CDH-5.9.0-1.cdh5.9.0.p0.23-el7.parcel.sha</code></li><li>所有节点更改cm相关文件夹的用户及用户组<br><code># chown -R cloudera-scm:cloudera-scm /opt/cloudera</code><br><code># chown -R cloudera-scm:cloudera-scm /opt/cm-5.9.0</code></li><li>启动Cloudera Manager    <ul><li>Server节点:<br><code># /opt/cm-5.9.0/etc/init.d/cloudera-scm-server start</code><br><code># /opt/cm-5.9.0/etc/init.d/cloudera-scm-agent start</code></li><li>其它节点:<br><code># /opt/cm-5.9.0/etc/init.d/cloudera-scm-agent start</code></li></ul></li></ol><h3 id="CDH集群部署"><a href="#CDH集群部署" class="headerlink" title="CDH集群部署"></a>CDH集群部署</h3><ol><li>Server和Agent都启动以后（第一次启动稍慢，需要耐心等待一会儿），就可以访问CM Web页面进行集群部署了，打开浏览器，访问 <code>http://cm-server-ip:7180</code> 即可，默认的用户名/密码为：admin/admin<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/Cl7K2JfHHd.png" alt="login"></li><li>然后是协议<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/I2Kc5kck9I.png" alt="协议"></li><li>版本选择，有订阅的选订阅版，没有的选企业试用版或者免费版，这里以免费版安装为例。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/7cIJA2Be4f.png" alt="许可证版本选择"></li><li>感谢语<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/0hGAlj7KCG.png" alt="Thanks"></li><li>指定要安装集群的主机，在当前管理的主机列表中可以看到已经启动CM agent的节点（如果没有，需要检查agent服务是否启动正常）。勾选上所需要的节点。我这里由于之前部署过程中没有截图，所以临时装了个虚拟机，故就一个节点。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/KbHeg4gge2.png" alt="hostSelect"> </li><li>Parcel包选择，默认已经选择好配置的本地仓库中的Parcel包。如果版本选择列表看不到选项，则可能是<strong><a href="#Cloudera-Manager%E5%AE%89%E8%A3%85">Cloudera Manager安装</a></strong>步骤的<strong>第6步、第7步</strong>没执行好。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/7hbhkk2fD4.png" alt="parcelSelect"></li><li>如果本地Parcel包配置无误，则下载步骤是瞬间完成的，然后就是耐心等待分配、解压过程，分配过程的速度取决于节点之间的网络传输速度。 所有节点激活完成后就可以进行下一步了。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/2l57dl9g3A.png" alt="包部署"></li><li>然后是主机检查。注意我打红框的地方，前面不禁用transparent hugepage和调整vm.swappiness参数的话，这里就会有警告信息。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/2aCF19a6eJ.png" alt="主机检查"></li><li>安装服务选择，一定要有Zookeeper、HDFS、Yarn，其他的根据自己需要选择。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/g6hE5AGE8e.png" alt="服务选择"></li><li>服务选择完以后，开始进行角色分配。这个需要根据集群规模、节点个数合理分配。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/iAh2BLgeFc.png" alt="角色分配"></li><li>如果选择了Hive，则在安装Hive之前，需要先将mysql jdbc驱动放到Hive的lib文件夹下：<br><code># cp /opt/cm-5.9.0/share/cmf/lib/mysql-connector-java-5.1.42-bin.jar /opt/cloudera/parcels/CDH-5.9.0-1.cdh5.9.0.p0.23/lib/hive/lib/</code><br>然后进入mysql创建hive数据库:<br><code>mysql&gt; create database hive;</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/IHJD0eG7m5.png" alt="hive"><br>配置完以后点一下测试连接，确定没问题以后进行下一步。</li><li>集群参数调整。这个地方可以调整一部分服务的参数，根据需要合理调整即可。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/BJd3jCc1KI.png" alt="参数调整"></li><li>集群启动。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/a0HALGFfe6.png" alt="start"></li><li>集群部署完成。由于我这是临时安装的虚拟机，内存很小，所以报了一大堆警告。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/7KmHFbDGhl.png" alt="success"></li></ol><h3 id="开启高可用-HA"><a href="#开启高可用-HA" class="headerlink" title="开启高可用(HA)"></a>开启高可用(HA)</h3><p>集群的高可用依赖于Zookeeper和ZKFailoverController(ZKFC)，因此启用HA需要确保Zookeeper服务已开启。<br>要求:</p><blockquote><ol><li>NameNode: 活动主机和备用主机(硬件配置相同)</li><li>JournalNode: 至少3个(奇数个)，系统最多可以承受 (JN个数-1)/2 个故障</li><li>Zookeeper: 至少3个(奇数个)</li></ol></blockquote><p>以下部分内容摘自于官方文档:</p><blockquote><p>注意:在HA群集中，备用NameNode还执行命名空间状态的检查点，因此无需在HA群集中运行Secondary NameNode，CheckpointNode或BackupNode<br>注意:启用或禁用HA会导致HDFS服务和所有依赖于HDFS的服务的服务中断。在启用或禁用HA之前，请确保您的群集上没有运行作业<br>注意:启用或禁用HA会导致以前的监视历史记录不可用<br>注意:启用或禁用HA需要使用具有集群管理员权限的用户    </p></blockquote><h4 id="启用HDFS-HA"><a href="#启用HDFS-HA" class="headerlink" title="启用HDFS HA"></a>启用HDFS HA</h4><ul><li>转到HDFS，操作-&gt;启用High Availability</li><li>设置备用NameNode主机(硬件配置与活动主机相同)</li><li>设置JournalNode主机(至少三个),建议放在活动NameNode和备用NameNode以及另外一个硬件类似的机器</li><li>指定每个JournalNode的Edits目录(需要手动创建，要求为目录空，且拥有适当的权限：<strong>hdfs</strong>用户，<strong>hadoop</strong>用户组)<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/h3hcDab27I.png" alt="jn"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/D5f2CCd255.png" alt="ha"></li><li>根据提示，停掉Hive服务，备份元数据库，更新Hive Metastore NameNode，然后重启Hive服务<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/e3kg4gAiB9.png" alt="hive1"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/leGi9fDG30.png" alt="hive2"></li></ul><h4 id="启用YARN-HA"><a href="#启用YARN-HA" class="headerlink" title="启用YARN HA"></a>启用YARN HA</h4><ul><li>转至YARN，操作-&gt;启用High Availability</li><li>选择备用ResourceManager</li><li>重新部署客户端配置</li></ul><h3 id="CDH高可用集群搭建完毕"><a href="#CDH高可用集群搭建完毕" class="headerlink" title="CDH高可用集群搭建完毕"></a>CDH高可用集群搭建完毕</h3><p>搭建完以后，就可以进行一些参数调整、性能测试了</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> CDH </tag>
            
            <tag> 高可用 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CentOS7下挂载新磁盘</title>
      <link href="/2018/02/02/AddDiskOnLinux/"/>
      <url>/2018/02/02/AddDiskOnLinux/</url>
      
        <content type="html"><![CDATA[<p>虚拟机也好，物理机也罢，在CentOS的使用过程中都有可能会出现需要增加磁盘的情况，这篇文章就是介绍如何为新磁盘进行分区以及挂载操作。</p><p>所有操作都在root用户下进行。</p><h4 id="查看当前磁盘使用状况"><a href="#查看当前磁盘使用状况" class="headerlink" title="查看当前磁盘使用状况"></a>查看当前磁盘使用状况</h4><p><code># df -h</code></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Filesystem           Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/mapper/cl-root   18G   15G  3.3G  82% /</span><br><span class="line">devtmpfs             902M     0  902M   0% /dev</span><br><span class="line">tmpfs                912M     0  912M   0% /dev/shm</span><br><span class="line">tmpfs                912M  8.6M  904M   1% /run</span><br><span class="line">tmpfs                912M     0  912M   0% /sys/fs/cgroup</span><br><span class="line">/dev/sda1            197M  119M   79M  61% /boot</span><br><span class="line">tmpfs                183M     0  183M   0% /run/user/0</span><br></pre></td></tr></table></figure><h4 id="列出现有的磁盘及分区信息"><a href="#列出现有的磁盘及分区信息" class="headerlink" title="列出现有的磁盘及分区信息"></a>列出现有的磁盘及分区信息</h4><p><code># fdisk -l</code></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># /dev/sda 是原有的磁盘，可以看到这块磁盘下面的分区信息</span><br><span class="line">Disk /dev/sda: 42.9 GB, 42949672960 bytes, 83886080 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk label type: dos</span><br><span class="line">Disk identifier: 0x000b4958</span><br><span class="line"></span><br><span class="line">   Device Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/sda1   *        2048      411647      204800   83  Linux</span><br><span class="line">/dev/sda2          411648    41943039    20765696   8e  Linux LVM</span><br><span class="line">/dev/sda3        41943040    83886079    20971520   83  Linux</span><br><span class="line"></span><br><span class="line"># /dev/sdb 就是我们刚添加的磁盘（如果原来只有一块磁盘的话），可以看到这块磁盘下面没有任何分区</span><br><span class="line">Disk /dev/sdb: 42.9 GB, 42949672960 bytes, 83886080 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Disk /dev/mapper/cl-root: 19.1 GB, 19113443328 bytes, 37330944 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Disk /dev/mapper/cl-swap: 2147 MB, 2147483648 bytes, 4194304 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br></pre></td></tr></table></figure><h4 id="对新磁盘-dev-sdb-进行分区操作"><a href="#对新磁盘-dev-sdb-进行分区操作" class="headerlink" title="对新磁盘 /dev/sdb 进行分区操作"></a>对新磁盘 <strong><code>/dev/sdb</code></strong> 进行分区操作</h4><p><code># fdisk /dev/sdb</code></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Welcome to fdisk (util-linux 2.23.2).</span><br><span class="line"></span><br><span class="line">Changes will remain in memory only, until you decide to write them.</span><br><span class="line">Be careful before using the write command.</span><br><span class="line"></span><br><span class="line">Device does not contain a recognized partition table</span><br><span class="line">Building a new DOS disklabel with disk identifier 0xfd5ee39c.</span><br><span class="line"></span><br><span class="line"># 输入 m 可以查看命令帮助（我们只需要用到 n 和 w 两个命令）</span><br><span class="line">Command (m for help): m</span><br><span class="line">Command action</span><br><span class="line">   a   toggle a bootable flag</span><br><span class="line">   b   edit bsd disklabel</span><br><span class="line">   c   toggle the dos compatibility flag</span><br><span class="line">   d   delete a partition</span><br><span class="line">   g   create a new empty GPT partition table</span><br><span class="line">   G   create an IRIX (SGI) partition table</span><br><span class="line">   l   list known partition types</span><br><span class="line">   m   print this menu</span><br><span class="line">   n   add a new partition # 添加分区</span><br><span class="line">   o   create a new empty DOS partition table</span><br><span class="line">   p   print the partition table</span><br><span class="line">   q   quit without saving changes</span><br><span class="line">   s   create a new empty Sun disklabel</span><br><span class="line">   t   change a partition&#x27;s system id</span><br><span class="line">   u   change display/entry units</span><br><span class="line">   v   verify the partition table</span><br><span class="line">   w   write table to disk and exit # 写入分区表并退出</span><br><span class="line">   x   extra functionality (experts only)</span><br><span class="line"></span><br><span class="line"># 输入 n 添加分区（一块磁盘最多可以有4个主分区-primary，没有特殊需求的话，全部按默认分一个区就行）</span><br><span class="line">Command (m for help): n</span><br><span class="line">Partition type:</span><br><span class="line">   p   primary (0 primary, 0 extended, 4 free)</span><br><span class="line">   e   extended</span><br><span class="line">Select (default p): </span><br><span class="line">Using default response p</span><br><span class="line">Partition number (1-4, default 1): </span><br><span class="line">First sector (2048-83886079, default 2048): </span><br><span class="line">Using default value 2048</span><br><span class="line">Last sector, +sectors or +size&#123;K,M,G&#125; (2048-83886079, default 83886079): </span><br><span class="line">Using default value 83886079</span><br><span class="line">Partition 1 of type Linux and of size 40 GiB is set</span><br><span class="line"></span><br><span class="line"># 输入 w 保存分区信息</span><br><span class="line">Command (m for help): w</span><br><span class="line">The partition table has been altered!</span><br><span class="line"></span><br><span class="line">Calling ioctl() to re-read partition table.</span><br><span class="line">Syncing disks.</span><br></pre></td></tr></table></figure><h4 id="再次查看磁盘分区信息"><a href="#再次查看磁盘分区信息" class="headerlink" title="再次查看磁盘分区信息"></a>再次查看磁盘分区信息</h4><p><code># fdisk -l</code></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Disk /dev/sda: 42.9 GB, 42949672960 bytes, 83886080 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk label type: dos</span><br><span class="line">Disk identifier: 0x000b4958</span><br><span class="line"></span><br><span class="line">   Device Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/sda1   *        2048      411647      204800   83  Linux</span><br><span class="line">/dev/sda2          411648    41943039    20765696   8e  Linux LVM</span><br><span class="line">/dev/sda3        41943040    83886079    20971520   83  Linux</span><br><span class="line"></span><br><span class="line">Disk /dev/sdb: 42.9 GB, 42949672960 bytes, 83886080 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk label type: dos</span><br><span class="line">Disk identifier: 0xfd5ee39c</span><br><span class="line"></span><br><span class="line"># 可以看到刚刚分的一个区 /dev/sdb1</span><br><span class="line">   Device Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/sdb1            2048    83886079    41942016   83  Linux</span><br><span class="line"></span><br><span class="line">Disk /dev/mapper/cl-root: 19.1 GB, 19113443328 bytes, 37330944 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Disk /dev/mapper/cl-swap: 2147 MB, 2147483648 bytes, 4194304 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br></pre></td></tr></table></figure><h4 id="格式化新分区-dev-sdb1"><a href="#格式化新分区-dev-sdb1" class="headerlink" title="格式化新分区 /dev/sdb1"></a>格式化新分区 <strong><code>/dev/sdb1</code></strong></h4><p>这里使用<strong>ext4</strong>文件系统<br><code># mkfs.ext4 /dev/sdb1</code></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mke2fs 1.42.9 (28-Dec-2013)</span><br><span class="line">Filesystem label=</span><br><span class="line">OS type: Linux</span><br><span class="line">Block size=4096 (log=2)</span><br><span class="line">Fragment size=4096 (log=2)</span><br><span class="line">Stride=0 blocks, Stripe width=0 blocks</span><br><span class="line">2621440 inodes, 10485504 blocks</span><br><span class="line">524275 blocks (5.00%) reserved for the super user</span><br><span class="line">First data block=0</span><br><span class="line">Maximum filesystem blocks=2157969408</span><br><span class="line">320 block groups</span><br><span class="line">32768 blocks per group, 32768 fragments per group</span><br><span class="line">8192 inodes per group</span><br><span class="line">Superblock backups stored on blocks: </span><br><span class="line">32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, </span><br><span class="line">4096000, 7962624</span><br><span class="line"></span><br><span class="line">Allocating group tables: done                            </span><br><span class="line">Writing inode tables: done                            </span><br><span class="line">Creating journal (32768 blocks): done</span><br><span class="line">Writing superblocks and filesystem accounting information: done   </span><br></pre></td></tr></table></figure><h4 id="创建分区挂载目录"><a href="#创建分区挂载目录" class="headerlink" title="创建分区挂载目录"></a>创建分区挂载目录</h4><p><code># mkdir /mnt/disk01</code></p><h4 id="挂载新分区"><a href="#挂载新分区" class="headerlink" title="挂载新分区"></a>挂载新分区</h4><p><code># mount /dev/sdb1 /mnt/disk01/</code></p><h4 id="查看磁盘使用情况"><a href="#查看磁盘使用情况" class="headerlink" title="查看磁盘使用情况"></a>查看磁盘使用情况</h4><p><code># df -h</code></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Filesystem           Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/mapper/cl-root   18G   15G  3.3G  82% /</span><br><span class="line">devtmpfs             902M     0  902M   0% /dev</span><br><span class="line">tmpfs                912M     0  912M   0% /dev/shm</span><br><span class="line">tmpfs                912M  8.6M  904M   1% /run</span><br><span class="line">tmpfs                912M     0  912M   0% /sys/fs/cgroup</span><br><span class="line">/dev/sda1            197M  119M   79M  61% /boot</span><br><span class="line">tmpfs                183M     0  183M   0% /run/user/0</span><br><span class="line"># 多出来了这个</span><br><span class="line">/dev/sdb1             40G   49M   38G   1% /mnt/disk01</span><br></pre></td></tr></table></figure><h4 id="设置开机自动挂载磁盘"><a href="#设置开机自动挂载磁盘" class="headerlink" title="设置开机自动挂载磁盘"></a>设置开机自动挂载磁盘</h4><p><code># vim /etc/fstab</code></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/dev/sdb1/mnt/disk01ext4defaults0 0</span><br></pre></td></tr></table></figure><p>说明: </p><blockquote><p>第一列是设备名<br>第二列是挂载点（挂载目录）<br>第三列是要使用的文件系统<br>第四列是挂载参数，使用默认即可（defaults）<br>第五列是dump备份参数，1：每天备份，2：不定期备份，0：不备份<br>第六列是扇区检验参数，1：最早检验，2：标识为1的设备检验完之后检验，0：不检验</p></blockquote><h4 id="完工"><a href="#完工" class="headerlink" title="完工!"></a>完工!</h4>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CentOS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CentOS7下使用FTP搭建局域网内Yum源</title>
      <link href="/2018/01/24/YumRepoCreate/"/>
      <url>/2018/01/24/YumRepoCreate/</url>
      
        <content type="html"><![CDATA[<p>国内有很多Yum的镜像源，比如阿里、网易等等，速度很快，使用着很方便。<br>但是，有些公司的生产环境是不能连接外网的，这样的环境下，不作一些措施的话，在CentOS上安装软件会很麻烦，依赖包的问题会很让人头疼。<br>所以最好是搭建一个局域网内yum仓库源。</p><h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><p>需要预先下载好Everything的CentOS7安装光盘包，Everything版的软件包比较全。<br>这里以CentOS7.3为例:<br>CentOS-7-x86_64-Everything-1611.iso</p><p>截止到写这篇文章时，CentOS已经更新到了7.4<br>放上版本号对应列表:</p><blockquote><p>1406 - 7.0<br>1503 - 7.1<br>1511 - 7.2<br>1611 - 7.3<br>1708 - 7.4</p></blockquote><h1 id="配置FTP服务器"><a href="#配置FTP服务器" class="headerlink" title="配置FTP服务器"></a>配置FTP服务器</h1><ul><li>首先创建挂载目录<br><code># mkdir /media/cdrom</code></li><li>挂载ISO文件<ul><li>使用VMware安装的虚拟机挂载方式，需要先确认好虚拟机已经连接上ISO文件：<br><code># mount /dev/sr0 /media/cdrom</code></li><li>非CentOS7虚拟机，先上传ISO文件到某一目录，再挂载：<br><code># mount -t iso9660 -o loop /upload/CentOS-7-x86_64-Everything-1611.iso /media/cdrom</code></li></ul></li><li>安装ftp软件（已安装的话就不用再安装了，可以使用<code># rpm -qa | grep vsftpd</code>命令检测）<br><code># rpm -ivh /media/cdrom/Packages/vsftpd-3.0.2-21.el7.x86_64.rpm</code></li><li>启动vsftpd服务,并设为开机自启<br><code># systemctl start vsftpd</code><br>查看21端口：<br><code># netstat -ntl | grep 21</code><br>设为开机自启：<br><code># systemctl enable vsftpd</code><br>浏览器访问<code>ftp://ip_or_hostname</code><br>如果连接超时，说明开启了防火墙，需要关闭防火墙服务并关闭开机自启：<br><code># systemctl stop firewalld</code><br><code># systwmctl disable firewalld</code></li><li>部署yum仓库到ftp服务器<br>将安装光盘中的文件复制到ftp文件夹<code>/var/ftp/pub/</code>下<br>只复制两个目录(<strong>Packages</strong>,<strong>repodata</strong>)、一个文件(<strong>RPM-GPG-KEY-CentOS7</strong>)即可：<br><code># mkdir /var/ftp/pub/centos7</code><br><code># cp -rvf /media/cdrom/Packages /var/ftp/pub/centos7</code><br><code># cp -rvf /media/cdrom/repodata /var/ftp/pub/centos7</code><br><code># cp -rvf /media/cdrom/RPM-GPG-KEY-CentOS7 /var/ftp/pub/centos7</code><br>确认文件复制完毕以后就可以卸载光盘了<br><code># umount /media/cdrom</code><br>再次访问<code>ftp://ip_or_hostname</code>，就可以看到rpm包了<h1 id="配置yum仓库文件"><a href="#配置yum仓库文件" class="headerlink" title="配置yum仓库文件"></a>配置yum仓库文件</h1></li><li>备份原有的yum仓库文件<br><code># cp -rvf /etc/yum.repo.d /upload/</code></li><li>删除原有yum仓库配置文件<br><code># rm -rf /etc/yum.repo.d/*</code></li><li>编辑新的yum仓库文件<br><code># cd /etc/yum.repo.d</code><br><code># vim ftp.repo</code><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[ftp]</span><br><span class="line"># 名字随便填</span><br><span class="line">name=ftp-repo</span><br><span class="line"># ftp服务器路径</span><br><span class="line">baseurl=ftp://ip_or_hostname/pub/centos7/</span><br><span class="line"># 1为启用GPG KEY检查，0禁用</span><br><span class="line">gpgcheck=0</span><br><span class="line"># 1为启用该仓库，0禁用</span><br><span class="line">enabled=1</span><br><span class="line"># GPG KEY路径</span><br><span class="line">gpgkey=ftp://ip_or_hostname/pub/centos7/RPM-GPG-KEY-CentOS-7</span><br></pre></td></tr></table></figure></li><li>保存后,执行<br><code># yum clean all</code><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Loaded plugins: fastestmirror, langpacks</span><br><span class="line">Cleaning repos: ftp</span><br><span class="line">Cleaning up everything</span><br><span class="line">Cleaning up list of fastest mirrors</span><br></pre></td></tr></table></figure></li><li>生成缓存<br><code># yum makecache</code><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Loaded plugins: fastestmirror, langpacks</span><br><span class="line">ftp                                                                                                                | 3.6 kB  00:00:00     </span><br><span class="line">(1/4): ftp/group_gz                                                                                                | 155 kB  00:00:00     </span><br><span class="line">(2/4): ftp/filelists_db                                                                                            | 6.6 MB  00:00:00     </span><br><span class="line">(3/4): ftp/primary_db                                                                                              | 5.6 MB  00:00:00     </span><br><span class="line">(4/4): ftp/other_db                                                                                                | 2.4 MB  00:00:00     </span><br><span class="line">Determining fastest mirrors</span><br><span class="line">Metadata Cache Created</span><br></pre></td></tr></table></figure>然后就可以愉快的在内网环境下使用 <code># yum -y install package_name</code> 来安装软件啦！！！</li></ul>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CentOS </tag>
            
            <tag> Yum </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop集群快捷启动/停止脚本</title>
      <link href="/2018/01/24/ClusterManager/"/>
      <url>/2018/01/24/ClusterManager/</url>
      
        <content type="html"><![CDATA[<p>由于原生Hadoop集群没有统一的管理工具，当向集群中部署了越来越多的组件后，集群的管理就变得非常繁琐复杂，包括集群的启动与停止，需要执行好多条命令，所以我就写了个一键启动、停止集群的shell脚本。</p><p>注意：</p><ul><li>该脚本在自己搭的伪分布式集群上随便玩玩就好，正式生产集群上慎用（一般正式环境上用原生Hadoop应该不会很多吧）！！！</li><li>放置该脚本的机器需要拥有对脚本中涉及到的机器的SSH免密钥登录权限</li><li>当前脚本包含组件有：Zookeeper,HDFS,YARN(HA),JobHistoryServer,HBase,HiveMetaStore,HiveServer2.</li><li>注意看脚本前面的说明<h2 id="脚本内容"><a href="#脚本内容" class="headerlink" title="脚本内容"></a>脚本内容</h2></li></ul><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># 启动|停止 原生Hadoop集群快捷脚本</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 包含组件:Zookeeper,HDFS,YARN(HA),JobHistoryServer,HBase,HiveMetaStore,HiveServer2</span></span><br><span class="line"><span class="comment"># 需要配置各节点间的SSH免密钥登录</span></span><br><span class="line"><span class="comment"># 必须配置:Zookeeper,Hadoop,HBase,Hive的环境变量(/etc/profile), 如下:</span></span><br><span class="line"><span class="comment">######################################################################################################</span></span><br><span class="line"><span class="comment"># export ZOOKEEPER_HOME=/usr/hadoop/zookeeper-3.4.10</span></span><br><span class="line"><span class="comment"># export HADOOP_PREFIX=/usr/hadoop/hadoop-2.7.4</span></span><br><span class="line"><span class="comment"># export HBASE_HOME=/usr/hadoop/hbase-1.2.6</span></span><br><span class="line"><span class="comment"># export HIVE_HOME=/usr/hadoop/hive-1.2.1</span></span><br><span class="line"><span class="comment"># export PATH=$PATH:$ZOOKEEPER_HOME/bin:$HADOOP_PREFIX/bin:$HADOOP_PREFIX/sbin:$HBASE_HOME/bin:$HIVE_HOME/bin</span></span><br><span class="line"><span class="comment">######################################################################################################</span></span><br><span class="line"><span class="comment"># 如果Yarn未配置ResourceManager高可用，需要注释掉两行命令（第55、91行）即可</span></span><br><span class="line"><span class="comment"># 如果未配置JobHistoryServer服务，需要注释掉第57、58、85、86这4行命令</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># zookeeper节点地址，多个地址用双引号包围，空格分隔</span></span><br><span class="line"><span class="built_in">export</span> ZK_HOST=(<span class="string">&quot;master1&quot;</span> <span class="string">&quot;master2&quot;</span> <span class="string">&quot;worker1&quot;</span>)</span><br><span class="line"><span class="comment"># hdfs主节点地址，高可用配置的话填写其中任何一个都可</span></span><br><span class="line"><span class="built_in">export</span> HDFS_HOST=master1</span><br><span class="line"><span class="comment"># yarn主节点地址</span></span><br><span class="line"><span class="built_in">export</span> YARN_HOST=master1</span><br><span class="line"><span class="comment"># yarn备用节点地址</span></span><br><span class="line"><span class="built_in">export</span> YARN_BAK_HOST=master2</span><br><span class="line"><span class="comment"># JobHistoryServer节点地址</span></span><br><span class="line"><span class="built_in">export</span> JOB_HOST=master2</span><br><span class="line"><span class="comment"># hbase主节点地址，高可用配置的话填写其中任何一个都可</span></span><br><span class="line"><span class="built_in">export</span> HBASE_HOST=master1</span><br><span class="line"><span class="comment"># hive metastore服务节点地址</span></span><br><span class="line"><span class="built_in">export</span> HMETA_HOST=master1</span><br><span class="line"><span class="comment"># hive server2服务节点地址</span></span><br><span class="line"><span class="built_in">export</span> HSERVER_HOST=master2</span><br><span class="line"><span class="comment"># 集群启动用户</span></span><br><span class="line"><span class="built_in">export</span> CLUSTER_USER=root</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -ne 1 ];<span class="keyword">then</span></span><br><span class="line">  <span class="built_in">echo</span> -e <span class="string">&quot;\n\tUsage: <span class="variable">$0</span> &#123;start|stop&#125;\n&quot;</span></span><br><span class="line">  <span class="built_in">exit</span> 1;</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="string">&quot;<span class="variable">$1</span>&quot;</span> <span class="keyword">in</span></span><br><span class="line">start)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;-------------------------- 启动Zookeeper ------------------------&quot;</span></span><br><span class="line"><span class="keyword">for</span> zk_host <span class="keyword">in</span> <span class="variable">$&#123;ZK_HOST[@]&#125;</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="built_in">echo</span> -e <span class="string">&quot;\nStart Zk_Server On Host [<span class="variable">$zk_host</span>]...&quot;</span></span><br><span class="line">  ssh <span class="variable">$CLUSTER_USER</span>@<span class="variable">$zk_host</span> <span class="string">&quot;source /etc/profile;zkServer.sh start&quot;</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;---------------------------- 启动HDFS ---------------------------&quot;</span></span><br><span class="line">ssh <span class="variable">$CLUSTER_USER</span>@<span class="variable">$HDFS_HOST</span> <span class="string">&quot;source /etc/profile;start-dfs.sh&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;---------------------------- 启动YARN ---------------------------&quot;</span></span><br><span class="line">ssh <span class="variable">$CLUSTER_USER</span>@<span class="variable">$YARN_HOST</span> <span class="string">&quot;source /etc/profile;start-yarn.sh&quot;</span></span><br><span class="line">ssh <span class="variable">$CLUSTER_USER</span>@<span class="variable">$YARN_BAK_HOST</span> <span class="string">&quot;source /etc/profile;yarn-daemon.sh start resourcemanager&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;---------------------- 启动JobHistoryServer ---------------------&quot;</span></span><br><span class="line">ssh <span class="variable">$CLUSTER_USER</span>@<span class="variable">$JOB_HOST</span> <span class="string">&quot;source /etc/profile;mr-jobhistory-daemon.sh start historyserver&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;---------------------------- 启动HBase --------------------------&quot;</span></span><br><span class="line">ssh <span class="variable">$CLUSTER_USER</span>@<span class="variable">$HBASE_HOST</span> <span class="string">&quot;source /etc/profile;start-hbase.sh&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;----------------------- 启动HiveMetaStore -----------------------&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Start HiveMetaStore On Host [<span class="variable">$HMETA_HOST</span>]...&quot;</span></span><br><span class="line">ssh <span class="variable">$CLUSTER_USER</span>@<span class="variable">$HMETA_HOST</span> <span class="string">&quot;source /etc/profile;nohup hive --service metastore &gt;&gt; /var/hivelog.log 2&gt;&amp;1 &amp;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;------------------------ 启动HiveServer2 ------------------------&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Start HiveServer2 On Host [<span class="variable">$HSERVER_HOST</span>]...&quot;</span></span><br><span class="line">ssh <span class="variable">$CLUSTER_USER</span>@<span class="variable">$HSERVER_HOST</span> <span class="string">&quot;source /etc/profile;nohup hiveserver2 &gt;&gt; /var/hivelog.log 2&gt;&amp;1 &amp;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;\n------------------------- 集群启动完成 --------------------------\n&quot;</span></span><br><span class="line">;;</span><br><span class="line">stop)</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;----------------------- 停止HiveMetaStore -----------------------&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Stop HiveMetaStore On Host [<span class="variable">$HMETA_HOST</span>]...&quot;</span></span><br><span class="line">ssh <span class="variable">$CLUSTER_USER</span>@<span class="variable">$HMETA_HOST</span> <span class="string">&quot;pkill -f hive.metastore.HiveMetaStore&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;------------------------ 停止HiveServer2 ------------------------&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Stop HiveServer2 On Host [<span class="variable">$HSERVER_HOST</span>]...&quot;</span></span><br><span class="line">ssh <span class="variable">$CLUSTER_USER</span>@<span class="variable">$HSERVER_HOST</span> <span class="string">&quot;pkill -f hive.service.server.HiveServer2&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;---------------------------- 停止HBase --------------------------&quot;</span></span><br><span class="line">ssh <span class="variable">$CLUSTER_USER</span>@<span class="variable">$HBASE_HOST</span> <span class="string">&quot;source /etc/profile;stop-hbase.sh&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;---------------------- 停止JobHistoryServer ---------------------&quot;</span></span><br><span class="line">ssh <span class="variable">$CLUSTER_USER</span>@<span class="variable">$JOB_HOST</span> <span class="string">&quot;source /etc/profile;mr-jobhistory-daemon.sh stop historyserver&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;---------------------------- 停止YARN ---------------------------&quot;</span></span><br><span class="line"></span><br><span class="line">ssh <span class="variable">$CLUSTER_USER</span>@<span class="variable">$YARN_HOST</span> <span class="string">&quot;source /etc/profile;stop-yarn.sh&quot;</span></span><br><span class="line">ssh <span class="variable">$CLUSTER_USER</span>@<span class="variable">$YARN_BAK_HOST</span> <span class="string">&quot;source /etc/profile;yarn-daemon.sh stop resourcemanager&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;---------------------------- 停止HDFS ---------------------------&quot;</span></span><br><span class="line">ssh <span class="variable">$CLUSTER_USER</span>@<span class="variable">$HDFS_HOST</span> <span class="string">&quot;source /etc/profile;stop-dfs.sh&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;------------------------- 停止Zookeeper -------------------------&quot;</span></span><br><span class="line"><span class="keyword">for</span> zk_host <span class="keyword">in</span> <span class="variable">$&#123;ZK_HOST[@]&#125;</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="built_in">echo</span> -e <span class="string">&quot;\nStop Zk_Server On Host [<span class="variable">$zk_host</span>]...&quot;</span></span><br><span class="line">  ssh <span class="variable">$CLUSTER_USER</span>@<span class="variable">$zk_host</span> <span class="string">&quot;source /etc/profile;zkServer.sh stop&quot;</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;\n------------------------- 集群已停止运行 -------------------------\n&quot;</span></span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line"><span class="built_in">echo</span> -e <span class="string">&quot;\n\tUsage: <span class="variable">$0</span> &#123;start|stop&#125;\n&quot;</span></span><br><span class="line"><span class="built_in">exit</span> 1</span><br><span class="line">;;</span><br><span class="line"><span class="keyword">esac</span></span><br><span class="line"><span class="built_in">exit</span> 0</span><br></pre></td></tr></table></figure><h2 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h2><p>复制脚本内容保存为<code>cluster.sh</code>文件，<br>将脚本上传到集群中任意一个节点（推荐管理节点），<br>并使用<code># chmod +x cluster.sh</code>赋予脚本可执行权限，</p><ul><li>集群启动<br><code># ./cluster.sh start</code></li><li>集群停止<br><code># ./cluster.sh stop</code></li></ul>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Hadoop </tag>
            
            <tag> shell </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>2017，再见。你好，2018</title>
      <link href="/2018/01/01/Hello2018/"/>
      <url>/2018/01/01/Hello2018/</url>
      
        <content type="html"><![CDATA[<p>2017，再见。你好，2018。</p><p>2017年，从头失败到脚的一年。<br>从1600公里到0，再从0到正无穷，之间充满了太多的无奈。<br>不管怎样，还是要感谢过去的一年里陪伴我的人，支持我的人，帮助过我的人，想念着我的人，有你们在，真好。</p><p>今天一月一日，是新的一天，也是新的一周，又是新的一月，还是新的一年。<br>在此写下2018年的一些目标：</p><ol><li>至少读12本书，也就是至少每月读一本书（人丑就要多读书。电子版，纸质都行）；</li><li>进行一次说走就走的旅行（单人也行，和朋友一块亦可，去哪里都无所谓）；</li><li>培养一项业余爱好（希望是乐器）；</li><li>找到自己的另一半（这个估计有点悬）；</li><li>工资翻倍。</li></ol><p>借用张嘉佳的《从你的全世界路过》中的一句话：</p><blockquote><p>照顾好自己，爱自己才能爱好别人。如果你压抑，痛苦，忧伤，不自由，又怎么可能在心里腾出温暖的房间，让重要的人住在里面。如果一颗心千疮百孔，住在里面的人就会被雨水打湿。</p></blockquote><p>山小杰你这个傻逼，2018年，照顾好自己。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hello2018/180101/7bDCdF973E.jpeg" alt="mark"></p>]]></content>
      
      
      <categories>
          
          <category> 杂记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 杂记 </tag>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop-3.0.0体验</title>
      <link href="/2017/12/22/Hadoop3Install/"/>
      <url>/2017/12/22/Hadoop3Install/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>距离Hadoop 3.0.0 GA版的发布已经过去好多天了，前两天太忙，今天终于有点时间，配置了下Hadoop 3.0.0单机版。这篇文章就来介绍一下Hadoop 3.0.0相比Hadoop 2.7.x的一些比较明显的变化，以及部署过程中需要注意的一些地方。另外，本文含有大量图片，流量党慎入！</p><p>从2.x到3.x一个大版本的跨度，修改的地方还是很多的，比如jdk要求从7升级到了8、一些shell脚本重写、支持部署2个以上的NameNode节点、服务端口更改等等，具体的功能改进我就不一一说了，官网上都有：<a href="https://hadoop.apache.org/docs/r3.0.0/index.html">Hadoop3.0介绍</a></p><p>下面是Hadoop从2.7.x -&gt; 3.0.0部分服务端口的调整情况，具体可以去<a href="https://issues.apache.org/jira/browse/HDFS-9427">HDFS-9427</a>和<a href="https://issues.apache.org/jira/browse/HADOOP-12811">HADOOP-12811</a>查看：</p><blockquote><p>Namenode ports: 50470 –&gt; 9871, 50070 –&gt; 9870, 8020 –&gt; 9820<br>Secondary NN ports: 50091 –&gt; 9869, 50090 –&gt; 9868<br>Datanode ports: 50020 –&gt; 9867, 50010 –&gt; 9866, 50475 –&gt; 9865, 50075 –&gt; 9864</p></blockquote><p>部署包bin目录文件:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/mE8HIj9IEf.png" alt="bin"><br>sbin目录文件:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/46bC35lae1.png" alt="sbin"><br>配置文件目录与2.7.3对比(左边2.7.3，右边3.0.0):<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/56LhDADkCf.png" alt="conf"></p><h1 id="Hadoop3-0单机版不靠谱配置"><a href="#Hadoop3-0单机版不靠谱配置" class="headerlink" title="Hadoop3.0单机版不靠谱配置"></a>Hadoop3.0单机版不靠谱配置</h1><p>注意标题，<strong>不靠谱配置</strong>！！！</p><p>部署过程也不细说了，跟之前差不多，配置文件名称除了<strong>节点配置文件</strong>由<strong>slaves</strong>改为了<strong>workers</strong>，其他都没变。这里就直接放基本配置信息了:</p><ol><li><strong>hadoop-env.sh</strong><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/java/jdk1.8.0_131</span><br></pre></td></tr></table></figure></li><li><strong>core-site.xml</strong><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master1:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/hadoop/hadoop3/<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><strong>hdfs-site.xml</strong><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><strong>mapred-site.xml</strong><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><strong>yarn-site.xml</strong><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><strong>workers</strong>–这个配置文件在Hadoop 2.7.x版本的名字是<strong>slaves</strong><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">master1</span><br></pre></td></tr></table></figure></li><li>系统环境变量配置<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_PREFIX=/usr/hadoop/hadoop-3.0.0</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_PREFIX</span>/bin:<span class="variable">$HADOOP_PREFIX</span>/sbin</span><br></pre></td></tr></table></figure></li></ol><h1 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h1><p>配置完了，那就启动吧，启动命令跟之前一样：<code>start-dfs.sh</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/adImBABedl.png" alt="profile"><br>哎，有警告，原来是<strong>HADOOP_PREFIX</strong>不让用了，那就按照提示改成<strong>HADOOP_HOME</strong>：<br>重新配置环境变量如下:</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/hadoop/hadoop-3.0.0</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin</span><br></pre></td></tr></table></figure><p>刷新环境变量后再次启动Hadoop：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/b73igbl3mc.png" alt="dfs-user"><br>报错!!!根据错误信息，发现必须要为这些命令指定一个用户。</p><p>看了一下Hadoop的配置文件，发现<strong>hadoop-env.sh</strong>文件中最后面有一段话：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># To prevent accidents, shell commands be (superficially) locked</span><br><span class="line"># to only allow certain users to execute certain subcommands.</span><br><span class="line"># It uses the format of (command)_(subcommand)_USER.</span><br></pre></td></tr></table></figure><p>即需要在<strong>hadoop-env.sh</strong>文件中新增3行配置：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> HDFS_NAMENODE_USER=root</span><br><span class="line"><span class="built_in">export</span> HDFS_DATANODE_USER=root</span><br><span class="line"><span class="built_in">export</span> HDFS_SECONDARYNAMENODE_USER=root</span><br></pre></td></tr></table></figure><p>如图所示:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/G4Ik8kjIHg.png" alt="set-dfs-user"></p><p>再次执行<code>start-dfs.sh</code>，启动成功：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/c1DjJIGBGG.png" alt="start-dfs"></p><p>然后启动Yarn： <code>start-yarn.sh</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/dB6hcHeE7L.png" alt="yarn-user"><br>报错，所以还需要指定<strong>YARN_RESOURCEMANAGER_USER</strong>和<strong>YARN_NODEMANAGER_USER</strong>这两个用户，继续在<strong>hadoop-env.sh</strong>文件中新增2行配置：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> YARN_RESOURCEMANAGER_USER=root</span><br><span class="line"><span class="built_in">export</span> YARN_NODEMANAGER_USER=root</span><br></pre></td></tr></table></figure><p>如图所示:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/j4aKAaI2B3.png" alt="set-yarn-user"><br>再次启动，成功:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/L428dFh71j.png" alt="start-yarn"></p><p>所以<strong>hadoop-env.sh</strong>文件最终需要配置的是:</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/java/jdk1.8.0_131</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> HDFS_NAMENODE_USER=root</span><br><span class="line"><span class="built_in">export</span> HDFS_DATANODE_USER=root</span><br><span class="line"><span class="built_in">export</span> HDFS_SECONDARYNAMENODE_USER=root</span><br><span class="line"><span class="built_in">export</span> YARN_RESOURCEMANAGER_USER=root</span><br><span class="line"><span class="built_in">export</span> YARN_NODEMANAGER_USER=root</span><br></pre></td></tr></table></figure><h1 id="WEB页面"><a href="#WEB页面" class="headerlink" title="WEB页面"></a>WEB页面</h1><p>由于端口变化，所以NameNode WEB UI 地址为：<code>http://namenode_ip_or_hostname:9870</code></p><p>Overview页面：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/iBKfllaHhg.png" alt="overview"></p><p>Datanodes页面：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/f8Jl3igcK8.png" alt="datanodes"></p><p>Explorer页面(这个页面变化还是挺大的)：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/57FGcB7dC7.png" alt="explorer"><br>可以直接对文件或者文件夹进行删除操作。<br>地址栏右边3个图标作用分别是:</p><ul><li><strong>创建文件夹</strong><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/gL1bhlHjfD.gif" alt="create-dir"></li><li><strong>上传文件</strong><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/hDghfj6fdG.gif" alt="upload-file"></li><li><strong>剪切文件</strong></li></ul><p><strong>勾选</strong>你要进行剪切的文件，点击<strong>Cut</strong>，网页会提示你操作文件或文件夹的个数，然后找到目标位置，点击<strong>Paste</strong>即可：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/iB903hAhbI.gif" alt="move-file"></p><p>网页上还可以进行权限、用户、用户组、文件副本数量的设置，不过默认的网页用户是<strong>dr.who</strong>，没有权限进行用户与用户组的设置：</p><ul><li><strong>设置权限</strong><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/KljecidK4h.png" alt="set-permission"></li><li><strong>修改用户</strong><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/fi8kh13424.png" alt="set-file-user1"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/Hd33iABD95.png" alt="set-file-user2"></li><li><strong>修改用户组</strong><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/eAdckHGbAf.png" alt="set-group"></li><li><strong>修改副本数</strong><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/b7I7f3eH08.png" alt="set-rep"><br>由于我这就一个节点，就没有测试这一项。</li></ul><p>点击文件，还可以直接对文件内容进行预览，可以分别查看前32K和后32K：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/lK4hF444Kc.gif" alt="文件预览"></p><p>然后就是Datanode WEB UI 地址了：<a href="http://datanode_ip_or_hostname:9864">http://datanode_ip_or_hostname:9864</a><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/mch50D4061.png" alt="datanode-web"><br>这部分没啥好说的。</p><h1 id="Wordcount"><a href="#Wordcount" class="headerlink" title="Wordcount"></a>Wordcount</h1><p>找个文件进行Wordcount测试：<br><code># yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0.jar wordcount /staroon/input/ /staroon/output/</code><br>日志会有提示：</p><blockquote><p>2017-12-22 11:15:40,838 INFO conf.Configuration: resource-types.xml not found<br>2017-12-22 11:15:40,839 INFO resource.ResourceUtils: Unable to find ‘resource-types.xml’.</p></blockquote><p>不过不影响Job的执行。关于resource-types.xml详细信息，可以去官网查看:<br><a href="https://hadoop.apache.org/docs/r3.0.0/hadoop-yarn/hadoop-yarn-site/ResourceModel.html">https://hadoop.apache.org/docs/r3.0.0/hadoop-yarn/hadoop-yarn-site/ResourceModel.html</a></p><p>计算结果可以直接在网页上看，可以说是非常方便了：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/3K6EaaGCDK.png" alt="job1"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/h6B5fF6HC1.png" alt="job2"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>以上就是对Hadoop3.0.0进行的很小一部分表面上的体验，但还是给了我焕然一新的感觉，安全性、易用性方面都有了很大的提升，尤其是Namenode网页端，上传、移动、删除、预览文件，修改权限等都可以直接在网页上进行，简直太人性化。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hive-1.2.1安装配置</title>
      <link href="/2017/12/09/HiveInstall/"/>
      <url>/2017/12/09/HiveInstall/</url>
      
        <content type="html"><![CDATA[<p>上一篇：<a href="https://blog.holoyoo.com/2017/11/30/HBaseInstall/">HBase安装</a><br>这一篇进行Hive-1.2.1的安装与基本配置。<br>Hive下载：<a href="https://mirror.bit.edu.cn/apache/hive/">点击进入下载Hive</a></p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p><code># tar -zxvf apache-hive-1.2.1-bin.tar.gz -C /usr/hadoop/</code><br><code># cd /usr/hadoop</code><br><code># mv apache-hive-1.2.1-bin hive-1.2.1</code></p><h2 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h2><p><code># vim /etc/profile</code></p><figure class="highlight profile"><table><tr><td class="code"><pre><span class="line">export HIVE_HOME=/usr/hadoop/hive<span class="number">-1.2</span><span class="number">.1</span></span><br><span class="line">export PATH=$PATH:$HIVE_HOME/bin</span><br></pre></td></tr></table></figure><p><code># source /etc/profile</code></p><h2 id="配置hive-env-sh"><a href="#配置hive-env-sh" class="headerlink" title="配置hive-env.sh"></a>配置<code>hive-env.sh</code></h2><p><code># cd $HIVE_HOME/conf</code><br><code># cp hive-env.sh.template hive-env.sh</code><br><code># vim hive-env.sh</code></p><figure class="highlight profile"><table><tr><td class="code"><pre><span class="line">HADOOP_HOME=/usr/hadoop/hadoop<span class="number">-2.7</span><span class="number">.3</span></span><br></pre></td></tr></table></figure><h2 id="配置hive-site-xml（需要新建）"><a href="#配置hive-site-xml（需要新建）" class="headerlink" title="配置hive-site.xml（需要新建）"></a>配置<code>hive-site.xml</code>（需要新建）</h2><p>指定元数据库存储库，需要预先创建好。<br>这里使用<code>Mysql</code>，数据库名为<code>hive</code>，字符集为<code>latin1</code>。<br>为什么不用<code>utf8</code>?<br>你自己试一下就知道了~<br><code># vim hive-site.xml</code></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;jdbc:mysql://master1:3306/hive?createDatabaseIfNotExist=true&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;root&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;123456&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><ol><li>启动前需要确保Hadoop服务已启动!!!</li><li>启动前需要添加<strong><a href="https://dev.mysql.com/downloads/connector/j/">Mysq连接驱动</a></strong>到<code>$HIVE_HOME/lib/</code>目录下!!!    </li></ol><h3 id="启动HiveMetaStore"><a href="#启动HiveMetaStore" class="headerlink" title="启动HiveMetaStore"></a>启动HiveMetaStore</h3><ol><li>直接启动:<br><code># hive --service metastore</code></li><li>后台启动（关闭shell连接依然存在）<br><code># nohup hive --service metastore &gt;&gt; /var/hivelog.log 2&gt;&amp;1 &amp;</code><blockquote><p>默认metastore端口为：9083</p></blockquote></li></ol><h3 id="启动HiveServer2"><a href="#启动HiveServer2" class="headerlink" title="启动HiveServer2"></a>启动HiveServer2</h3><ol><li>直接启动:<br><code># hiveserver2</code></li><li>后台启动<br><code># nohup hiveserver2 &gt;&gt; /var/hivelog.log 2&gt;&amp;1 &amp;</code><blockquote><p>默认hive.server2.thrift.port=10000<br>默认hive.server2.thrift.http.port=10001</p></blockquote></li></ol><p>查看进程<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HiveInstall/171209/k5IfkHlB9E.png" alt="jps"></p><h2 id="Hive命令行工具（推荐使用Beeline）"><a href="#Hive命令行工具（推荐使用Beeline）" class="headerlink" title="Hive命令行工具（推荐使用Beeline）"></a>Hive命令行工具（推荐使用Beeline）</h2><h3 id="使用hive-cli"><a href="#使用hive-cli" class="headerlink" title="使用hive cli"></a>使用hive cli</h3><p><code># hive</code></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@master1 conf]# hive</span><br><span class="line">Logging initialized using configuration in jar:file:/usr/hadoop/hive-1.2.1/lib/hive-common-1.2.1.jar!/hive-log4j.properties</span><br><span class="line">hive&gt;</span><br><span class="line">创建数据库:</span><br><span class="line">hive&gt; create database test;</span><br><span class="line">hive&gt; use test；</span><br><span class="line">创建people表:</span><br><span class="line">hive&gt; create table people(name string, age bigint, adress string) row format delimited fields terminated by &#x27;\t&#x27;;</span><br><span class="line">加载数据到people表:</span><br><span class="line">hive&gt; load data inpath &#x27;/upload/word.txt&#x27; overwrite into table people;</span><br><span class="line">查询sql:</span><br><span class="line">hive&gt; select * from people;</span><br></pre></td></tr></table></figure><h3 id="使用Beeline"><a href="#使用Beeline" class="headerlink" title="使用Beeline"></a>使用Beeline</h3><p>需要确保hiveserver2服务已启动。<br><code># beeline</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HiveInstall/171209/CHb28B0li4.png" alt="beeline"></p><p>退出beeline:<code>!q</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HiveInstall/171209/bdLJGh9d3B.png" alt="exit"></p><h2 id="OVER"><a href="#OVER" class="headerlink" title="OVER"></a>OVER</h2><p>Hive安装部分已结束！</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HBase-1.2.6高可用配置</title>
      <link href="/2017/11/30/HBaseInstall/"/>
      <url>/2017/11/30/HBaseInstall/</url>
      
        <content type="html"><![CDATA[<p>接上一篇:<a href="https://blog.holoyoo.com/2017/11/18/HadoopInstall/">Hadoop安装</a><br>这一篇进行HBase-1.2.6(高可用)的安装与基本配置。<br>HBase下载：<a href="https://mirror.bit.edu.cn/apache/hbase/">点击进入下载</a></p><p>HBase相关服务分配：</p><table><thead><tr><th align="center">Hostname</th><th align="center">HMaster</th><th align="center">Backup Master</th><th align="center">HRegionServer</th></tr></thead><tbody><tr><td align="center">master1</td><td align="center">1</td><td align="center"></td><td align="center"></td></tr><tr><td align="center">master2</td><td align="center"></td><td align="center">1</td><td align="center"></td></tr><tr><td align="center">worker1</td><td align="center"></td><td align="center"></td><td align="center">1</td></tr><tr><td align="center">worker2</td><td align="center"></td><td align="center"></td><td align="center">1</td></tr></tbody></table><h2 id="安装HBase-所有节点"><a href="#安装HBase-所有节点" class="headerlink" title="安装HBase(所有节点)"></a>安装HBase(所有节点)</h2><p><code># tar -zxvf hbase-1.2.6-bin.tar.gz -C /usr/hadoop/</code></p><h2 id="配置HBase环境变量-所有节点"><a href="#配置HBase环境变量-所有节点" class="headerlink" title="配置HBase环境变量 (所有节点)"></a>配置HBase环境变量 (所有节点)</h2><p><code># vim /etc/profile</code></p><figure class="highlight profile"><table><tr><td class="code"><pre><span class="line">export HBASE_HOME=/usr/hadoop/hbase<span class="number">-1.2</span><span class="number">.6</span></span><br><span class="line">export PATH=$PATH:$HBASE_HOME/bin</span><br></pre></td></tr></table></figure><p><code># source /etc/profile</code></p><h2 id="修改hbase-env-sh"><a href="#修改hbase-env-sh" class="headerlink" title="修改hbase-env.sh"></a>修改<code>hbase-env.sh</code></h2><p>进入到HBase配置文件目录:<br><code># cd /usr/hadoop/hbase-1.2.6/conf</code><br><code># vim hbase-env.sh</code></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_131</span><br><span class="line">export HBASE_MANAGES_ZK=false    # 不使用hbase内置的zookeper</span><br></pre></td></tr></table></figure><h2 id="修改regionservers"><a href="#修改regionservers" class="headerlink" title="修改regionservers"></a>修改<code>regionservers</code></h2><p><code># vim regionservers</code><br>删除:localhost</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">worker1</span><br><span class="line">worker2</span><br></pre></td></tr></table></figure><h2 id="配置backup-masters-默认没有-需要新建"><a href="#配置backup-masters-默认没有-需要新建" class="headerlink" title="配置backup-masters(默认没有,需要新建)"></a>配置<code>backup-masters</code>(默认没有,需要新建)</h2><p><code># vim backup-masters</code></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">master2    # 备用master的hostname</span><br></pre></td></tr></table></figure><h2 id="修改hbase-site-xml"><a href="#修改hbase-site-xml" class="headerlink" title="修改hbase-site.xml"></a>修改<code>hbase-site.xml</code></h2><p><code># vim hbase-site.xml</code></p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://ns1/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>master1,master2,worker1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="把hadoop的hdfs-site-xml和core-site-xml复制到hbase-conf下"><a href="#把hadoop的hdfs-site-xml和core-site-xml复制到hbase-conf下" class="headerlink" title="把hadoop的hdfs-site.xml和core-site.xml复制到hbase/conf下"></a>把hadoop的<code>hdfs-site.xml</code>和<code>core-site.xml</code>复制到<code>hbase/conf</code>下</h2><p><code># cp /usr/hadoop/hadoop-2.7.3/etc/hadoop/hdfs-site.xml /usr/hadoop/hbase-1.2.6/conf/</code><br><code># cp /usr/hadoop/hadoop-2.7.3/etc/hadoop/core-site.xml /usr/hadoop/hbase-1.2.6/conf/</code></p><h2 id="复制hbase-conf文件夹里的内容到其他节点"><a href="#复制hbase-conf文件夹里的内容到其他节点" class="headerlink" title="复制hbase/conf文件夹里的内容到其他节点"></a>复制<code>hbase/conf</code>文件夹里的内容到其他节点</h2><p><code># scp * root@master2:/usr/hadoop/hbase-1.2.6/conf</code><br><code># scp * root@worker1:/usr/hadoop/hbase-1.2.6/conf</code><br><code># scp * root@worker2:/usr/hadoop/hbase-1.2.6/conf</code></p><h2 id="启动hbase-在master上执行，其它机器不需要执行"><a href="#启动hbase-在master上执行，其它机器不需要执行" class="headerlink" title="启动hbase (在master上执行，其它机器不需要执行)"></a>启动hbase (在master上执行，其它机器不需要执行)</h2><p>启动之前需要确保Hadoop和Zookeeper集群已启动!!!<br>启动hbase：<br><code># start-hbase.sh</code><br>检查hbase启动情况：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HBaseInstall/171130/CdeHaKFG5k.png" alt="jps"><br>访问网页查看<br><strong>Master</strong>:<code>http://hm-ip:16010/master-status</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HBaseInstall/171130/KFHK2fmG3e.png" alt="hmaster"><br><strong>Backup Master</strong>: <code>http://bak-hm-ip:16010/master-status</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HBaseInstall/171130/l39HE00gI2.png" alt="bak-master"><br><strong>RegionServer</strong>: <code>http://rs-ip:16030/rs-status</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HBaseInstall/171130/2c1G28l77d.png" alt="rs"></p><h2 id="测试Master高可用"><a href="#测试Master高可用" class="headerlink" title="测试Master高可用"></a>测试Master高可用</h2><p>kill掉master1上的HMaster进程<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HBaseInstall/171130/FfmH2leGh1.png" alt="kill"><br>去网页查看，master2已经变为Master状态<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HBaseInstall/171130/eBc9B4c664.png" alt="ha"><br>高可用测试成功!</p><h2 id="OVER"><a href="#OVER" class="headerlink" title="OVER"></a>OVER</h2><p>HBase的安装部分已结束!</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> 高可用 </tag>
            
            <tag> HBase </tag>
            
            <tag> HA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop-2.7.3高可用配置</title>
      <link href="/2017/11/18/HadoopInstall/"/>
      <url>/2017/11/18/HadoopInstall/</url>
      
        <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p><a href="https://blog.holoyoo.com/2017/11/05/SetEnv/">前一篇文章</a>已经大致介绍了安装Hadoop需要的一些环境准备工作，这篇文章就来进行下原生Hadoop（完全分布式+高可用）的安装与配置。</p><p>Hadoop Namenode存在单点故障问题，Hadoop2.0版本以后可以开启两个Namenode来解决这个问题，一个为Active Namenode管理集群，一个为Standby Namenode作为热备份。</p><p>Standby Namenode节点与Active Namenode节点之间数据的同步依赖于JournalNode服务。<br>Zookeeper和ZKFC(ZKFailoverController)服务可以保证集群中有且只有一个Active状态的Namenode。</p><p>本文同时配置了<code>NameNode</code>和<code>Resource Manager</code>的高可用(HA)。</p><p>Zookeeper下载：<a href="https://mirror.bit.edu.cn/apache/zookeeper/">点击进入下载Zookeeper</a><br>Hadoop下载：<a href="https://mirror.bit.edu.cn/apache/hadoop/common/">点击进入下载Hadoop</a></p><p>注：本文使用的</p><blockquote><p>Zookeeper版本为3.4.10<br>Hadoop版本为2.7.3   </p></blockquote><h2 id="Zookeeper安装与配置"><a href="#Zookeeper安装与配置" class="headerlink" title="Zookeeper安装与配置"></a>Zookeeper安装与配置</h2><p>需要部署奇数(2N+1)个Zookeeper服务，至少3个，3个节点应该具有相同的硬件配置。</p><h3 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h3><p><code># tar -zxvf zookeeper-3.4.10.tar.gz -C /usr/hadoop/</code></p><h3 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h3><p><code># vim /etc/profile</code></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export ZOOKEEPER_HOME=/usr/hadoop/zookeeper-3.4.10</span><br><span class="line">export PATH=$PATH:$ZOOKEEPER_HOME/bin</span><br></pre></td></tr></table></figure><p><code># source /etc/profile</code></p><h3 id="配置Zookeeper"><a href="#配置Zookeeper" class="headerlink" title="配置Zookeeper"></a>配置Zookeeper</h3><p><code># cd /usr/hadoop/zookeeper-3.4.10/conf</code><br><code># cp zoo_sample.cfg zoo.cfg</code><br><code># vim zoo.cfg</code></p><figure class="highlight profile"><table><tr><td class="code"><pre><span class="line">tickTime=<span class="number">2000</span></span><br><span class="line">initLimit=<span class="number">10</span></span><br><span class="line">syncLimit=<span class="number">5</span></span><br><span class="line"># 数据存放位置</span><br><span class="line">dataDir=/hadoop/zookeeper/zkdata</span><br><span class="line"># 日志存放位置</span><br><span class="line">dataLogDir=/hadoop/zookeeper/zklog</span><br><span class="line"># 端口</span><br><span class="line">clientPort=<span class="number">2181</span></span><br><span class="line"># 指定部署Zookeeper的三个节点</span><br><span class="line">server.1=master1:<span class="number">2888</span>:<span class="number">3888</span></span><br><span class="line">server.2=master2:<span class="number">2888</span>:<span class="number">3888</span></span><br><span class="line">server.3=worker1:<span class="number">2888</span>:<span class="number">3888</span></span><br></pre></td></tr></table></figure><h4 id="创建文件夹"><a href="#创建文件夹" class="headerlink" title="创建文件夹"></a>创建文件夹</h4><p><code># mkdir -p /hadoop/zookeeper/zkdata</code><br><code># mkdir /hadoop/zookeeper/zklog</code></p><h4 id="创建myid"><a href="#创建myid" class="headerlink" title="创建myid"></a>创建<code>myid</code></h4><p>在<code>/hadoop/zookeeper/zkdata</code>下创建文件<code>myid</code><br>编辑内容为当前server数值(1,2,3)，需要与上面<code>zoo.cfg</code>中的配置相对应：</p><blockquote><p>master1节点 -&gt; 1<br>master2节点 -&gt; 2<br>worker1节点 -&gt; 3   </p></blockquote><p><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171118/JclclJk8dE.png" alt="zk-myid"></p><h2 id="Hadoop安装与配置"><a href="#Hadoop安装与配置" class="headerlink" title="Hadoop安装与配置"></a>Hadoop安装与配置</h2><h3 id="解压-1"><a href="#解压-1" class="headerlink" title="解压"></a>解压</h3><p><code># tar -zxvf hadoop-2.7.3.tar.gz -C /usr/hadoop/</code><br>进入配置文件目录<br><code># cd /usr/hadoop/hadoop-2.7.3/etc/hadoop/</code></p><h3 id="配置core-site-xml"><a href="#配置core-site-xml" class="headerlink" title="配置core-site.xml"></a>配置<code>core-site.xml</code></h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定hdfs nameservice --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://ns1/<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 开启垃圾回收站功能，值为检查点被删除的分钟数，设为0为禁用 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1440<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定hadoop数据文件夹 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/hadoop/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定Zookeeper地址及端口 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>master1:2181,master2:2181,worker1:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="配置hdfs-site-xml"><a href="#配置hdfs-site-xml" class="headerlink" title="配置hdfs-site.xml"></a>配置<code>hdfs-site.xml</code></h3><p>说明: 启用 NameNode HA的话,不再需要开启Secondary NameNode</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>ns1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.ns1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>nn1,nn2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.ns1.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>master1:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.ns1.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>master1:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.ns1.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>master2:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.ns1.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>master2:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定JN节点 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>qjournal://master1:8485;master2:8485;worker1:8485/ns1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定JN数据在本地磁盘的存放位置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.journalnode.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/hadoop/hadoop/edits<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 开启NameNode自动故障切换 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 配置自动故障切换实现方式 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.proxy.provider.ns1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.methods<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span></span><br><span class="line">    sshfence  </span><br><span class="line">    shell(/bin/true)  </span><br><span class="line">    <span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>/root/.ssh/id_rsa<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.ssh.connect-timeout<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>30000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 配置block副本数 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="配置yarn-site-xml"><a href="#配置yarn-site-xml" class="headerlink" title="配置yarn-site.xml"></a>配置<code>yarn-site.xml</code></h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 启用RM高可用 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 自定义RM的id --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.cluster-id<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>yrc<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.rm-ids<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>rm1,rm2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定分配RM服务的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>master1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>master2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>master1:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>master2:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定zk集群地址 --&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.zk-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>master1:2181,master2:2181,worker1:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="配置marped-site-xml"><a href="#配置marped-site-xml" class="headerlink" title="配置marped-site.xml"></a>配置<code>marped-site.xml</code></h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定mr框架为yarn --&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="配置hadoop-env-sh"><a href="#配置hadoop-env-sh" class="headerlink" title="配置hadoop-env.sh"></a>配置<code>hadoop-env.sh</code></h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/java/jdk1.8.0_131</span><br></pre></td></tr></table></figure><h3 id="配置slaves"><a href="#配置slaves" class="headerlink" title="配置slaves"></a>配置<code>slaves</code></h3><p>指定DataNode节点(hostname)</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">worker1</span><br><span class="line">worker2</span><br></pre></td></tr></table></figure><h3 id="将配置好的Hadoop复制到其他节点"><a href="#将配置好的Hadoop复制到其他节点" class="headerlink" title="将配置好的Hadoop复制到其他节点"></a>将配置好的Hadoop复制到其他节点</h3><p><code># scp -r hadoop-2.7.3 root@master2:/usr/hadoop/</code><br><code>...</code></p><h3 id="配置环境变量-1"><a href="#配置环境变量-1" class="headerlink" title="配置环境变量"></a>配置环境变量</h3><p><code># vim /etc/profile</code></p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_PREFIX=/usr/hadoop/hadoop-2.7.3</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_PREFIX</span>/bin:<span class="variable">$HADOOP_PREFIX</span>/sbin</span><br></pre></td></tr></table></figure><p><code># source /etc/profile</code></p><h2 id="集群启动"><a href="#集群启动" class="headerlink" title="集群启动"></a>集群启动</h2><h3 id="启动Zookeeper"><a href="#启动Zookeeper" class="headerlink" title="启动Zookeeper"></a>启动<code>Zookeeper</code></h3><p>在master1,master2,worker1上执行:<br><code># zkServer.sh start</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/eEH6bB7dL2.png" alt="zkStart"><br>查看状态<code># zkServer.sh status</code>，一个leader，两个flower<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/fmjkdD0djD.png" alt="zkStatus"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/L3iD3LaiJC.png" alt="zkStatus1"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/KbcK7FHLfA.png" alt="zkStatus2"></p><h3 id="启动JournalNode"><a href="#启动JournalNode" class="headerlink" title="启动JournalNode"></a>启动<code>JournalNode</code></h3><p>在master1,master2,worker1上执行:<br><code># hadoop-daemon.sh start journalnode</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/2A2310GjGL.png" alt="JNStart"></p><h3 id="格式化HDFS"><a href="#格式化HDFS" class="headerlink" title="格式化HDFS"></a>格式化<code>HDFS</code></h3><p>在master1上格式化namenode:<br><code># hdfs namenode -format</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/IhHdKei9if.png" alt="nn1"><br>在master1上启动namenode:<br><code># hadoop-daemon.sh start namenode</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/FfF56if0i2.png" alt="nnStart"><br>在master2上格式化namenode:<br><code># hdfs namenode -bootstrapStandby</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/bGddejK2jd.png" alt="nn2"></p><h3 id="格式化zkfc"><a href="#格式化zkfc" class="headerlink" title="格式化zkfc"></a>格式化<code>zkfc</code></h3><p>在master1上执行:<br><code># hdfs zkfc -formatZK</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/kj9imci79h.png" alt="zkfc"></p><h3 id="启动HDFS"><a href="#启动HDFS" class="headerlink" title="启动HDFS"></a>启动<code>HDFS</code></h3><p>在master1上执行:<br><code># start-dfs.sh</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/26hKHabgda.png" alt="hdfsStart"></p><h3 id="启动Yarn"><a href="#启动Yarn" class="headerlink" title="启动Yarn"></a>启动<code>Yarn</code></h3><p>在master1上执行:<br><code># start-yarn.sh</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/Fa7KBbeDCI.png" alt="yarn1"><br>在master2上执行:<br><code># yarn-daemon.sh start resourcemanager</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/eKhkHe65JD.png" alt="yarn2"></p><h3 id="启动完成"><a href="#启动完成" class="headerlink" title="启动完成"></a>启动完成</h3><p>Hadoop已经启动完成，可以访问网页：<code>namenode-ip:50070</code>来查看集群状态并浏览集群文件</p><h2 id="验证NameNode高可用"><a href="#验证NameNode高可用" class="headerlink" title="验证NameNode高可用"></a>验证NameNode高可用</h2><p>首先分别访问：<code>master1:50070</code>和<code>master2:50070</code>网页，查看这两个节点的状态：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/HLhmaF5Ih4.png" alt="n1"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/GHHCHBJk8J.png" alt="n2"><br>可以看到，master1节点为active状态。<br>然后我们手动kill掉master1的namenode服务：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/cL625hIgH0.png" alt="kill"><br>去master2:50070网页查看发现master2已经变为active状态：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171203/CdGCb1icCl.png" alt="HATest"><br>我们再手动启动master1的namenode服务：<br><code># hadoop-daemon.sh start namenode</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/CHH7il7318.png" alt="HA2"><br>去master1:50070网页查看，master1处于standby状态<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/E1mEfJ8Lf8.png" alt="HA22"><br>自动故障切换验证成功！！！</p><h2 id="OVER"><a href="#OVER" class="headerlink" title="OVER"></a>OVER</h2><p>至此，Hadoop的部署已经完成，本文给出的配置只是最简单、最基础的配置，其它详细参数配置请参考官网：<a href="https://hadoop.apache.org/docs/r2.7.3/">Apache Hadoop 2.7.3 Doc</a></p><p>当然你也可以测试一下MR任务的执行，跑一个WordCount，这里就不演示了。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> 高可用 </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HA </tag>
            
            <tag> Zookeeper </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop集群搭建系统环境准备</title>
      <link href="/2017/11/05/SetEnv/"/>
      <url>/2017/11/05/SetEnv/</url>
      
        <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Hadoop集群的搭建需要一系列的环境准备，包括操作系统参数的调整以及一些必备软件的安装等。</p><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>硬件配置我就不说了，CDH官网有说明：<a href="https://blog.cloudera.com/blog/2013/08/how-to-select-the-right-hardware-for-your-new-hadoop-cluster/">硬件配置</a></p><p>测试使用嘛，随便搞搞就行。</p><p>操作系统就选用很受欢迎的开源免费的CentOS了。<br>以4个节点的测试集群为例：</p><table><thead><tr><th align="center">ip</th><th align="center">hostname</th></tr></thead><tbody><tr><td align="center">192.168.0.201</td><td align="center">master1</td></tr><tr><td align="center">192.168.0.202</td><td align="center">master2</td></tr><tr><td align="center">192.168.0.203</td><td align="center">worker1</td></tr><tr><td align="center">192.168.0.204</td><td align="center">worker2</td></tr></tbody></table><p>所有节点安装CentOS7-x64操作系统</p><h3 id="修改主机名hostname"><a href="#修改主机名hostname" class="headerlink" title="修改主机名hostname"></a>修改主机名hostname</h3><p><code># vim /etc/hostname</code><br><code>master1</code><br>或者<br><code># hostnamectl set-hostname master1</code><br>查看hostname<br><code># hostname</code></p><h3 id="配置ip"><a href="#配置ip" class="headerlink" title="配置ip"></a>配置ip</h3><p><code># vim /etc/sysconfig/network-scripts/ifcfg-eth33/</code></p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">TYPE</span>=<span class="string">Ethernet</span></span><br><span class="line"><span class="attr">BOOTPROTO</span>=<span class="string">static                # 设置为静态</span></span><br><span class="line"><span class="attr">DEFROUTE</span>=<span class="string">yes</span></span><br><span class="line"><span class="attr">PEERDNS</span>=<span class="string">yes</span></span><br><span class="line"><span class="attr">PEERROUTES</span>=<span class="string">yes</span></span><br><span class="line"><span class="attr">IPV4_FAILURE_FATAL</span>=<span class="string">no</span></span><br><span class="line"><span class="attr">IPV6INIT</span>=<span class="string">yes</span></span><br><span class="line"><span class="attr">IPV6_AUTOCONF</span>=<span class="string">yes</span></span><br><span class="line"><span class="attr">IPV6_DEFROUTE</span>=<span class="string">yes</span></span><br><span class="line"><span class="attr">IPV6_PEERDNS</span>=<span class="string">yes</span></span><br><span class="line"><span class="attr">IPV6_PEERROUTES</span>=<span class="string">yes</span></span><br><span class="line"><span class="attr">IPV6_FAILURE_FATAL</span>=<span class="string">no</span></span><br><span class="line"><span class="attr">IPV6_ADDR_GEN_MODE</span>=<span class="string">stable-privacy</span></span><br><span class="line"><span class="attr">NAME</span>=<span class="string">ens33</span></span><br><span class="line"><span class="attr">DEVICE</span>=<span class="string">ens33</span></span><br><span class="line"><span class="attr">ONBOOT</span>=<span class="string">yes                      # 开机启用</span></span><br><span class="line"><span class="attr">IPADDR</span>=<span class="string">192.168.0.201    # ip地址</span></span><br><span class="line"><span class="attr">GATEWAY</span>=<span class="string">xxx.xxx.xxx.xxx         # 网关</span></span><br><span class="line"><span class="attr">NETMASK</span>=<span class="string">xxx.xxx.xxx.xxx         # 子网掩码</span></span><br><span class="line"><span class="attr">DNS</span>=<span class="string">xxx.xxx.xxx.xxx             # DNS</span></span><br></pre></td></tr></table></figure><p>重启服务<br><code># systemctl restart network</code><br>查看ip<br><code># ip addr</code></p><h3 id="修改Hosts"><a href="#修改Hosts" class="headerlink" title="修改Hosts"></a>修改Hosts</h3><p><code># vim /etc/hosts</code></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">192.168.0.201master1</span><br><span class="line">192.168.0.202master2</span><br><span class="line">192.168.0.203worker1</span><br><span class="line">192.168.0.204worker2</span><br></pre></td></tr></table></figure><h3 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h3><p>Hadoop集群运行需要用到很多端口，关掉防火墙省事些。<br>关闭防火墙:<br><code># systemctl stop firewalld.service</code><br>关闭开机自动启动:<br><code># systemctl disable firewalld.service</code></p><h3 id="关闭SELinux"><a href="#关闭SELinux" class="headerlink" title="关闭SELinux"></a>关闭SELinux</h3><p>编辑<code>/etc/selinux/config</code>文件，将<code>SELINUX=enforcing</code>改为<code>SELINUX=disabled</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/SetEnv/SELinux.png" alt=""></p><h3 id="配置SSH免密码登陆"><a href="#配置SSH免密码登陆" class="headerlink" title="配置SSH免密码登陆"></a>配置SSH免密码登陆</h3><p>1.查看ssh服务状态(CentOS默认已安装并开机自启动的)<br><code># service sshd status</code><br>2.生成私钥和公钥(所有节点都执行)<br><code># ssh-keygen -t rsa</code><br><code># cd ~/.ssh</code><br>3.在master2节点<br><code># cp id_rsa.pub master2.id_rsa.pub</code><br><code># scp master2.id_rsa.pub root@master1:~/.ssh</code><br>4.在worker1节点<br><code># cp id_rsa.pub worker1.id_rsa.pub</code><br><code># scp worker1.id_rsa.pub root@master1:~/.ssh</code><br>5.在worker2节点<br><code># cp id_rsa.pub worker2.id_rsa.pub</code><br><code># scp worker2.id_rsa.pub root@master1:~/.ssh</code><br>6.在master1节点<br>将所有节点的公钥信息保存到主节点下的authorized_keys（新生成的）文件中<br><code># cat id_rsa.pub &gt;&gt; authorized_keys</code><br><code># cat master2.id_rsa.pub &gt;&gt; authorized_keys</code><br><code># cat worker1.id_rsa.pub &gt;&gt; authorized_keys</code><br><code># cat worker2.id_rsa.pub &gt;&gt; authorized_keys</code><br>如图所示:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/SetEnv/ssh1.png" alt=""><br>7.再把authorized_keys文件拷贝到其它节点上去<br><code># scp authorized_keys root@master2:~/.ssh</code><br><code># scp authorized_keys root@worker1:~/.ssh</code><br><code># scp authorized_keys root@worker2:~/.ssh</code><br>8.测试SSH:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/SetEnv/ssh2.png" alt=""></p><h3 id="配置ntp时间同步"><a href="#配置ntp时间同步" class="headerlink" title="配置ntp时间同步"></a>配置ntp时间同步</h3><p>集群中所有节点必须保持时间同步，如果时间相差较大会引起问题(如HBase服务无法正常启动)</p><p>实现方法：master1节点作为ntp服务器，对其它节点提供时间同步服务。 所有其它节点以master1节点为基础同步时间。<br>1.所有节点安装相关ntp组件<br><code># yum install ntp/或者手动安装rpm包</code><br>2.所有节点设置时区,中国上海:<br><code># timedatectl set-timezone Asia/Shanghai</code><br>3.启动ntp，以及设置开机启动<br><code># systemctl start ntpd</code><br><code># systemctl enable ntpd</code><br>4.在master1节点上设置现在的准确时间<br><code># date -s “2017-06-15 09:10:00”</code><br>5.配置ntp服务器(master1节点)<br><code># vim /etc/ntp.conf</code><br>配置示例：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/SetEnv/ntp1.png" alt=""><br>6.在其它节点上设置ntp客户端<br><code># vim /etc/ntp.conf</code><br>配置示例：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/SetEnv/ntp2.png" alt=""><br>7.配置文件修改完毕后，重启ntp服务<br><code># systemctl restart ntpd</code><br>8.在其它节点上手动同步master1的时间<br><code># ntpdate -u 192.168.0.201</code><br>9.查看同步状态(可能需要稍等一会才能同步上)<br><code># ntpstat</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/SetEnv/ntp3.png" alt=""></p><h3 id="禁用Transparent-Hugepage"><a href="#禁用Transparent-Hugepage" class="headerlink" title="禁用Transparent Hugepage"></a>禁用Transparent Hugepage</h3><p>1.查看当前是否启用(启用状态可能会严重降低Hadoop集群性能，CentOS默认启用)<br><code># cat /sys/kernel/mm/transparent_hugepage/enabled</code></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[always] madvise never表示已启用</span><br><span class="line">always madvise [never]表示已禁用</span><br></pre></td></tr></table></figure><p>2.禁用Transparent Hugepage(重启生效):<br><code># vim /etc/rc.local</code></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag</span><br><span class="line">echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</span><br></pre></td></tr></table></figure><p>配置如图：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/SetEnv/trans.png" alt=""><br>3.赋予rc.local文件可执行权限<br><code># chmod +x /etc/rc.d/rc.local</code></p><h3 id="调整vm-swappiness-Linux内核参数"><a href="#调整vm-swappiness-Linux内核参数" class="headerlink" title="调整vm.swappiness Linux内核参数"></a>调整vm.swappiness Linux内核参数</h3><p>该值用于控制从物理内存到磁盘上的虚拟内存的应用数据的交换。值越高，内存交换越积极。值越低，交换的次数越少。</p><p>大多数系统默认为60，但不适用于Hadoop集群，因为即使有足够的内存，Hadoop进程也有可能会被交换到磁盘，影响集群稳定性和性能。</p><p>1.查看当前的参数<br><code># cat /proc/sys/vm/swappiness</code><br><code>30    当前是30，建议设置为1-10之间，最好为1</code><br>2.设置vm.swappiness值为1<br><code># vim /etc/sysctl.conf</code><br><code>vm.swappiness=1</code><br>如图所示:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/SetEnv/vm.png" alt=""></p><h2 id="MySQL-5-6安装"><a href="#MySQL-5-6安装" class="headerlink" title="MySQL 5.6安装"></a>MySQL 5.6安装</h2><p>1.检查MySQL及相关RPM包是否已安装，如果有安装，则移除<br><code># rpm -qa | grep -i mysql</code><br><code># yum -y remove mysql-libxxxx</code><br>2.下载MySQL包：<a href="https://dev.mysql.com/downloads/mysql/5.6.html#downloads">MySQL-5.6.36-1.linux_glibc2.5.x86_64.rpm-bundle.tar</a><br>解压:<br><code># tar -xvf MySQL-5.6.36-1.linux_glibc2.5.x86_64.rpm-bundle.tar</code><br>3.安装mysql-server<br><code># rpm -ivh MySQL-server-5.6.36-1.linux_glibc2.5.x86_64.rpm</code><br>与已安装的软件有冲突，需要卸载有冲突的软件:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/SetEnv/mysql1.png" alt=""><br><code># yum -y remove xxxxxxxxx</code><br>再次安装mysql-server，安装成功，但是下面执行数据库初始化会报错，缺少一个模块<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/SetEnv/mysql2.png" alt=""><br>需要安装autoconf(需要联网或者搭建本地yum仓库或者从CentOS7安装包里拷出autoconf的rpm包及其依赖包，手动安装):<br><code># yum -y install autoconf</code></p><p><strong>说明</strong>：这里有个坑，即最好是先安装autoconf，然后再装mysql-server，这个时候安装程序就会自动进行Mysql初始化。<br>4.安装客户端<br><code># rpm -ivh MySQL-client-5.6.36-1.linux_glibc2.5.x86_64.rpm</code><br>5.初始化mysql(因为安装server之前没有安装autoconf，所以这里需要手动初始化mysql)<br><code># /usr/bin/mysql_install_db</code><br>6.启动mysql服务<br><code># service mysql start</code><br>若无法启动则将<code>/var/lib/mysql</code>目录下所有文件及子文件夹的用户及用户组设置为<strong>mysql</strong><br><code># chown -R mysql:mysql /var/lib/mysql/</code><br>设置开机启动:<br><code># chkconfig mysql on</code><br><code># chkconfig --list | grep mysql</code><br>7.对mysql进行安全设置<br>查看root账户密码:<br><code># cat /root/.mysql_secret</code><br>执行安全设置(需要确保MySQL服务已经正常启动)：<br><code># /usr/bin/mysql_secure_installation</code></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a)修改root用户密码 Y</span><br><span class="line">b)删除匿名账号 Y</span><br><span class="line">c)取消root用户远程登录 N</span><br><span class="line">d)删除test库和对test库的访问权限 Y</span><br><span class="line">e)刷新授权表使修改生效 Y</span><br></pre></td></tr></table></figure><p>8.进入mysql<br><code># mysql -uroot -p</code><br>9.开放远程登陆权限<br><code>mysql&gt; GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;password&#39; WITH GRANT OPTION;</code><br><code>mysql&gt; FLUSH PRIVILEGES;</code><br>10.MySQL的默认安装位置</p><blockquote><p>/var/lib/mysql/ ———-#数据库目录<br>/usr/share/mysql ——–#配置文件目录<br>/usr/bin ——————#相关命令目录<br>/etc/init.d/mysql ———#启动脚本</p></blockquote><p>11.如果需要修改字符集则需配置<code>/etc/my.cnf</code>文件<br>若<code>etc</code>目录下没有该文件则从<code>/usr/share/mysql/</code>下复制一个过来<br><code># cp /usr/share/mysql/my-default.cnf /etc/my.cnf</code><br>查看字符集:</p><blockquote><p>mysql&gt; show variables like ‘%collation%’;<br>mysql&gt; show variables like ‘%char%’;<br>mysql&gt; show create database databaseName;<br>mysql&gt; show create table tableName;</p></blockquote><h2 id="JDK1-8安装"><a href="#JDK1-8安装" class="headerlink" title="JDK1.8安装"></a>JDK1.8安装</h2><p>1.查看系统自带java版本，如果已安装就先卸载掉<br><code># java -version</code></p><p>2.安装Oracle官网下载jdk的rpm安装包，并使用rpm -ivh packageName安装:<br><a href="https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html">Download jdk1.8</a><br>3.修改环境变量<br><code># vim /etc/profile</code><br>添加如下(使用rpm安装的java在/usr/java/jdk1.8XXXX)</p><figure class="highlight profile"><table><tr><td class="code"><pre><span class="line">export JAVA_HOME=/usr/java/jdk1.8.0_131</span><br><span class="line">export JRE_HOME=/usr/java/jdk1.8.0_131/jre</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line">export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH</span><br></pre></td></tr></table></figure><p>4.执行命令使环境变量生效<br><code># source /etc/profile</code><br>5.测试<br><code># java -version</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/SetEnv/java.png" alt=""></p><h2 id="OVER"><a href="#OVER" class="headerlink" title="OVER"></a>OVER</h2><p>至此，Hadoop集群搭建的环境准备部分已结束。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CentOS </tag>
            
            <tag> 大数据 </tag>
            
            <tag> Hadoop </tag>
            
            <tag> MySQL安装 </tag>
            
            <tag> Java安装 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop版本选型</title>
      <link href="/2017/11/05/HadoopSelect/"/>
      <url>/2017/11/05/HadoopSelect/</url>
      
        <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>说到大数据，首先得说一说Hadoop，这个Apache旗下的一个顶级项目，一个分布式的存储、计算系统，适用于超大数据量的存储与计算。<br>Hadoop可以说是大数据生态圈的代名词，有很多基于Hadoop集成开发出来的衍生项目，所以面对众多的Hadoop产品，选择一个合适的产品尤为重要。</p><p>除了原生Hadoop之外，比较受欢迎的开源的可以免费使用的第三方发行版Hadoop有：</p><ul><li><a href="https://www.cloudera.com/products/open-source/apache-hadoop/key-cdh-components.html">Cloudera’s Distribution including Apache Hadoop (CDH)</a></li><li><a href="https://hortonworks.com/products/data-platforms/hdp/">Hortonworks Data Platform (HDP)</a></li></ul><p>所以这篇文章就简单介绍一下原生Hadoop和第三方发行版Hadoop的区别</p><h2 id="Apache-Hadoop原生版本优缺点"><a href="#Apache-Hadoop原生版本优缺点" class="headerlink" title="Apache Hadoop原生版本优缺点"></a>Apache Hadoop原生版本优缺点</h2><p>优点:</p><ul><li>完全开源免费</li><li>社区活跃，版本更新快</li><li>文档、资料详实</li><li>自由度高，可定制性强</li></ul><p>缺点：</p><ul><li>集群部署、安装、配置复杂。通常部署集群需要编写大量的配置文件，分发到每一台节点上，容易出错，效率低下。</li><li>对集群的监控，运维，需要安装第三方监控软件，运维难度较大。</li><li>组件选择与搭配困难。在Hadoop生态圈中，组件的选择、使用，比如Hive，HBase，Spark等等，需要大量考虑兼容性、稳定性的问题。</li></ul><h2 id="第三方发行版Hadoop优缺点"><a href="#第三方发行版Hadoop优缺点" class="headerlink" title="第三方发行版Hadoop优缺点"></a>第三方发行版Hadoop优缺点</h2><p>优点:</p><ul><li>基于Apache协议，100%开源。</li><li>比Apache Hadoop在兼容性、安全性、稳定性上有增强。第三方发行版通常都经过了大量的测试验证，有众多部署实例。</li><li>提供了部署、安装、配置工具，大大提高了集群部署的效率。</li><li>运维简单。提供了管理、监控、诊断、配置修改的工具，管理配置方便，定位问题快速、准确，使运维工作简单，有效。</li></ul><p>缺点:</p><ul><li>自由度低，可定制性低</li><li>由于是集成起来的Hadoop平台，考虑到稳定性和兼容性，所有组件版本相比原生版本都比较低，因此发行版Hadoop可能不具有原生版本的某些新功能、新特性。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>刚开始学习大数据的时候，最好是从原生Hadoop学起，因为必须要对Hadoop的安装、配置、启动有个大概了解。公司转入大数据行业初期可以考虑使用第三方发行版Hadoop，因为部署、管理、运维方便，稳定性、兼容性强。后期如果觉得第三方发行版不能满足功能需要，或者需要定制个性化功能的话，可以再去考虑Apache原生版本Hadoop，自己进行集成开发。</p><p>对于第三方发行版Hadoop，我只用过CDH，觉得还是蛮好用的。特别是调整集群参数的时候，有一个管理工具（<a href="https://www.cloudera.com/downloads/manager/5-13-0.html">Cloudera Manager</a>）是真的方便，原生版本还要手动修改配置文件，再手动分发到其他节点，很容易出差错。</p><p>简单体验过国内上海某公司的发行版Hadoop(?DH)，觉得不如CDH好用，而且收费不开源。有一个社区版，没体验过，不知道跟商业版有什么区别。</p><p>HDP没用过，不做评价，只知道可以使用Apache旗下的一个集群管理工具（<a href="https://ambari.apache.org/">Ambari</a>）来部署和管理。</p><h2 id="OVER"><a href="#OVER" class="headerlink" title="OVER"></a>OVER</h2>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> CDH </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HDP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>给网页加上js特效 - 让网页动起来</title>
      <link href="/2017/08/12/AddCanvas/"/>
      <url>/2017/08/12/AddCanvas/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>刚搭建好的博客网页背景一片惨白，死气沉沉毫无生机，所以就想着给网站加个动态背景什么的，翻了好久，终于在GitHub上找了个可与鼠标互动的js特效：<a href="https://github.com/hustcc/canvas-nest.js">canvas-nest.js</a>。使用起来也很简单，只需要在html代码<code>&lt;body&gt;&lt;/body&gt;</code>标签里面加入一行<code>&lt;script&gt;</code>代码就行了。</p><p>但是，网站只有一两个html页面的话手动添加还可以，如果网站有几十个甚至上百个html页面，而且Hexo框架generate后的文件夹很多，想找到这些html文件还得一个个翻文件夹，手动的话岂不得累死？！！！</p><p>我去GitHub上canvas-nest项目下看了下，只有一个wordpress的插件，并没有hexo插件，hexo插件库里好像也没有添加外部js代码的插件。</p><p><a href="https://hexo.io/zh-cn/docs/plugins.html">Hexo官方文档</a>倒是有一句话：<strong>如果您的代码很简单，建议您编写脚本，您只需要把 JavaScript 文件放到 scripts 文件夹，在启动时就会自动载入。</strong>我试过了，载入的时候会报错，没办法，只好自己写了个shell脚本（Git for Win支持执行Shell脚本），所以就有了这篇文章。</p><h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><p>很简单，先找出hexo generate后存放html文件夹下（public文件夹）的所有html文件路径，然后给这些html文件执行添加js代码命令。</p><p>每次执行<code>hexo g</code>都会重新生成html文件，所以不用担心会重复添加的问题。</p><h2 id="shell代码"><a href="#shell代码" class="headerlink" title="shell代码"></a>shell代码</h2><h4 id="简单版："><a href="#简单版：" class="headerlink" title="简单版："></a>简单版：</h4><p>需要先执行<code>hexo g</code>生成静态网页，<br>再执行shell添加js代码，<br>再执行<code>hexo d</code>部署到github。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">echo &quot;+++++++++++++++ 开始添加js代码 +++++++++++++++&quot;</span><br><span class="line">find public/ -name index.html &gt; add-js.log</span><br><span class="line"></span><br><span class="line">addJs() &#123;</span><br><span class="line">    sed -i &#x27;/&lt;\/body&gt;/i\&lt;script type=&quot;text/javascript&quot; color=&quot;63,81,181&quot; opacity=&#x27;0.7&#x27; zIndex=&quot;-1&quot; count=&quot;180&quot; src=&quot;//cdn.bootcss.com/canvas-nest.js/1.0.1/canvas-nest.min.js&quot;&gt;&lt;\/script&gt;&#x27; $1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">cat add-js.log | while read line</span><br><span class="line">do</span><br><span class="line">    addJs $line</span><br><span class="line">    echo &quot;add success -&gt; $line&quot;</span><br><span class="line">done</span><br><span class="line">echo &quot;+++++++++++++++ 添加js代码完毕 +++++++++++++++&quot;</span><br></pre></td></tr></table></figure><h4 id="懒人版："><a href="#懒人版：" class="headerlink" title="懒人版："></a>懒人版：</h4><p>只不过是把<code>hexo g</code>和<code>hexo d</code>包含进来了而已…<br>一个脚本搞定所有<del>~</del></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">echo &quot;++++++++++++ 开始执行&#123;hexo g&#125;命令 ++++++++++++&quot;</span><br><span class="line">hexo g</span><br><span class="line"></span><br><span class="line">echo &quot;+++++++++++++++ 开始添加js代码 +++++++++++++++&quot;</span><br><span class="line">find public/ -name index.html &gt; add-js.log</span><br><span class="line"></span><br><span class="line">addJs() &#123;</span><br><span class="line">    sed -i &#x27;/&lt;\/body&gt;/i\&lt;script type=&quot;text/javascript&quot; color=&quot;63,81,181&quot; opacity=&#x27;0.7&#x27; zIndex=&quot;-1&quot; count=&quot;180&quot; src=&quot;//cdn.bootcss.com/canvas-nest.js/1.0.1/canvas-nest.min.js&quot;&gt;&lt;\/script&gt;&#x27; $1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">cat add-js.log | while read line</span><br><span class="line">do</span><br><span class="line">    addJs $line</span><br><span class="line">    echo &quot;add success -&gt; $line&quot;</span><br><span class="line">done</span><br><span class="line">echo &quot;+++++++++++++++ 添加js代码完毕 +++++++++++++++&quot;</span><br><span class="line"></span><br><span class="line">echo &quot;++++++++++++ 开始执行&#123;hexo d&#125;命令 ++++++++++++&quot;</span><br><span class="line">hexo d 2&gt;/dev/null</span><br></pre></td></tr></table></figure><h2 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h2><p>复制shell代码，在你的blog目录下新建一个<strong>add-js.sh</strong><br>文件，编辑该文件（编码格式设为<strong>UTF-8</strong>），将刚刚复制的代码粘贴进去，保存。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/AddCanvas/snap0636.png" alt=""></p><p>至于<code>&lt;script&gt;&lt;/script&gt;</code>标签里面的参数含义，可以去GitHub项目<a href="https://github.com/hustcc/canvas-nest.js">canvas-nest.js</a>上了解详细信息。</p><p>写完文章以后，<br><strong>简单版：</strong><br>先执行：<code>hexo g</code><br>再执行：<code>./add-js.sh</code><br>最后执行：<code>hexo d</code></p><p><strong>懒人版：</strong><br>直接执行：<code>./add-js.sh</code></p><p>shell执行完毕后会在当前文件夹生成一个<strong>add-js.log</strong>文件，里面存放的是public目录下所有<strong>index.html</strong>的路径。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/AddCanvas/snap0637.png" alt=""></p><p>控制台会也输出哪些文件被修改了：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/AddCanvas/snap0638.png" alt=""></p><p>搞定！！！</p><p>另外，我这Linux Shell是刚学的，代码肯定还能再优化。但是，这又不是不能用，总比手动快多了，手动滑稽~</p>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 博客搭建 </tag>
            
            <tag> Hexo </tag>
            
            <tag> js样式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>利用GitHub Pages + Hexo框架搭建个人博客</title>
      <link href="/2017/07/30/HexoInstall/"/>
      <url>/2017/07/30/HexoInstall/</url>
      
        <content type="html"><![CDATA[<p>+++本文全部是在Windows10平台联网环境下操作的+++</p><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><h4 id="安装Node-js"><a href="#安装Node-js" class="headerlink" title="安装Node.js"></a>安装<a href="https://nodejs.org/en/download/">Node.js</a></h4><p>Hexo是基于Node.js的静态博客框架，所以需要安装这个。官网下载msi安装程序（我用的是node-v6.10.3-x64.msi）安装，同时安装过程中不要忘了勾选Add  to PATH选项，用来添加系统环境变量:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0574.png" alt=""></p><h4 id="安装Git-for-Win"><a href="#安装Git-for-Win" class="headerlink" title="安装Git for Win"></a>安装<a href="https://github.com/waylau/git-for-win">Git for Win</a></h4><p>Git可以很方便的提交代码到GitHub仓库中。由于众所周知的原因，官网下载Git会很慢，所以我找了个国内下载源。<br>Git安装（全部默认即可）完成后开始菜单会有个Git文件夹，我们需要用到的是Git Bash:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0575.png" alt=""></p><h4 id="注册GitHub账号"><a href="#注册GitHub账号" class="headerlink" title="注册GitHub账号"></a>注册<a href="https://github.com/">GitHub账号</a></h4><p>因为需要用到GitHub的GitHub Pages功能，所以需要有一个GitHub账号。还有，没有GitHub账号的程序员不是一个合格的程序员！</p><h4 id="Git配置"><a href="#Git配置" class="headerlink" title="Git配置"></a>Git配置</h4><p>1.配置账户：<br>打开Git Bash，输入以下两条命令(name替换成你的github用户名，email替换成你注册github时用的邮箱):<br><code>git config --global user.name &quot;name&quot;</code><br><code>git config --global user.email &quot;email&quot;</code></p><p>可以使用<code>git config --list</code>命令来查看当前的配置信息，可以看到<code>user.name</code>和<code>user.email</code>已经出现在了最后两行:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0577.png" alt=""><br>如果你发现信息输入有误，重新执行上面两条命令即可。</p><p>2.配置SSH密钥：<br>打开Git Bash，确保当前位置是用户工作目录，也就是:<strong>~</strong>这个位置：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0600.png" alt=""><br>不在这个位置的话可以输入：<br><code>cd ~</code><br>进入这个目录<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0602.png" alt=""><br>可以看到，这个目录其实是对应电脑上<strong>C:\Users\用户名</strong>这个位置。<br>执行下面的命令来生成ssh密钥文件：<br><code>ssh-keygen -t rsa -C &quot;email&quot;</code><br>email替换成你注册github时用的邮箱。<br>一路回车，过程中让你输入东西的时候不要输入，直接回车，使用默认即可，完后当前目录<br>会多出一个名叫<strong>.ssh</strong>的文件夹，我们进入这个文件夹：<br><code>cd .ssh</code><br>里面有两个密钥文件：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0603.png" alt=""><br>不带<code>.pub</code>后缀的是私钥，带<code>.pub</code>后缀的是公钥，私钥我们要自己保存好，不要泄露出去，公钥是可以公开分享的。<br>然后我们把公钥里面的内容全部复制出来，可以使用cat命令使密钥内容显示出来再复制，也可以使用文本编辑器（不推荐使用记事本）打开再复制：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0604.png" alt=""></p><p>再然后登陆我们前面注册的github账号，点击头像，进入设置<br>找到<strong>SSH and GPG keys</strong>，点击右侧的<strong>New SSH key</strong>：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0605.png" alt=""><br><strong>Title</strong>随便填，把我们刚才复制的公钥内容粘贴进<strong>Key</strong>下面的输入框内，点击<strong>Add SSH key</strong><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0606.png" alt=""></p><p>最后测试一下SSH<br>命令行执行：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0609.png" alt=""><br>第一次执行这个命令的话程序会问你是否要继续进行连接，输入<code>yes</code>回车就好。<br>然后控制台输出：<br><code>Hi Staroon! You&#39;ve successfully authenticated, but GitHub does not provide shell access.</code><br>说明SSH密钥配置成功！！！</p><h4 id="创建本地Git仓库"><a href="#创建本地Git仓库" class="headerlink" title="创建本地Git仓库"></a>创建本地Git仓库</h4><p>我这里把它建在了D盘，所有文件夹名字都是可以自定义的。打开Git Bash:<br><code>cd \d:</code><br><code>mkdir git_repository</code><br>创建我们的博客文件夹：<br><code>cd git_repository</code><br><code>mkdir blog</code><br>进入blog文件夹：<br><code>cd blog</code><br>这是我电脑上的blog文件夹全路径: <strong>/d/git_repository/blog</strong></p><h2 id="部署Hexo"><a href="#部署Hexo" class="headerlink" title="部署Hexo"></a>部署Hexo</h2><h4 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h4><p>打开Git Bash，执行下面的命令:<br><code>npm install -g hexo-cli</code><br>稍等一会儿，不要着急，会开始自动下载安装:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0579.png" alt=""><br>可能会报下面的两个警告，不用理会，我还没发现有什么影响。</p><blockquote><p><code>npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@^1.0.0 (node_modules\hexo-cli\node_modules\chokidar\node_modules\fsevents):</code><br><code>npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.1.2: wanted &#123;&quot;os&quot;:&quot;darwin&quot;,&quot;arch&quot;:&quot;any&quot;&#125; (current: &#123;&quot;os&quot;:&quot;win32&quot;,&quot;arch&quot;:&quot;x64&quot;&#125;)</code>   </p></blockquote><p>可以使用<code>hexo -v</code>命令测试是否安装成功:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0580.png" alt=""></p><h4 id="初始化Hexo"><a href="#初始化Hexo" class="headerlink" title="初始化Hexo"></a>初始化Hexo</h4><p>进入blog文件夹，空白处鼠标右键，点击Git Bash Here进入命令窗口，执行初始化命令：<br><code>hexo init</code><br>等待初始化完成…<br>最后会有一句: </p><blockquote><p><code>INFO  Start blogging with Hexo!</code></p></blockquote><p>然后执行:<br><code>npm install</code><br>等待执行结束，初始化成功！现在就已经可以开始使用Hexo了！！！</p><p>但是还有一些插件最好提前装上：</p><ul><li>索引生成器：<code>npm install hexo-generator-index --save</code></li><li>归档生成器：<code>npm install hexo-generator-archive --save</code></li><li>分类生成器：<code>npm install hexo-generator-category --save</code></li><li>标签生成器：<code>npm install hexo-generator-tag --save</code></li><li>本地搜索: <code>npm install hexo-generator-search --save</code></li><li>本地化服务：<code>npm install hexo-server --save</code></li><li>Git部署功能：<code>npm install hexo-deployer-git --save</code></li><li>渲染器：<code>npm install hexo-renderer-marked --save</code></li><li>渲染器：<code>npm install hexo-renderer-stylus --save</code></li><li>置顶功能：<code>npm install hexo-helper-post-top --save</code></li><li>二维码分享: <code>npm install hexo-helper-qrcode --save</code></li><li>站点地图: <code>npm install hexo-generator-seo-friendly-sitemap --save</code></li></ul><p>初始化完成后的文件夹结构是这样的:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0581.png" alt=""></p><p>关于该目录下的文件及文件夹说明，查看<a href="https://hexo.io/zh-cn/docs/setup.html">hexo官方文档</a>即可。</p><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>配置文件<code>_config.yml</code>，具体的配置信息还是去<a href="https://hexo.io/zh-cn/docs/configuration.html">hexo官方文档</a>看吧。</p><p>建议用专业的文本编辑器编辑该文件，不要用Win自带的记事本。我用的是EditPlus.</p><h2 id="开始写文章"><a href="#开始写文章" class="headerlink" title="开始写文章"></a>开始写文章</h2><p>参考<a href="https://hexo.io/zh-cn/docs/writing.html">hexo官方文档</a>挺好，突然发现官方文档挺详细。。。<br>说明一下，官方文档里新建文章的命令是:<br><code>hexo new [layout] &lt;title&gt;</code><br><code>[layout]</code>默认为<code>post</code>，可以不用加<code>[layout]</code>命令。<br>比如我想新建一个名叫<code>helloHexo</code>的文章，直接命令：<br><code>hexo new &quot;helloHexo&quot;</code><br>即可，然后控制台会输出该文档位置信息：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0591.png" alt=""><br>进入存放我们文章的文件夹，可以看到我们的<code>helloHexo.md</code>已经在这了，另外还有一个<code>hello-word.md</code>文件，这里面写的是一些常用hexo命令，可以删掉这个文件。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0592.png" alt=""><br>用文本编辑器或者Markdown编辑器打开<code>helloHexo.md</code>就可以写文章啦~~<br>我正在用的Markdown编辑器是：<a href="https://code.visualstudio.com/">Visual Studio Code</a></p><p>打开该文件，里面已经有一部分内容了：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0593.png" alt=""></p><p>这一部分内容官方称为<a href="https://hexo.io/zh-cn/docs/front-matter.html">Front-matter</a>，可以参考官方文档补充这一部分的内容。</p><p>三道杠<code>---</code>下面的空白地方就是我们要写文章内容的部分了，全部使用Markdown语法。</p><p>一些Markdown语法：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0594.png" alt=""></p><p>文章写完了，先预览一下吧~~<br>这就需要用到我们之前装的server插件了<br>命令行输入：<br><code>hexo server</code><br>启动本地服务器：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0595.png" alt=""></p><p>浏览器访问 <code>http://localhost:4000/</code> 就可以看到最原始状态的博客啦~<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0596.png" alt=""></p><p>说明：同样的Markdown语法在不同的网站上可能会显示出不同的效果，不过没关系，只要能在Github上显示出我们想要的效果就行了，因为我们的目的就是把博客部署在Github上！</p><p>默认的主题太丑？<br>hexo有很多第三方主题，如何配置使用可以去各主题官网查看。</p><p>如何搜索主题？<br>Github上搜索关键字<code>hexo theme</code>一大堆主题</p><p>至此，本地博客已经搭建完成！</p><h2 id="部署博客到GitHub"><a href="#部署博客到GitHub" class="headerlink" title="部署博客到GitHub"></a>部署博客到GitHub</h2><h4 id="创建Github仓库"><a href="#创建Github仓库" class="headerlink" title="创建Github仓库"></a>创建Github仓库</h4><p>仓库名字一定要是：<strong>{github username}.github.io</strong><br>比如我的github用户名是<strong>Staroon</strong>，则仓库名字为：<strong>Staroon.github.io</strong><br>用户名即是Owner那里的用户名<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0599.png" alt=""></p><h4 id="部署配置"><a href="#部署配置" class="headerlink" title="部署配置"></a>部署配置</h4><p>配置<code>_config.yml</code>文件。<br>翻到最下面找到<strong>deploy</strong>这一项，填写：</p><blockquote><p>type: git<br>repo: <a href="mailto:git@github.com">git@github.com</a>:<strong>{username}</strong>/<strong>{username}</strong>.github.io.git<br>branch: master   </p></blockquote><p>如下图所示<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0607.png" alt=""></p><h4 id="博客发布"><a href="#博客发布" class="headerlink" title="博客发布"></a>博客发布</h4><p>命令行执行：<br><code>hexo g</code><br>然后执行：<br><code>hexo d</code><br>当控制台输出：<code>INFO  Deploy done: git</code>的时候，说明项目已经成功的发布到github上，耐心等待一会儿，就可以通过访问<strong>{username}.github.io</strong>来访问博客了~~</p><h4 id="博客更新"><a href="#博客更新" class="headerlink" title="博客更新"></a>博客更新</h4><p><code>hexo new &quot;name&quot;</code>或者直接在<strong>/source/_posts/</strong>里面新建<code>.md</code>文件<br>写完Markdown文章后，执行：<br><code>hexo g -d</code><br>即可一键部署。</p><p>每次博客内容有改动都可以使用<code>hexo g -d</code>进行部署。</p><p>至此，博客搭建教程已经全部完成！</p><h2 id="注册个人域名"><a href="#注册个人域名" class="headerlink" title="注册个人域名"></a>注册个人域名</h2><p>找个正规的域名厂商注册即可。<br>我是在<a href="https://sg.godaddy.com/zh/">GoDaddy</a>上注册的。</p><h2 id="将个人域名与博客绑定"><a href="#将个人域名与博客绑定" class="headerlink" title="将个人域名与博客绑定"></a>将个人域名与博客绑定</h2><h4 id="DNS设置"><a href="#DNS设置" class="headerlink" title="DNS设置"></a>DNS设置</h4><p>国内推荐使用<a href="https://www.dnspod.cn/">DNSPod</a><br>国外的话可以使用<a href="https://www.cloudflare.com">Cloudflare</a>，可以免费使用https。</p><p>这里以DNSPod为例：<br>注册登录，在<strong>域名解析</strong>里面<strong>添加域名</strong><br>将上面注册的域名添加进去<br>然后点击<strong>添加纪录</strong>添加3条记录，如下图所示：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0610.png" alt=""><br>两条A记录指向的IP分别是：</p><ul><li>192.30.252.153</li><li>192.30.252.154</li></ul><p>CNAME记录指向的是你的原博客地址:<strong>{username}.github.io</strong></p><h4 id="域名服务器设置"><a href="#域名服务器设置" class="headerlink" title="域名服务器设置"></a>域名服务器设置</h4><p>这里以GoDaddy为例：<br>进入<strong>我的产品</strong>页，找到要管理的域名，点击<strong>DNS</strong>进入DNS管理页面：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0611.png" alt=""></p><p>然后找到<strong>域名服务器</strong>点击<strong>更改</strong>：</p><p><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0612.png" alt=""></p><p>将域名服务器修改为DNSPod提供的域名服务器即可。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0613.png" alt=""></p><h4 id="博客内设置"><a href="#博客内设置" class="headerlink" title="博客内设置"></a>博客内设置</h4><p>在博客<strong>source</strong>目录下，新建一个<strong>CNAME</strong>文件<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0614.png" alt=""><br>编辑该文件，将你的新域名写进去：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0615.png" alt=""></p><p>然后执行<code>hexo g -d</code>重新部署</p><p>完成！！！</p><p>耐心等待一会儿，就可以使用新域名访问博客了！</p>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 博客搭建 </tag>
            
            <tag> Hexo </tag>
            
            <tag> GoDaddy域名 </tag>
            
            <tag> DNSPod </tag>
            
            <tag> GitHub </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2017/06/04/HelloWorld/"/>
      <url>/2017/06/04/HelloWorld/</url>
      
        <content type="html"><![CDATA[<p>这里是我的第一篇文章。</p><p>所以标题起名叫<strong>Hello World</strong>。</p><p>在<a href="https://www.ithome.com/html/win10/311572.htm">IT之家</a>看到了利用Github搭建个人博客的教程，觉得挺好玩，就跟着教程做了一下。过程中发现那篇教程并不是很完美，有很多坑且很繁琐，然后去网上搜各种文档，折腾到大半夜才搞定。</p><p>以后就打算在这里写东西了，闲着没事的时候写(zhuan)一(zai)点技术文档或者美文过来，嘿嘿~</p><p>也算是一个小小窝了~</p><p>改天我也写一个搭博客的教程，作为这里的第一篇技术文档(●ˇ∀ˇ●)</p>]]></content>
      
      
      <categories>
          
          <category> 杂记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 杂记 </tag>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
