<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>Kettle系列教程-第四章：资源库（数据库存储方式）</title>
      <link href="/2018/07/18/KettleDoc-4/"/>
      <url>/2018/07/18/KettleDoc-4/</url>
      <content type="html"><![CDATA[<p>本系列教程基于Kettle 8.1（pdi-ce-8.1.0.0-365）。大部分内容同样适用于Kettle 7.x版本。<br>章节目录：    </p><ul><li>一、<a href="">运行环境配置</a><ul><li>JDK</li><li>JVM参数</li><li>KETTLE_HOME</li><li>依赖包导入</li></ul></li><li>二、<a href="">转换与作业</a><ul><li>转换流程</li><li>作业流程</li></ul></li><li>三、<a href="">数据库连接配置</a><ul><li>创建数据库连接</li><li>共享数据库连接</li><li>数据库连接参数</li></ul></li><li>四、<a href="">资源库（数据库存储方式）</a><ul><li>创建资源库</li><li>保存流程到资源库</li><li>从资源库打开流程</li></ul></li><li>五、<a href="">变量/参数</a></li><li>六、<a href="">转换流程-输入组件</a></li><li>七、<a href="">转换流程-转换组件</a></li><li>八、<a href="">转换流程-输出组件</a></li><li>九、<a href="">脚本组件</a></li><li>十、<a href="">对接大数据平台</a></li><li>十一、<a href="">使用Windows计划任务定时执行Kettle作业</a></li><li>十二、<a href="">使用Java执行Kettle作业</a><h3 id="本章说明"><a href="#本章说明" class="headerlink" title="本章说明"></a>本章说明</h3>本篇内容为第四章：资源库（数据库存储方式）。<br>由于默认的转换、作业流程存储方式为单个文件存储，当有很多个转换、作业文件的时候，管理起来会很麻烦，所以这个时候就需要用到资源库了，用于统一管理转换、作业流程。资源库有两种存储方式：<strong>数据库存储</strong>和<strong>文件存储</strong>，本章只讲解<strong>数据库存储</strong>方式。<h3 id="创建资源库"><a href="#创建资源库" class="headerlink" title="创建资源库"></a>创建资源库</h3>首先需要创建一个字符集编码为<code>UTF8</code>的空白数据库（为什么指定编码为<code>UTF8</code>？因为不指定编码可能会出现中文乱码情况）。还是以MySQL为例，创建一个数据库名为<code>kettle</code>的空白数据库，并指定字符集编码：<code>CREATE DATABASE kettle DEFAULT CHARSET=UTF8;</code>。<br>然后点击Spoon界面右上角的<code>Connect</code>按钮，在弹出的窗口中点击<code>Other Repositories</code>：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/Jo9RSgaMFNbB.png" alt="img"><br>然后选中<code>Database Repository</code>，点击<code>Get Started</code>：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/EZreriA004WL.png" alt="img"><br>给资源库起个名字，再点击<em>None</em>：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/RNXvLPeNHX9N.png" alt="img"><br>弹出的窗口中点击<code>Create New Connection</code>:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/v0Oipld6JT83.png" alt="img"><br>配置一下刚创建的kettle数据库的连接信息：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/AfZWTscKj27v.png" alt="img"><br>再配置一下连接参数：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/o5N6cYwoHcgK.png" alt="img"><br>测试通过后，即可保存。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/eijtS9aasIuY.png" alt="img"><br>然后选中刚创建的数据库连接<code>mysql-repo</code>，再点击<code>Back</code>：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/MISKU8SGiSlR.png" alt="img"><br>确认配置无误后，点击<code>Finish</code>：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/tr0NyKI2PAx7.png" alt="img"><br>初始化数据库，稍等一会即可：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/FxI8gvdWiXOa.png" alt="img"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/4u67q8araddj.png" alt="img"><br>初始化完成，点击<code>Connect Now</code>，输入<code>admin/admin</code>，然后点击<code>Connect</code>即可连接到资源库。有兴趣的话可以去看下资源库的表结构：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/IBhuzwh5sAOx.png" alt="img"><br>此时Spoon界面右上角会变成这样：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/xBbythB976mT.png" alt="img"><h3 id="保存转换、作业流程到资源库"><a href="#保存转换、作业流程到资源库" class="headerlink" title="保存转换、作业流程到资源库"></a>保存转换、作业流程到资源库</h3>这一部分Kettle 8.1与Kettle 7.x差别较大。<br>新建一个转换或者作业，<code>Ctrl + S</code>保存，如果已经连接了资源库，则默认保存到资源库中：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/waT5vTpiVljA.png" alt="img"><br>右上角可以新建目录：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/H1YcPV42lLgo.png" alt="img"><br>选中保存位置，填写转换或者作业名称，点击<code>Save</code>即可保存到资源库。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/ifoqRh8gMjtw.png" alt="img"><h3 id="从资源库打开转换、作业流程"><a href="#从资源库打开转换、作业流程" class="headerlink" title="从资源库打开转换、作业流程"></a>从资源库打开转换、作业流程</h3></li><li>打开单个流程：<br><code>Ctrl + O</code>或者左上角 <code>文件 -&gt; 打开</code>，选中要打开的流程，<code>Open</code>即可：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/85zBswd9EtZT.png" alt="img">    </li><li>批量打开多个流程：<br><code>Ctrl + E</code>或者 <code>菜单栏 -&gt; 工具 -&gt; 资源库 -&gt; 探索资源库</code>，同时选中多个流程，然后按<code>回车键</code>，即可批量打开多个流程：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/SRzozZpTt8pn.png" alt="img">    <h3 id="管理资源库"><a href="#管理资源库" class="headerlink" title="管理资源库"></a>管理资源库</h3><code>Ctrl + E</code>或者 <code>菜单栏 -&gt; 工具 -&gt; 资源库 -&gt; 探索资源库</code>，右键菜单可以对目录、流程进行删除或者重命名等操作：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/iSE6Pl6ykqMm.png" alt="img">    </li></ul><p>本章完！<br>下一章：<a href="">变量/参数</a></p>]]></content>
      
      <categories>
          
          <category> Kettle </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kettle </tag>
            
            <tag> 资源库 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kettle系列教程-第三章：数据库连接配置</title>
      <link href="/2018/07/18/KettleDoc-3/"/>
      <url>/2018/07/18/KettleDoc-3/</url>
      <content type="html"><![CDATA[<p>本系列教程基于Kettle 8.1（pdi-ce-8.1.0.0-365）。大部分内容同样适用于Kettle 7.x版本。<br>章节目录：    </p><ul><li>一、<a href="">运行环境配置</a><ul><li>JDK</li><li>JVM参数</li><li>KETTLE_HOME</li><li>依赖包导入</li></ul></li><li>二、<a href="">转换与作业</a><ul><li>转换流程</li><li>作业流程</li></ul></li><li>三、<a href="">数据库连接配置</a><ul><li>创建数据库连接</li><li>共享数据库连接</li><li>数据库连接参数</li></ul></li><li>四、<a href="">资源库（数据库存储方式）</a><ul><li>创建资源库</li><li>保存流程到资源库</li><li>从资源库打开流程</li></ul></li><li>五、<a href="">变量/参数</a></li><li>六、<a href="">转换流程-输入组件</a></li><li>七、<a href="">转换流程-转换组件</a></li><li>八、<a href="">转换流程-输出组件</a></li><li>九、<a href="">脚本组件</a></li><li>十、<a href="">对接大数据平台</a></li><li>十一、<a href="">使用Windows计划任务定时执行Kettle作业</a></li><li>十二、<a href="">使用Java执行Kettle作业</a><h3 id="本章说明"><a href="#本章说明" class="headerlink" title="本章说明"></a>本章说明</h3>本篇内容为第三章：数据库连接配置。<br>使用Kettle的时候，肯定要与数据库打交道，常用的是jdbc连接方式。<h3 id="创建数据库连接"><a href="#创建数据库连接" class="headerlink" title="创建数据库连接"></a>创建数据库连接</h3>新建一个作业或者转换，可以在<code>主对象树</code>下面看到<code>DB连接</code>选项，<strong>双击</strong><code>DB连接</code>或者<code>右键菜单</code>点击<code>新建</code>，打开创建数据库连接窗口。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/lFK1WQll6nTJ.png" alt="img"><br>选择数据库类型以及连接方式（默认JDBC），填写相应配置：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/rFPib3lPJNVs.png" alt="img"><br>配置完成后点击<code>测试</code>按钮测试一下数据库连接，如下图所示表示配置成功，然后就可以点击<code>确认</code>保存数据库连接了，新建的数据库连接会显示在<code>DB连接</code>分组下：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/O365X5qfls5L.png" alt="img"> -&gt; <img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/z8ZvSBRLxoDx.png" alt="img">    <h3 id="共享数据库连接"><a href="#共享数据库连接" class="headerlink" title="共享数据库连接"></a>共享数据库连接</h3>新建的数据库连接只能在当前转换或者作业中使用，好在Kettle提供了数据库连接共享功能，在<code>数据库连接名称</code>上鼠标<strong>右键</strong>，点击<code>共享</code>即可将该数据库连接共享给其他转换或者作业使用，共享成功后，数据库连接名称将<strong>加粗</strong>显示：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/t5V88qkPQLvl.png" alt="img"> -&gt; <img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/AnMZ6tf2eOKx.png" alt="img"><br>另外，数据库连接共享后还会在<code>.kettle</code>目录下生成一个<code>shared.xml</code>文件，文件中记录着被共享的数据库连接信息：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/GgHYIec5GeMc.png" alt="img"><br><strong>警告：如果数据库名为中文，则不能共享该连接，否则会报出异常，影响Spoon的正常使用：</strong><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/SvRn4DEvRZzv.png" alt="img"> -&gt; <img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/Px7As6kbyqhb.png" alt="img"><br>如果手误已经发生这种情况，则可以使用<strong>记事本</strong>打开<code>.kettle</code>目录下的<code>shared.xml</code>文件，手动删除掉<strong>database标签值为中文的connection标签</strong>即可：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/2gcqYXO0bUDy.png" alt="img"><h3 id="数据库连接参数"><a href="#数据库连接参数" class="headerlink" title="数据库连接参数"></a>数据库连接参数</h3>创建数据库连接的时候还可以配置一些连接参数，比如连接MySQL的时候可以添加连接编码：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/vMccz79IUZ2H.png" alt="img"><br>这种方式可以解决由于编码不一致导致的中文乱码问题（上图的这个参数配置的前提是数据库字符集也是UTF8）。</li></ul><p>本章完！<br>下一章：<a href="">资源库（数据库存储方式）</a></p>]]></content>
      
      <categories>
          
          <category> Kettle </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kettle </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kettle系列教程-第二章：转换与作业</title>
      <link href="/2018/07/18/KettleDoc-2/"/>
      <url>/2018/07/18/KettleDoc-2/</url>
      <content type="html"><![CDATA[<p>本系列教程基于Kettle 8.1（pdi-ce-8.1.0.0-365）。大部分内容同样适用于Kettle 7.x版本。<br>章节目录：    </p><ul><li>一、<a href="">运行环境配置</a><ul><li>JDK</li><li>JVM参数</li><li>KETTLE_HOME</li><li>依赖包导入</li></ul></li><li>二、<a href="">转换与作业</a><ul><li>转换流程</li><li>作业流程</li></ul></li><li>三、<a href="">数据库连接配置</a><ul><li>创建数据库连接</li><li>共享数据库连接</li><li>数据库连接参数</li></ul></li><li>四、<a href="">资源库（数据库存储方式）</a><ul><li>创建资源库</li><li>保存流程到资源库</li><li>从资源库打开流程</li></ul></li><li>五、<a href="">变量/参数</a></li><li>六、<a href="">转换流程-输入组件</a></li><li>七、<a href="">转换流程-转换组件</a></li><li>八、<a href="">转换流程-输出组件</a></li><li>九、<a href="">脚本组件</a></li><li>十、<a href="">对接大数据平台</a></li><li>十一、<a href="">使用Windows计划任务定时执行Kettle作业</a></li><li>十二、<a href="">使用Java执行Kettle作业</a><h3 id="本章说明"><a href="#本章说明" class="headerlink" title="本章说明"></a>本章说明</h3>本篇内容为第二章：转换与作业。<br>经过第一章的学习，运行环境配置完成以后，就可以开始运行Kettle了，双击<code>data-integration</code>目录下的<code>Spoon.bat</code>文件，即可启动Kettle的任务设计器Spoon。启动速度较慢，可能会出现假死情况，耐心等待即可，<strong>不要连续多次双击</strong><code>Spoon.bat</code>文件。<br>Spoon主页：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/58LwsXEkyOFJ.png" alt="img"><br>Kettle有两种流程，转换流程和作业流程。<br>本章只介绍基本操作，不进行具体可执行流程设计。<h3 id="转换流程"><a href="#转换流程" class="headerlink" title="转换流程"></a>转换流程</h3>Kettle是个<strong>ETL</strong>工具嘛，转换流程就是主要进行数据转换（T）步骤设计的地方。当然也包含数据源（E）和目标（L）。<br>新建转换流程的方式有很多，比如左上角 <code>文件 -&gt; 新建 -&gt; 转换</code> ，或者点击欢迎页面WORK图标下的<code>New transforation</code>，亦可<code>双击左侧主对象树下的转换图标</code>，又可按快捷键<code>Ctrl + N</code>。<br>转换流程设计页面左侧<code>核心对象</code>下面是一个个的分类模块，每个分类下面又有许多个功能不同的组件，鼠标按住左侧组件图标拖拽到右侧流程设计面板即可增加一个步骤。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/VNaTpu1Z9jNY.png" alt="img"><br>步骤之间需要使用箭头连接，箭头方向表示步骤流向，按住Shift键的同时鼠标点住步骤图标向外拉即可拉出一条箭头（按住鼠标中键也可拉出箭头），将箭头拉向下一个步骤，即可形成一个简单的转换流程：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/Ap4s4RqfMXdv.png" alt="img"> -&gt; <img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/4eSh5bkcIzMG.png" alt="img"><br>需要注意的是步骤之间箭头的颜色，<strong>深色表示连接状态，浅色表示断开状态</strong>。比如下面这个转换流程，<strong>表输出</strong>步骤与上一步骤是断开连接的，执行流程的时候执行到<strong>去除重复记录</strong>这一步骤后就不会再往下执行了。单击箭头可以调整连接状态。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/RV0bXtVlWSno.png" alt="img"><br><code>Ctrl + S</code>保存，将保存为<code>ktr</code>后缀的文件。<h3 id="作业流程"><a href="#作业流程" class="headerlink" title="作业流程"></a>作业流程</h3>作业流程，即是对转换流程进行调度的。除了调度转换流程还可以做一些其他的工作，比如文件管理、条件判断、脚本执行等等，也可以调度其他作业流程。<br>新建作业流程与转换流程类似，快捷键是<code>Ctrl + Alt + N</code>。核心组件在<code>通用</code>分类下，一个作业流程必须包含<code>START</code>组件，可以没有<code>成功</code>组件。作业流程中可以嵌套转换流程和作业流程：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/k6rk5JXSm9lT.png" alt="img"><br>与转换流程不同的是，除了步骤之间有<code>连接状态</code>（箭头颜色深浅），还有<code>连接条件</code>（箭头上的图标，一共三种）。上图的这个作业中包含了所有连接条件：    </li><li>小锁图标，表示不管上一步骤执行结果如何，都执行下一个步骤；</li><li>红叉图标，表示只有上一步骤执行出错或者返回FALSE，才执行下一步骤；</li><li>绿勾图标，表示只有上一步骤执行成功或者返回TRUE，才执行下一步骤。    </li></ul><p>单击连接条件图标可以调整连接条件，<code>START</code>步骤与下一步骤之间的连接条件不可修改。<br><code>START</code>组件标识着工作流的开始，也是配置定时任务的地方：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/nRGdpRf37ULI.png" alt="img"><br>定时调度功能还是很灵活的，只不过需要一直保持Spoon处于启动状态，一旦Spoon窗口被误关闭，定时任务就无效了，所以一般不使用Kettle自带的这个调度器。比较常用的是使用操作系统的定时任务功能，比如Windows的计划任务，或者可以编写Java程序进行调度，后面会有详细讲解，这里就不再细说。<br><code>Ctrl + S</code>保存，将保存为<code>kjb</code>后缀的文件。</p><p>本章完！<br>下一章：<a href="">数据库连接配置</a></p>]]></content>
      
      <categories>
          
          <category> Kettle </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kettle </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Kettle系列教程-第一章：运行环境配置</title>
      <link href="/2018/07/18/KettleDoc-1/"/>
      <url>/2018/07/18/KettleDoc-1/</url>
      <content type="html"><![CDATA[<p>本系列教程基于Kettle 8.1（pdi-ce-8.1.0.0-365）。大部分内容同样适用于Kettle 7.x版本。<br>章节目录：    </p><ul><li>一、<a href="">运行环境配置</a><ul><li>JDK</li><li>JVM参数</li><li>KETTLE_HOME</li><li>依赖包导入</li></ul></li><li>二、<a href="">转换与作业</a><ul><li>转换流程</li><li>作业流程</li></ul></li><li>三、<a href="">数据库连接配置</a><ul><li>创建数据库连接</li><li>共享数据库连接</li><li>数据库连接参数</li></ul></li><li>四、<a href="">资源库（数据库存储方式）</a><ul><li>创建资源库</li><li>保存流程到资源库</li><li>从资源库打开流程</li></ul></li><li>五、<a href="">变量/参数</a></li><li>六、<a href="">转换流程-输入组件</a></li><li>七、<a href="">转换流程-转换组件</a></li><li>八、<a href="">转换流程-输出组件</a></li><li>九、<a href="">脚本组件</a></li><li>十、<a href="">对接大数据平台</a></li><li>十一、<a href="">使用Windows计划任务定时执行Kettle作业</a></li><li>十二、<a href="">使用Java执行Kettle作业</a><h3 id="本章说明"><a href="#本章说明" class="headerlink" title="本章说明"></a>本章说明</h3></li><li>本篇内容为第一章：运行环境配置。</li><li>本章内容基于Windows平台，可能不适用于Linux下的环境配置。</li><li>本章所有操作都是重启Kettle后生效。<h3 id="JDK"><a href="#JDK" class="headerlink" title="JDK"></a>JDK</h3>Kettle 8.1要求jdk版本1.8以上，Windows下jdk环境的配置这里就不赘述了。只说一下其中一种可能的情况：系统已配置jdk环境，但不是jdk1.8，又不想升级已配置的jdk环境，即需要<strong>单独为Kettle配置jdk1.8环境</strong>。<br>操作如下：首先安装jdk1.8，不用修改系统环境变量。然后进入 <code>data-integration</code>目录找到<code>Spoon.bat</code>文件，右键使用<strong>除了记事本以外的文本编辑器</strong>打开（比如 VS Code、EditPlus、Notepad ++），在”<code>cd /D %~dp0</code>“下面添加一行（路径指向jdk1.8的目录，可以使用相对路径）：”<code>set JAVA_HOME=/path/to/jdk1.8</code>“即可。如图所示:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/xkOTRakGtwyB.png" alt="img"><h3 id="JVM参数"><a href="#JVM参数" class="headerlink" title="JVM参数"></a>JVM参数</h3>Kettle 8.1默认使用的最大jvm堆内存是2G，执行某些复杂作业可能会出现堆内存溢出错误（<code>OutOfMemoryError</code>），此时就需要调正Kettle的jvm参数。<br>依旧是<code>data-integration</code>目录下的<code>Spoon.bat</code>文件，找到<pre><code class="bat">if &quot;%PENTAHO_DI_JAVA_OPTIONS%&quot;==&quot;&quot; set PENTAHO_DI_JAVA_OPTIONS=&quot;-Xms1024m&quot; &quot;-Xmx2048m&quot; &quot;-XX:MaxPermSize=256m&quot;</code></pre>这一行，适当增大”<code>-Xmx</code>“参数值即可。<br>如果出现了栈溢出错误（<code>StackOverFlowError</code>）（一般不会出现），则需要再增加一个参数”<code>-Xss</code>“，数值需要根据本机内存配置适当填写。<br>如图所示：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/ygRaKzNIkhbA.png" alt="img"><h3 id="KETTLE-HOME"><a href="#KETTLE-HOME" class="headerlink" title="KETTLE_HOME"></a>KETTLE_HOME</h3>Kettle运行时会使用一个名叫”<code>.kettle</code>“的文件夹，里面存放着一些配置文件。默认该目录在C盘个人用户目录下：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/L7G3SZr9Qs5N.png" alt="img"><br>通常情况下没什么问题，但如果需要同时安装多个Kettle的话，最好还是单独配置一下<code>KETTLE_HOME</code>，这样的话，<code>.kettle</code>目录就会自动创建在配置的<code>KETTLE_HOME</code>目录下。<br>仍旧是<code>data-integration</code>目录下的<code>Spoon.bat</code>文件，在”<code>cd /D %~dp0</code>“下面添加一行”<code>set KETTLE_HOME=../</code>“，如图所示：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/cLvuzC8sK7vc.png" alt="img"><br>这次使用了相对路径，启动Kettle后会在<strong>Spoon.bat所在目录的上一层目录</strong>下创建一个<code>.kettle</code>文件夹(当然也可以使用绝对路径)：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/InPwufFufS59.png" alt="img"><h3 id="依赖包导入"><a href="#依赖包导入" class="headerlink" title="依赖包导入"></a>依赖包导入</h3>Kettle是没有内置数据库jdbc连接驱动的，当测试数据库连接的时候报出未找到驱动错误，那肯定是忘记导入jdbc驱动了。因此需要提前把常用数据库的jdbc驱动放置到<code>data-integration/lib/</code>目录下，另外，若是在Java代码组件中使用了第三方依赖包，也需要依赖包放置到该目录下。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/kettle/doc/20180719/eIW4tw8CDERU.png" alt="img"><br>不同版本的jdbc驱动对于不同版本的数据库可能会出现不兼容问题，导入驱动的时候需要对照下数据库版本。<br>不能把一个数据库的多个版本的jdbc驱动同时导入，会造成依赖冲突。</li></ul><p>本章完！<br>下一章：<a href="">Kettle转换与作业</a></p>]]></content>
      
      <categories>
          
          <category> Kettle </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kettle </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Gpg4win&amp;Kettle文件加密、解密组件的使用</title>
      <link href="/2018/05/06/KettleGPG/"/>
      <url>/2018/05/06/KettleGPG/</url>
      <content type="html"><![CDATA[<p>Kettle是一个很强大的开源的数据ETL工具，并且可以与大数据平台整合，直接将关系型数据库中的数据接入到Hadoop平台上。    </p><p>在对数据文件进行操作的时候有些场景可能需要对数据文件进行加密，以保证数据的安全性，而Kettle刚好提供了文件加密组件<strong>用PGP加密文件</strong>，这个组件在<strong>作业</strong>/<strong>文件加密</strong>模块下，使用的加密方式是GPG加密。    </p><p>所以在介绍Kettle加密文件之前，先介绍一下GPG这个软件:    </p><h3 id="GPG加密软件的使用"><a href="#GPG加密软件的使用" class="headerlink" title="GPG加密软件的使用"></a>GPG加密软件的使用</h3><p>GPG，全称GnuPG，根据<a href="https://www.gnupg.org/" target="_blank" rel="noopener">GPG官网</a>的说法，是商业加密软件PGP的免费版，可以对数据和通信进行加密和签名，并具有多功能密钥管理系统。    </p><p>GPG提供了非对称加密的方式，即加密和解密使用的是不同的密钥（分别叫公钥、私钥），公钥只能用于加密，不能解密，私钥可以解密。顾名思义，公钥是可以共享给别人的密钥，而私钥则是需要自己好好保护的密钥。别人使用公钥对要发送给你的数据进行加密，你收到加密后的密文后就可以拿私钥对该密文进行解密，由于私钥只在自己手中，就算是黑客也没办法获取密文中的真实数据，可以保证信息的安全传输。    </p><h4 id="在Windows下安装GPG加密软件"><a href="#在Windows下安装GPG加密软件" class="headerlink" title="在Windows下安装GPG加密软件"></a>在Windows下安装GPG加密软件</h4><p>Windows下需要安装<a href="https://www.gpg4win.org/" target="_blank" rel="noopener">Gpg4win</a>。<br>下载Gpg4win安装程序后，双击安装：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/dl3gHjbdAj.png" alt="mark"><br>只勾选第二个选项（注意：XP系统下第二个选项不可选，需要勾选第三个选项）：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/7fmB5dCFbF.png" alt="mark"><br>下一步，默认安装位置安装。    </p><p>安装完成，桌面上会多出一个图标（密钥管理器）：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/BBGg3Gd9c9.png" alt="mark"><br>双击这个图标打开<strong>密钥管理器</strong>：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/aGhdCA513A.png" alt="mark"><br>首先需要创建一个密钥对，点击<strong>新建密钥对</strong>按钮：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/d6Lg1f8FJf.png" alt="mark"><br>输入相关信息，下一步：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/d6Lg1f8FJf.png" alt="mark"><br>点击创建：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/H394HLlGmC.png" alt="mark"><br>然后会弹出一个输入框，需要给私钥设置一个保护密码：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/9cDea9beH4.png" alt="mark"><br>如果你设置的密码不够复杂的话，会弹出一个警告，点击Take this one anyway即可：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/I5eli5EE6c.png" alt="mark"><br>创建完成：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/HfcK07Dkfl.png" alt="mark"><br>可以在密钥列表中看到新建的密钥对：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/A7EEjkGimb.png" alt="mark">    </p><h4 id="密钥的导入与导出"><a href="#密钥的导入与导出" class="headerlink" title="密钥的导入与导出"></a>密钥的导入与导出</h4><ul><li>导出密钥<br>选中密钥对，鼠标右键即可弹出菜单，第一个<strong>导出</strong>只是导出公钥，如果想要导出私钥，需要选择下面的<strong>导出绝对密钥</strong>选项：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/7DK4ED844F.png" alt="mark">    </li><li>导入密钥<br>点击菜单栏的导入按钮（示例是一个绝对密钥文件的导入）:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/fdj2BH16DG.png" alt="mark"><br>点击<strong>是</strong>修改密钥的信任级别为<strong>无限制</strong>，关于信任级别的作用后面会有提到。    <h4 id="删除私钥保护密码"><a href="#删除私钥保护密码" class="headerlink" title="删除私钥保护密码"></a>删除私钥保护密码</h4>文件加密解密操作这里就不再介绍，密钥管理器界面上有操作按钮。<br>刚刚新建的密钥对是设置了私钥保护密码的，解密的时候就需要输入保护密码，为了方便操作，可以将保护密码去除掉。<br>右键要去掉私钥保护密码的密钥，选择更改密码句：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/J3jL04kkFc.png" alt="mark"><br>输入原密码：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/DmjI5l51cj.png" alt="mark"><br>留空，直接OK：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/kdC30C9Ike.png" alt="mark"><br>点击Yes：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/ih2GkJjFF6.png" alt="mark"><br>再次直接OK：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/kdC30C9Ike.png" alt="mark"><br>再次YES：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/ih2GkJjFF6.png" alt="mark"><br>密码去除成功：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180506/7ebbigAiEg.png" alt="mark"><br>此后再去解密文件就不需要输入保护密码了。    </li></ul><p>关于GPG软件的其它进阶操作这里就不再介绍。</p><h3 id="Kettle文件加密组件的使用"><a href="#Kettle文件加密组件的使用" class="headerlink" title="Kettle文件加密组件的使用"></a>Kettle文件加密组件的使用</h3><p>打开Kettle，新建一个作业[Ctrl + Alt + N]，将<strong>核心对象</strong>下的<strong>文件加密</strong>文件夹下的<strong>用PGP加密文件</strong>组件拖到右侧，组成一个简单的流程：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/mfl5H8e2df.png" alt="mark"><br>为了操作方便，先双击<strong>作业空白处</strong>配置两个参数（<strong>源文件夹</strong>和<strong>目标文件夹</strong>）：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/KEibA64JAD.png" alt="mark"><br>然后双击<strong>用PGP加密文件</strong>组件，打开配置页面：<br>最上面<strong>GPG文件路径</strong>，是设置<code>gpg.exe</code>这个文件路径的，如果是默认位置安装的话就是图示的这个位置；<br><strong>源文件/文件夹</strong>和<strong>目标文件/文件夹</strong>分别填写上刚刚设置的参数项；<br><strong>通配符</strong>设为<code>.*</code>表示对源文件夹的的所有文件都进行加密操作：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/HiG0FfAIJ9.png" alt="mark"><br>配置完以后，点击<strong>源文件/文件夹</strong>后面的<strong>添加</strong>按钮：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/kGad6I51fD.png" alt="mark"><br>然后需要填写<strong>用户ID</strong>，<strong>用户ID</strong>即为GPG<strong>密钥管理器</strong>密钥列表中的<strong>名称</strong>列：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/7FBlBm2I91.png" alt="mark"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/fHFege6EJj.png" alt="mark"><br>切换到<strong>目标文件</strong>选项卡，勾选上<strong>创建目标文件夹</strong>选项，这样如果目标文件夹不存在，Kettle会自动创建目标文件夹；下方还可以配置<strong>如果目标文件已存在</strong>的处理方式，这里我选择的是<strong>覆盖</strong>已存在文件。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/2lLCKdCJg3.png" alt="mark"><br>然后就可以测试文件加密了，向待加密文件夹里放几个文件：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/EdEKlaGKef.png" alt="mark"><br>跑一下加密流程：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/13iI3cKKdA.png" alt="mark"><br>看一下待解密文件夹：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/G0I0b5EBCm.png" alt="mark"><br>图片已经不可查看，文件加密成功！</p><h3 id="Kettle文件解密组件的使用"><a href="#Kettle文件解密组件的使用" class="headerlink" title="Kettle文件解密组件的使用"></a>Kettle文件解密组件的使用</h3><p>新建一个作业[Ctrl + Alt + N]，将<strong>核心对象</strong>下的<strong>文件加密</strong>文件夹下的<strong>用PGP解密文件</strong>组件拖到右侧，组成一个简单的流程：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/ebmiECi9a6.png" alt="mark"><br>同样的，为了操作方便，先双击<strong>作业空白处</strong>配置两个参数（<strong>源文件夹</strong>和<strong>目标文件夹</strong>）：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/15iaAA3cJh.png" alt="mark"><br>与加密类似，需要配置<strong>gpg文件路径</strong>，<strong>源路径</strong>和<strong>目标路径</strong>，<strong>密钥</strong>不用填写：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/2GiAk2hdJi.png" alt="mark"><br><strong>目标文件夹</strong>选项卡也与加密类似：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/HclG8Edd9H.png" alt="mark"><br>配置完成后，确定，保存，即可开始运行解密流程（如果未去除私钥保护密码，则第一次运行会弹出输入密码窗口）：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/9c63kE7m1C.png" alt="mark"><br>查看<strong>已解密文件</strong>文件夹：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/J7K10amE34.png" alt="mark"><br>文件解密成功！</p><h3 id="使用Kettle进行文件加密、解密注意事项"><a href="#使用Kettle进行文件加密、解密注意事项" class="headerlink" title="使用Kettle进行文件加密、解密注意事项"></a>使用Kettle进行文件加密、解密注意事项</h3><p>加密报错:<code>Error running command: gpg: B3CC28EC0344DA15: There is no assurance this key belongs to the named user</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/cmH1g35I2l.png" alt="mark"><br>则可能是因为该密钥信任级别较低，这个时候就需要修改一下密钥的信任级别或者进行认证。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/1k5Fg1ea5K.png" alt="mark">    </p><ul><li>方法一：使用密钥管理器可以右键要认证的密钥，点击认证，不过需要至少已经存在一个信任级别为5级的密钥才能认证。    </li><li>方法二：使用CMD命令修改密钥信任级别。打开cmd窗口，进入<strong>gpg.exe</strong>所在目录，执行<code>gpg --edit-key staroon</code>，<strong>staroon</strong>是想要修改信任级别的密钥的<strong>密钥ID</strong>，然后输入<strong>trust</strong>回车，再输入<strong>5</strong>回车，再输入<strong>y</strong>回车，最后输入<strong>save</strong>保存，即可：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/I4078iJeCb.png" alt="mark"><br>认证以后再回到密钥管理器就可以看到密钥的认证级别已变为<strong>认证的</strong>，Kettle就可以正常加密了：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/KettleGPG/180507/Kgdb08DeCG.png" alt="mark"></li></ul>]]></content>
      
      <categories>
          
          <category> Kettle </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kettle </tag>
            
            <tag> GPG </tag>
            
            <tag> ETL </tag>
            
            <tag> 文件加密 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>CDH5高可用集群离线部署</title>
      <link href="/2018/02/08/CDH5Install/"/>
      <url>/2018/02/08/CDH5Install/</url>
      <content type="html"><![CDATA[<p>前几篇文章介绍了下原生Hadoop集群的部署过程，这篇文章就来介绍下CDH的部署过程，毕竟发行版Hadoop的部署、运维都很方便，稳定性也好，实际生产环境上用原生Hadoop的并不是很多。</p><p>推荐还是多看<a href="https://www.cloudera.com/documentation.html" target="_blank" rel="noopener">CDH官方文档</a></p><p>CDH5各版本的部署过程应该都差不多，我这边测试的CDH5.10.2的和CDH5.9.0的部署过程一模一样，这篇文章就以CDH5.9.0为例。</p><h3 id="操作系统环境准备"><a href="#操作系统环境准备" class="headerlink" title="操作系统环境准备"></a>操作系统环境准备</h3><p>这个前面的文章已经介绍过，这里不再赘述。<br>包含<strong>操作系统的参数调整</strong>、<strong>MySQL安装</strong>、<strong>Jdk1.8安装</strong>等。<br>-&gt; <a href="https://staroon.pro/2017/11/05/SetEnv/">Hadoop集群搭建系统环境准备</a></p><p>注意: 这里操作系统参数不调整的话，后面安装CDH集群前进行主机检查的时候会发出告警。</p><h3 id="文件准备"><a href="#文件准备" class="headerlink" title="文件准备"></a>文件准备</h3><p>由于是离线部署，因此需要预先下载好需要的文件。<br>需要准备的文件有:    </p><ul><li>Cloudera Manager 5<br>文件名: cloudera-manager-centos7-cm5.9.0_x86_64.tar.gz<br>下载地址: <a href="https://archive.cloudera.com/cm5/cm/5/" target="_blank" rel="noopener">https://archive.cloudera.com/cm5/cm/5/</a>    </li><li>CDH安装包（Parecls包）<br>版本号必须与Cloudera Manager相对应<br>下载地址: <a href="https://archive.cloudera.com/cdh5/parcels/5.9.0/" target="_blank" rel="noopener">https://archive.cloudera.com/cdh5/parcels/5.9.0/</a><br>需要下载下面3个文件：    <ul><li>CDH-5.9.0-1.cdh5.9.0.p0.23-el7.parcel</li><li>CDH-5.9.0-1.cdh5.9.0.p0.23-el7.parcel.sha1</li><li>manifest.json</li></ul></li><li>MySQL jdbc驱动<br>文件名: mysql-connector-java-<em>.tar.gz<br>下载地址: <a href="https://dev.mysql.com/downloads/connector/j/" target="_blank" rel="noopener">https://dev.mysql.com/downloads/connector/j/</a><br>解压出: mysql-connector-java-</em>bin.jar    </li></ul><h3 id="Cloudera-Manager安装"><a href="#Cloudera-Manager安装" class="headerlink" title="Cloudera Manager安装"></a>Cloudera Manager安装</h3><ol><li>所有节点上传cloudera-manager-centos7-cm5.9.0_x86_64.tar.gz文件并解压<br><code># tar -zxvf cloudera-manager-centos7-cm5.9.0_x86_64.tar.gz -C /opt</code></li><li>所有节点手动创建文件夹<br><code># mkdir /opt/cm-5.9.0/run/cloudera-scm-agent</code></li><li>所有节点创建<strong>cloudera-scm</strong>用户<br><code># useradd --system --home=/opt/cm-5.9.0/run/cloudera-scm-server --no-create-home --shell=/bin/false --comment &quot;Cloudera SCM User&quot; cloudera-scm</code></li><li>初始化数据库（只需要在Cloudera Manager Server节点执行）    <ul><li>首先需要将mysql jdbc驱动放入相应位置:<br><code># cp /path/to/mysql-connector-java-5.1.42-bin.jar /opt/cm-5.9.0/share/cmf/lib/</code></li><li>然后执行命令:<br><code># /opt/cm-5.9.0/share/cmf/schema/scm_prepare_database.sh mysql -h 192.168.0.201 -uroot -p123456 --scm-host 192.168.0.201 scm scm scm</code></li><li>脚本参数说明:<br>${<strong>数据库类型</strong>} -h ${<strong>数据库所在节点ip/hostname</strong>} -u${<strong>数据库用户名</strong>} -p${<strong>数据库密码</strong>} –scm-host ${<strong>Cloudera Manager Server节点ip/hostname</strong>} scm scm scm</li><li>提示下面这个说明执行成功:<br><code>All done, your SCM database is configured correctly!</code></li></ul></li><li>所有节点修改Agent配置<br><code># vim /opt/cm-5.9.0/etc/cloudera-scm-agent/config.ini</code><br>将其中的<strong>server_host</strong>参数修改为<strong>Cloudera Manager Server节点的主机名</strong></li><li>将如下文件放到<strong>Server节点</strong>的<code>/opt/cloudera/parcel-repo/</code>目录中:    <ul><li>CDH-5.9.0-1.cdh5.9.0.p0.23-el7.parcel</li><li>CDH-5.9.0-1.cdh5.9.0.p0.23-el7.parcel.sha1</li><li>manifest.json</li></ul></li><li>重命名sha1文件<br><code># mv CDH-5.9.0-1.cdh5.9.0.p0.23-el7.parcel.sha1 CDH-5.9.0-1.cdh5.9.0.p0.23-el7.parcel.sha</code></li><li>所有节点更改cm相关文件夹的用户及用户组<br><code># chown -R cloudera-scm:cloudera-scm /opt/cloudera</code><br><code># chown -R cloudera-scm:cloudera-scm /opt/cm-5.9.0</code></li><li>启动Cloudera Manager    <ul><li>Server节点:<br><code># /opt/cm-5.9.0/etc/init.d/cloudera-scm-server start</code><br><code># /opt/cm-5.9.0/etc/init.d/cloudera-scm-agent start</code></li><li>其它节点:<br><code># /opt/cm-5.9.0/etc/init.d/cloudera-scm-agent start</code></li></ul></li></ol><h3 id="CDH集群部署"><a href="#CDH集群部署" class="headerlink" title="CDH集群部署"></a>CDH集群部署</h3><ol><li>Server和Agent都启动以后（第一次启动稍慢，需要耐心等待一会儿），就可以访问CM Web页面进行集群部署了，打开浏览器，访问 <code>http://cm-server-ip:7180</code> 即可，默认的用户名/密码为：admin/admin<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/Cl7K2JfHHd.png" alt="login"></li><li>然后是协议<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/I2Kc5kck9I.png" alt="协议"></li><li>版本选择，有订阅的选订阅版，没有的选企业试用版或者免费版，这里以免费版安装为例。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/7cIJA2Be4f.png" alt="许可证版本选择"></li><li>感谢语<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/0hGAlj7KCG.png" alt="Thanks"></li><li>指定要安装集群的主机，在当前管理的主机列表中可以看到已经启动CM agent的节点（如果没有，需要检查agent服务是否启动正常）。勾选上所需要的节点。我这里由于之前部署过程中没有截图，所以临时装了个虚拟机，故就一个节点。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/KbHeg4gge2.png" alt="hostSelect"> </li><li>Parcel包选择，默认已经选择好配置的本地仓库中的Parcel包。如果版本选择列表看不到选项，则可能是<strong><a href="#Cloudera-Manager%E5%AE%89%E8%A3%85">Cloudera Manager安装</a></strong>步骤的<strong>第6步、第7步</strong>没执行好。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/7hbhkk2fD4.png" alt="parcelSelect"></li><li>如果本地Parcel包配置无误，则下载步骤是瞬间完成的，然后就是耐心等待分配、解压过程，分配过程的速度取决于节点之间的网络传输速度。 所有节点激活完成后就可以进行下一步了。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/2l57dl9g3A.png" alt="包部署"></li><li>然后是主机检查。注意我打红框的地方，前面不禁用transparent hugepage和调整vm.swappiness参数的话，这里就会有警告信息。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/2aCF19a6eJ.png" alt="主机检查"></li><li>安装服务选择，一定要有Zookeeper、HDFS、Yarn，其他的根据自己需要选择。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/g6hE5AGE8e.png" alt="服务选择"></li><li>服务选择完以后，开始进行角色分配。这个需要根据集群规模、节点个数合理分配。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/iAh2BLgeFc.png" alt="角色分配"></li><li>如果选择了Hive，则在安装Hive之前，需要先将mysql jdbc驱动放到Hive的lib文件夹下：<br><code># cp /opt/cm-5.9.0/share/cmf/lib/mysql-connector-java-5.1.42-bin.jar /opt/cloudera/parcels/CDH-5.9.0-1.cdh5.9.0.p0.23/lib/hive/lib/</code><br>然后进入mysql创建hive数据库:<br><code>mysql&gt; create database hive;</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/IHJD0eG7m5.png" alt="hive"><br>配置完以后点一下测试连接，确定没问题以后进行下一步。</li><li>集群参数调整。这个地方可以调整一部分服务的参数，根据需要合理调整即可。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/BJd3jCc1KI.png" alt="参数调整"></li><li>集群启动。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/a0HALGFfe6.png" alt="start"></li><li>集群部署完成。由于我这是临时安装的虚拟机，内存很小，所以报了一大堆警告。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/7KmHFbDGhl.png" alt="success"></li></ol><h3 id="开启高可用-HA"><a href="#开启高可用-HA" class="headerlink" title="开启高可用(HA)"></a>开启高可用(HA)</h3><p>集群的高可用依赖于Zookeeper和ZKFailoverController(ZKFC)，因此启用HA需要确保Zookeeper服务已开启。<br>要求:</p><blockquote><ol><li>NameNode: 活动主机和备用主机(硬件配置相同)</li><li>JournalNode: 至少3个(奇数个)，系统最多可以承受 (JN个数-1)/2 个故障</li><li>Zookeeper: 至少3个(奇数个)</li></ol></blockquote><p>以下部分内容摘自于官方文档:</p><blockquote><p>注意:在HA群集中，备用NameNode还执行命名空间状态的检查点，因此无需在HA群集中运行Secondary NameNode，CheckpointNode或BackupNode<br>注意:启用或禁用HA会导致HDFS服务和所有依赖于HDFS的服务的服务中断。在启用或禁用HA之前，请确保您的群集上没有运行作业<br>注意:启用或禁用HA会导致以前的监视历史记录不可用<br>注意:启用或禁用HA需要使用具有集群管理员权限的用户    </p></blockquote><h4 id="启用HDFS-HA"><a href="#启用HDFS-HA" class="headerlink" title="启用HDFS HA"></a>启用HDFS HA</h4><ul><li>转到HDFS，操作-&gt;启用High Availability</li><li>设置备用NameNode主机(硬件配置与活动主机相同)</li><li>设置JournalNode主机(至少三个),建议放在活动NameNode和备用NameNode以及另外一个硬件类似的机器</li><li>指定每个JournalNode的Edits目录(需要手动创建，要求为目录空，且拥有适当的权限：<strong>hdfs</strong>用户，<strong>hadoop</strong>用户组)<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/h3hcDab27I.png" alt="jn"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/D5f2CCd255.png" alt="ha"></li><li>根据提示，停掉Hive服务，备份元数据库，更新Hive Metastore NameNode，然后重启Hive服务<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/e3kg4gAiB9.png" alt="hive1"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/CDHInstall/180208/leGi9fDG30.png" alt="hive2"></li></ul><h4 id="启用YARN-HA"><a href="#启用YARN-HA" class="headerlink" title="启用YARN HA"></a>启用YARN HA</h4><ul><li>转至YARN，操作-&gt;启用High Availability</li><li>选择备用ResourceManager</li><li>重新部署客户端配置</li></ul><h3 id="CDH高可用集群搭建完毕"><a href="#CDH高可用集群搭建完毕" class="headerlink" title="CDH高可用集群搭建完毕"></a>CDH高可用集群搭建完毕</h3><p>搭建完以后，就可以进行一些参数调整、性能测试了</p>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> 高可用 </tag>
            
            <tag> CDH </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>CentOS7下挂载新磁盘</title>
      <link href="/2018/02/02/AddDiskOnLinux/"/>
      <url>/2018/02/02/AddDiskOnLinux/</url>
      <content type="html"><![CDATA[<p>虚拟机也好，物理机也罢，在CentOS的使用过程中都有可能会出现需要增加磁盘的情况，这篇文章就是介绍如何为新磁盘进行分区以及挂载操作。</p><p>所有操作都在root用户下进行。</p><h4 id="查看当前磁盘使用状况"><a href="#查看当前磁盘使用状况" class="headerlink" title="查看当前磁盘使用状况"></a>查看当前磁盘使用状况</h4><p><code># df -h</code></p><pre><code>Filesystem           Size  Used Avail Use% Mounted on/dev/mapper/cl-root   18G   15G  3.3G  82% /devtmpfs             902M     0  902M   0% /devtmpfs                912M     0  912M   0% /dev/shmtmpfs                912M  8.6M  904M   1% /runtmpfs                912M     0  912M   0% /sys/fs/cgroup/dev/sda1            197M  119M   79M  61% /boottmpfs                183M     0  183M   0% /run/user/0</code></pre><h4 id="列出现有的磁盘及分区信息"><a href="#列出现有的磁盘及分区信息" class="headerlink" title="列出现有的磁盘及分区信息"></a>列出现有的磁盘及分区信息</h4><p><code># fdisk -l</code></p><pre><code># /dev/sda 是原有的磁盘，可以看到这块磁盘下面的分区信息Disk /dev/sda: 42.9 GB, 42949672960 bytes, 83886080 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x000b4958   Device Boot      Start         End      Blocks   Id  System/dev/sda1   *        2048      411647      204800   83  Linux/dev/sda2          411648    41943039    20765696   8e  Linux LVM/dev/sda3        41943040    83886079    20971520   83  Linux# /dev/sdb 就是我们刚添加的磁盘（如果原来只有一块磁盘的话），可以看到这块磁盘下面没有任何分区Disk /dev/sdb: 42.9 GB, 42949672960 bytes, 83886080 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk /dev/mapper/cl-root: 19.1 GB, 19113443328 bytes, 37330944 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk /dev/mapper/cl-swap: 2147 MB, 2147483648 bytes, 4194304 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytes</code></pre><h4 id="对新磁盘-dev-sdb-进行分区操作"><a href="#对新磁盘-dev-sdb-进行分区操作" class="headerlink" title="对新磁盘 /dev/sdb 进行分区操作"></a>对新磁盘 <strong><code>/dev/sdb</code></strong> 进行分区操作</h4><p><code># fdisk /dev/sdb</code></p><pre><code>Welcome to fdisk (util-linux 2.23.2).Changes will remain in memory only, until you decide to write them.Be careful before using the write command.Device does not contain a recognized partition tableBuilding a new DOS disklabel with disk identifier 0xfd5ee39c.# 输入 m 可以查看命令帮助（我们只需要用到 n 和 w 两个命令）Command (m for help): mCommand action   a   toggle a bootable flag   b   edit bsd disklabel   c   toggle the dos compatibility flag   d   delete a partition   g   create a new empty GPT partition table   G   create an IRIX (SGI) partition table   l   list known partition types   m   print this menu   n   add a new partition # 添加分区   o   create a new empty DOS partition table   p   print the partition table   q   quit without saving changes   s   create a new empty Sun disklabel   t   change a partition&#39;s system id   u   change display/entry units   v   verify the partition table   w   write table to disk and exit # 写入分区表并退出   x   extra functionality (experts only)# 输入 n 添加分区（一块磁盘最多可以有4个主分区-primary，没有特殊需求的话，全部按默认分一个区就行）Command (m for help): nPartition type:   p   primary (0 primary, 0 extended, 4 free)   e   extendedSelect (default p): Using default response pPartition number (1-4, default 1): First sector (2048-83886079, default 2048): Using default value 2048Last sector, +sectors or +size{K,M,G} (2048-83886079, default 83886079): Using default value 83886079Partition 1 of type Linux and of size 40 GiB is set# 输入 w 保存分区信息Command (m for help): wThe partition table has been altered!Calling ioctl() to re-read partition table.Syncing disks.</code></pre><h4 id="再次查看磁盘分区信息"><a href="#再次查看磁盘分区信息" class="headerlink" title="再次查看磁盘分区信息"></a>再次查看磁盘分区信息</h4><p><code># fdisk -l</code></p><pre><code>Disk /dev/sda: 42.9 GB, 42949672960 bytes, 83886080 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x000b4958   Device Boot      Start         End      Blocks   Id  System/dev/sda1   *        2048      411647      204800   83  Linux/dev/sda2          411648    41943039    20765696   8e  Linux LVM/dev/sda3        41943040    83886079    20971520   83  LinuxDisk /dev/sdb: 42.9 GB, 42949672960 bytes, 83886080 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0xfd5ee39c# 可以看到刚刚分的一个区 /dev/sdb1   Device Boot      Start         End      Blocks   Id  System/dev/sdb1            2048    83886079    41942016   83  LinuxDisk /dev/mapper/cl-root: 19.1 GB, 19113443328 bytes, 37330944 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk /dev/mapper/cl-swap: 2147 MB, 2147483648 bytes, 4194304 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytes</code></pre><h4 id="格式化新分区-dev-sdb1"><a href="#格式化新分区-dev-sdb1" class="headerlink" title="格式化新分区 /dev/sdb1"></a>格式化新分区 <strong><code>/dev/sdb1</code></strong></h4><p>这里使用<strong>ext4</strong>文件系统<br><code># mkfs.ext4 /dev/sdb1</code></p><pre><code>mke2fs 1.42.9 (28-Dec-2013)Filesystem label=OS type: LinuxBlock size=4096 (log=2)Fragment size=4096 (log=2)Stride=0 blocks, Stripe width=0 blocks2621440 inodes, 10485504 blocks524275 blocks (5.00%) reserved for the super userFirst data block=0Maximum filesystem blocks=2157969408320 block groups32768 blocks per group, 32768 fragments per group8192 inodes per groupSuperblock backups stored on blocks:     32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208,     4096000, 7962624Allocating group tables: done                            Writing inode tables: done                            Creating journal (32768 blocks): doneWriting superblocks and filesystem accounting information: done   </code></pre><h4 id="创建分区挂载目录"><a href="#创建分区挂载目录" class="headerlink" title="创建分区挂载目录"></a>创建分区挂载目录</h4><p><code># mkdir /mnt/disk01</code></p><h4 id="挂载新分区"><a href="#挂载新分区" class="headerlink" title="挂载新分区"></a>挂载新分区</h4><p><code># mount /dev/sdb1 /mnt/disk01/</code></p><h4 id="查看磁盘使用情况"><a href="#查看磁盘使用情况" class="headerlink" title="查看磁盘使用情况"></a>查看磁盘使用情况</h4><p><code># df -h</code></p><pre><code>Filesystem           Size  Used Avail Use% Mounted on/dev/mapper/cl-root   18G   15G  3.3G  82% /devtmpfs             902M     0  902M   0% /devtmpfs                912M     0  912M   0% /dev/shmtmpfs                912M  8.6M  904M   1% /runtmpfs                912M     0  912M   0% /sys/fs/cgroup/dev/sda1            197M  119M   79M  61% /boottmpfs                183M     0  183M   0% /run/user/0# 多出来了这个/dev/sdb1             40G   49M   38G   1% /mnt/disk01</code></pre><h4 id="设置开机自动挂载磁盘"><a href="#设置开机自动挂载磁盘" class="headerlink" title="设置开机自动挂载磁盘"></a>设置开机自动挂载磁盘</h4><p><code># vim /etc/fstab</code></p><pre><code>/dev/sdb1    /mnt/disk01    ext4    defaults    0 0</code></pre><p>说明: </p><blockquote><p>第一列是设备名<br>第二列是挂载点（挂载目录）<br>第三列是要使用的文件系统<br>第四列是挂载参数，使用默认即可（defaults）<br>第五列是dump备份参数，1：每天备份，2：不定期备份，0：不备份<br>第六列是扇区检验参数，1：最早检验，2：标识为1的设备检验完之后检验，0：不检验</p></blockquote><h4 id="完工"><a href="#完工" class="headerlink" title="完工!"></a>完工!</h4>]]></content>
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CentOS </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>CentOS7下使用FTP搭建局域网内Yum源</title>
      <link href="/2018/01/24/YumRepoCreate/"/>
      <url>/2018/01/24/YumRepoCreate/</url>
      <content type="html"><![CDATA[<p>国内有很多Yum的镜像源，比如阿里、网易等等，速度很快，使用着很方便。<br>但是，有些公司的生产环境是不能连接外网的，这样的环境下，不作一些措施的话，在CentOS上安装软件会很麻烦，依赖包的问题会很让人头疼。<br>所以最好是搭建一个局域网内yum仓库源。</p><h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><p>需要预先下载好Everything的CentOS7安装光盘包，Everything版的软件包比较全。<br>这里以CentOS7.3为例:<br>CentOS-7-x86_64-Everything-1611.iso</p><p>截止到写这篇文章时，CentOS已经更新到了7.4<br>放上版本号对应列表:</p><blockquote><p>1406 - 7.0<br>1503 - 7.1<br>1511 - 7.2<br>1611 - 7.3<br>1708 - 7.4</p></blockquote><h1 id="配置FTP服务器"><a href="#配置FTP服务器" class="headerlink" title="配置FTP服务器"></a>配置FTP服务器</h1><ul><li>首先创建挂载目录<br><code># mkdir /media/cdrom</code></li><li>挂载ISO文件<ul><li>使用VMware安装的虚拟机挂载方式，需要先确认好虚拟机已经连接上ISO文件：<br><code># mount /dev/sr0 /media/cdrom</code></li><li>非CentOS7虚拟机，先上传ISO文件到某一目录，再挂载：<br><code># mount -t iso9660 -o loop /upload/CentOS-7-x86_64-Everything-1611.iso /media/cdrom</code></li></ul></li><li>安装ftp软件（已安装的话就不用再安装了，可以使用<code># rpm -qa | grep vsftpd</code>命令检测）<br><code># rpm -ivh /media/cdrom/Packages/vsftpd-3.0.2-21.el7.x86_64.rpm</code></li><li>启动vsftpd服务,并设为开机自启<br><code># systemctl start vsftpd</code><br>查看21端口：<br><code># netstat -ntl | grep 21</code><br>设为开机自启：<br><code># systemctl enable vsftpd</code><br>浏览器访问<code>ftp://ip_or_hostname</code><br>如果连接超时，说明开启了防火墙，需要关闭防火墙服务并关闭开机自启：<br><code># systemctl stop firewalld</code><br><code># systwmctl disable firewalld</code></li><li>部署yum仓库到ftp服务器<br>将安装光盘中的文件复制到ftp文件夹<code>/var/ftp/pub/</code>下<br>只复制两个目录(<strong>Packages</strong>,<strong>repodata</strong>)、一个文件(<strong>RPM-GPG-KEY-CentOS7</strong>)即可：<br><code># mkdir /var/ftp/pub/centos7</code><br><code># cp -rvf /media/cdrom/Packages /var/ftp/pub/centos7</code><br><code># cp -rvf /media/cdrom/repodata /var/ftp/pub/centos7</code><br><code># cp -rvf /media/cdrom/RPM-GPG-KEY-CentOS7 /var/ftp/pub/centos7</code><br>确认文件复制完毕以后就可以卸载光盘了<br><code># umount /media/cdrom</code><br>再次访问<code>ftp://ip_or_hostname</code>，就可以看到rpm包了<h1 id="配置yum仓库文件"><a href="#配置yum仓库文件" class="headerlink" title="配置yum仓库文件"></a>配置yum仓库文件</h1></li><li>备份原有的yum仓库文件<br><code># cp -rvf /etc/yum.repo.d /upload/</code></li><li>删除原有yum仓库配置文件<br><code># rm -rf /etc/yum.repo.d/*</code></li><li>编辑新的yum仓库文件<br><code># cd /etc/yum.repo.d</code><br><code># vim ftp.repo</code><pre><code>[ftp]# 名字随便填name=ftp-repo# ftp服务器路径baseurl=ftp://ip_or_hostname/pub/centos7/# 1为启用GPG KEY检查，0禁用gpgcheck=0# 1为启用该仓库，0禁用enabled=1# GPG KEY路径gpgkey=ftp://ip_or_hostname/pub/centos7/RPM-GPG-KEY-CentOS-7</code></pre></li><li>保存后,执行<br><code># yum clean all</code><pre><code>Loaded plugins: fastestmirror, langpacksCleaning repos: ftpCleaning up everythingCleaning up list of fastest mirrors</code></pre></li><li>生成缓存<br><code># yum makecache</code><pre><code>Loaded plugins: fastestmirror, langpacksftp                                                                                                                | 3.6 kB  00:00:00     (1/4): ftp/group_gz                                                                                                | 155 kB  00:00:00     (2/4): ftp/filelists_db                                                                                            | 6.6 MB  00:00:00     (3/4): ftp/primary_db                                                                                              | 5.6 MB  00:00:00     (4/4): ftp/other_db                                                                                                | 2.4 MB  00:00:00     Determining fastest mirrorsMetadata Cache Created</code></pre>然后就可以愉快的在内网环境下使用 <code># yum -y install package_name</code> 来安装软件啦！！！</li></ul>]]></content>
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CentOS </tag>
            
            <tag> Yum </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hadoop集群快捷启动/停止脚本</title>
      <link href="/2018/01/24/ClusterManager/"/>
      <url>/2018/01/24/ClusterManager/</url>
      <content type="html"><![CDATA[<p>由于原生Hadoop集群没有统一的管理工具，当向集群中部署了越来越多的组件后，集群的管理就变得非常繁琐复杂，包括集群的启动与停止，需要执行好多条命令，所以我就写了个一键启动、停止集群的shell脚本。</p><p>注意：</p><ul><li>该脚本在自己搭的伪分布式集群上随便玩玩就好，正式生产集群上慎用（一般正式环境上用原生Hadoop应该不会很多吧）！！！</li><li>放置该脚本的机器需要拥有对脚本中涉及到的机器的SSH免密钥登录权限</li><li>当前脚本包含组件有：Zookeeper,HDFS,YARN(HA),JobHistoryServer,HBase,HiveMetaStore,HiveServer2.</li><li>注意看脚本前面的说明<h2 id="脚本内容"><a href="#脚本内容" class="headerlink" title="脚本内容"></a>脚本内容</h2></li></ul><pre><code class="bash">#!/bin/bash# 启动|停止 原生Hadoop集群快捷脚本# 包含组件:Zookeeper,HDFS,YARN(HA),JobHistoryServer,HBase,HiveMetaStore,HiveServer2# 需要配置各节点间的SSH免密钥登录# 必须配置:Zookeeper,Hadoop,HBase,Hive的环境变量(/etc/profile), 如下:####################################################################################################### export ZOOKEEPER_HOME=/usr/hadoop/zookeeper-3.4.10# export HADOOP_PREFIX=/usr/hadoop/hadoop-2.7.4# export HBASE_HOME=/usr/hadoop/hbase-1.2.6# export HIVE_HOME=/usr/hadoop/hive-1.2.1# export PATH=$PATH:$ZOOKEEPER_HOME/bin:$HADOOP_PREFIX/bin:$HADOOP_PREFIX/sbin:$HBASE_HOME/bin:$HIVE_HOME/bin####################################################################################################### 如果Yarn未配置ResourceManager高可用，需要注释掉两行命令（第55、91行）即可# 如果未配置JobHistoryServer服务，需要注释掉第57、58、85、86这4行命令# zookeeper节点地址，多个地址用双引号包围，空格分隔export ZK_HOST=(&quot;master1&quot; &quot;master2&quot; &quot;worker1&quot;)# hdfs主节点地址，高可用配置的话填写其中任何一个都可export HDFS_HOST=master1# yarn主节点地址export YARN_HOST=master1# yarn备用节点地址export YARN_BAK_HOST=master2# JobHistoryServer节点地址export JOB_HOST=master2# hbase主节点地址，高可用配置的话填写其中任何一个都可export HBASE_HOST=master1# hive metastore服务节点地址export HMETA_HOST=master1# hive server2服务节点地址export HSERVER_HOST=master2# 集群启动用户export CLUSTER_USER=rootif [ $# -ne 1 ];then  echo -e &quot;\n\tUsage: $0 {start|stop}\n&quot;  exit 1;ficase &quot;$1&quot; instart)echo &quot;-------------------------- 启动Zookeeper ------------------------&quot;for zk_host in ${ZK_HOST[@]}do  echo -e &quot;\nStart Zk_Server On Host [$zk_host]...&quot;  ssh $CLUSTER_USER@$zk_host &quot;source /etc/profile;zkServer.sh start&quot;doneecho &quot;---------------------------- 启动HDFS ---------------------------&quot;ssh $CLUSTER_USER@$HDFS_HOST &quot;source /etc/profile;start-dfs.sh&quot;echo &quot;---------------------------- 启动YARN ---------------------------&quot;ssh $CLUSTER_USER@$YARN_HOST &quot;source /etc/profile;start-yarn.sh&quot;ssh $CLUSTER_USER@$YARN_BAK_HOST &quot;source /etc/profile;yarn-daemon.sh start resourcemanager&quot;echo &quot;---------------------- 启动JobHistoryServer ---------------------&quot;ssh $CLUSTER_USER@$JOB_HOST &quot;source /etc/profile;mr-jobhistory-daemon.sh start historyserver&quot;echo &quot;---------------------------- 启动HBase --------------------------&quot;ssh $CLUSTER_USER@$HBASE_HOST &quot;source /etc/profile;start-hbase.sh&quot;echo &quot;----------------------- 启动HiveMetaStore -----------------------&quot;echo &quot;Start HiveMetaStore On Host [$HMETA_HOST]...&quot;ssh $CLUSTER_USER@$HMETA_HOST &quot;source /etc/profile;nohup hive --service metastore &gt;&gt; /var/hivelog.log 2&gt;&amp;1 &amp;&quot;echo &quot;------------------------ 启动HiveServer2 ------------------------&quot;echo &quot;Start HiveServer2 On Host [$HSERVER_HOST]...&quot;ssh $CLUSTER_USER@$HSERVER_HOST &quot;source /etc/profile;nohup hiveserver2 &gt;&gt; /var/hivelog.log 2&gt;&amp;1 &amp;&quot;echo -e &quot;\n------------------------- 集群启动完成 --------------------------\n&quot;;;stop)echo &quot;----------------------- 停止HiveMetaStore -----------------------&quot;echo &quot;Stop HiveMetaStore On Host [$HMETA_HOST]...&quot;ssh $CLUSTER_USER@$HMETA_HOST &quot;pkill -f hive.metastore.HiveMetaStore&quot;echo &quot;------------------------ 停止HiveServer2 ------------------------&quot;echo &quot;Stop HiveServer2 On Host [$HSERVER_HOST]...&quot;ssh $CLUSTER_USER@$HSERVER_HOST &quot;pkill -f hive.service.server.HiveServer2&quot;echo &quot;---------------------------- 停止HBase --------------------------&quot;ssh $CLUSTER_USER@$HBASE_HOST &quot;source /etc/profile;stop-hbase.sh&quot;echo &quot;---------------------- 停止JobHistoryServer ---------------------&quot;ssh $CLUSTER_USER@$JOB_HOST &quot;source /etc/profile;mr-jobhistory-daemon.sh stop historyserver&quot;echo &quot;---------------------------- 停止YARN ---------------------------&quot;ssh $CLUSTER_USER@$YARN_HOST &quot;source /etc/profile;stop-yarn.sh&quot;ssh $CLUSTER_USER@$YARN_BAK_HOST &quot;source /etc/profile;yarn-daemon.sh stop resourcemanager&quot;echo &quot;---------------------------- 停止HDFS ---------------------------&quot;ssh $CLUSTER_USER@$HDFS_HOST &quot;source /etc/profile;stop-dfs.sh&quot;echo &quot;------------------------- 停止Zookeeper -------------------------&quot;for zk_host in ${ZK_HOST[@]}do  echo -e &quot;\nStop Zk_Server On Host [$zk_host]...&quot;  ssh $CLUSTER_USER@$zk_host &quot;source /etc/profile;zkServer.sh stop&quot;doneecho -e &quot;\n------------------------- 集群已停止运行 -------------------------\n&quot;;;*)echo -e &quot;\n\tUsage: $0 {start|stop}\n&quot;exit 1;;esacexit 0</code></pre><h2 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h2><p>复制脚本内容保存为<code>cluster.sh</code>文件，<br>将脚本上传到集群中任意一个节点（推荐管理节点），<br>并使用<code># chmod +x cluster.sh</code>赋予脚本可执行权限，</p><ul><li>集群启动<br><code># ./cluster.sh start</code></li><li>集群停止<br><code># ./cluster.sh stop</code></li></ul>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Hadoop </tag>
            
            <tag> shell </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>2017，再见。你好，2018</title>
      <link href="/2018/01/01/Hello2018/"/>
      <url>/2018/01/01/Hello2018/</url>
      <content type="html"><![CDATA[<p>2017，再见。你好，2018。</p><p>2017年，从头失败到脚的一年。<br>从1600公里到0，再从0到正无穷，之间充满了太多的无奈。<br>不管怎样，还是要感谢过去的一年里陪伴我的人，支持我的人，帮助过我的人，想念着我的人，有你们在，真好。</p><p>今天一月一日，是新的一天，也是新的一周，又是新的一月，还是新的一年。<br>在此写下2018年的一些目标：</p><ol><li>至少读12本书，也就是至少每月读一本书（人丑就要多读书。电子版，纸质都行）；</li><li>进行一次说走就走的旅行（单人也行，和朋友一块亦可，去哪里都无所谓）；</li><li>培养一项业余爱好（希望是乐器）；</li><li>找到自己的另一半（这个估计有点悬）；</li><li>工资翻倍。</li></ol><p>借用张嘉佳的《从你的全世界路过》中的一句话：</p><blockquote><p>照顾好自己，爱自己才能爱好别人。如果你压抑，痛苦，忧伤，不自由，又怎么可能在心里腾出温暖的房间，让重要的人住在里面。如果一颗心千疮百孔，住在里面的人就会白雨水打湿。</p></blockquote><p>山小杰你这个傻逼，2018年，照顾好自己。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hello2018/180101/7bDCdF973E.jpeg" alt="mark"></p>]]></content>
      
      <categories>
          
          <category> 杂记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 杂记 </tag>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hadoop-3.0.0体验</title>
      <link href="/2017/12/22/Hadoop3Install/"/>
      <url>/2017/12/22/Hadoop3Install/</url>
      <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>距离Hadoop 3.0.0 GA版的发布已经过去好多天了，前两天太忙，今天终于有点时间，配置了下Hadoop 3.0.0单机版。这篇文章就来介绍一下Hadoop 3.0.0相比Hadoop 2.7.x的一些比较明显的变化，以及部署过程中需要注意的一些地方。另外，本文含有大量图片，流量党慎入！</p><p>从2.x到3.x一个大版本的跨度，修改的地方还是很多的，比如jdk要求从7升级到了8、一些shell脚本重写、支持部署2个以上的NameNode节点、服务端口更改等等，具体的功能改进我就不一一说了，官网上都有：<a href="https://hadoop.apache.org/docs/r3.0.0/index.html" target="_blank" rel="noopener">Hadoop3.0介绍</a></p><p>下面是Hadoop从2.7.x -&gt; 3.0.0部分服务端口的调整情况，具体可以去<a href="https://issues.apache.org/jira/browse/HDFS-9427" target="_blank" rel="noopener">HDFS-9427</a>和<a href="https://issues.apache.org/jira/browse/HADOOP-12811" target="_blank" rel="noopener">HADOOP-12811</a>查看：</p><blockquote><p>Namenode ports: 50470 –&gt; 9871, 50070 –&gt; 9870, 8020 –&gt; 9820<br>Secondary NN ports: 50091 –&gt; 9869, 50090 –&gt; 9868<br>Datanode ports: 50020 –&gt; 9867, 50010 –&gt; 9866, 50475 –&gt; 9865, 50075 –&gt; 9864</p></blockquote><p>部署包bin目录文件:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/mE8HIj9IEf.png" alt="bin"><br>sbin目录文件:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/46bC35lae1.png" alt="sbin"><br>配置文件目录与2.7.3对比(左边2.7.3，右边3.0.0):<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/56LhDADkCf.png" alt="conf"></p><h1 id="Hadoop3-0单机版不靠谱配置"><a href="#Hadoop3-0单机版不靠谱配置" class="headerlink" title="Hadoop3.0单机版不靠谱配置"></a>Hadoop3.0单机版不靠谱配置</h1><p>注意标题，<strong>不靠谱配置</strong>！！！</p><p>部署过程也不细说了，跟之前差不多，配置文件名称除了<strong>节点配置文件</strong>由<strong>slaves</strong>改为了<strong>workers</strong>，其他都没变。这里就直接放基本配置信息了:</p><ol><li><strong>hadoop-env.sh</strong><pre><code class="bash">export JAVA_HOME=/usr/java/jdk1.8.0_131</code></pre></li><li><strong>core-site.xml</strong><pre><code class="xml">&lt;configuration&gt;&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master1:9000&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/hadoop/hadoop3/&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt;</code></pre></li><li><strong>hdfs-site.xml</strong><pre><code class="xml">&lt;configuration&gt;&lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;false&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt;</code></pre></li><li><strong>mapred-site.xml</strong><pre><code class="xml">&lt;configuration&gt;&lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt;</code></pre></li><li><strong>yarn-site.xml</strong><pre><code class="xml">&lt;configuration&gt;&lt;property&gt;   &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;   &lt;value&gt;mapreduce_shuffle&lt;/value&gt;  &lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt; &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt;</code></pre></li><li><strong>workers</strong>–这个配置文件在Hadoop 2.7.x版本的名字是<strong>slaves</strong><pre><code>master1</code></pre></li><li>系统环境变量配置<pre><code class="bash">export HADOOP_PREFIX=/usr/hadoop/hadoop-3.0.0export PATH=$PATH:$HADOOP_PREFIX/bin:$HADOOP_PREFIX/sbin</code></pre></li></ol><h1 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h1><p>配置完了，那就启动吧，启动命令跟之前一样：<code>start-dfs.sh</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/adImBABedl.png" alt="profile"><br>哎，有警告，原来是<strong>HADOOP_PREFIX</strong>不让用了，那就按照提示改成<strong>HADOOP_HOME</strong>：<br>重新配置环境变量如下:</p><pre><code class="bash">export HADOOP_HOME=/usr/hadoop/hadoop-3.0.0export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</code></pre><p>刷新环境变量后再次启动Hadoop：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/b73igbl3mc.png" alt="dfs-user"><br>报错!!!根据错误信息，发现必须要为这些命令指定一个用户。</p><p>看了一下Hadoop的配置文件，发现<strong>hadoop-env.sh</strong>文件中最后面有一段话：</p><pre><code># To prevent accidents, shell commands be (superficially) locked# to only allow certain users to execute certain subcommands.# It uses the format of (command)_(subcommand)_USER.</code></pre><p>即需要在<strong>hadoop-env.sh</strong>文件中新增3行配置：</p><pre><code class="bash">export HDFS_NAMENODE_USER=rootexport HDFS_DATANODE_USER=rootexport HDFS_SECONDARYNAMENODE_USER=root</code></pre><p>如图所示:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/G4Ik8kjIHg.png" alt="set-dfs-user"></p><p>再次执行<code>start-dfs.sh</code>，启动成功：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/c1DjJIGBGG.png" alt="start-dfs"></p><p>然后启动Yarn： <code>start-yarn.sh</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/dB6hcHeE7L.png" alt="yarn-user"><br>报错，所以还需要指定<strong>YARN_RESOURCEMANAGER_USER</strong>和<strong>YARN_NODEMANAGER_USER</strong>这两个用户，继续在<strong>hadoop-env.sh</strong>文件中新增2行配置：</p><pre><code class="bash">export YARN_RESOURCEMANAGER_USER=rootexport YARN_NODEMANAGER_USER=root</code></pre><p>如图所示:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/j4aKAaI2B3.png" alt="set-yarn-user"><br>再次启动，成功:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/L428dFh71j.png" alt="start-yarn"></p><p>所以<strong>hadoop-env.sh</strong>文件最终需要配置的是:</p><pre><code class="bash">export JAVA_HOME=/usr/java/jdk1.8.0_131export HDFS_NAMENODE_USER=rootexport HDFS_DATANODE_USER=rootexport HDFS_SECONDARYNAMENODE_USER=rootexport YARN_RESOURCEMANAGER_USER=rootexport YARN_NODEMANAGER_USER=root</code></pre><h1 id="WEB页面"><a href="#WEB页面" class="headerlink" title="WEB页面"></a>WEB页面</h1><p>由于端口变化，所以NameNode WEB UI 地址为：<code>http://namenode_ip_or_hostname:9870</code></p><p>Overview页面：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/iBKfllaHhg.png" alt="overview"></p><p>Datanodes页面：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/f8Jl3igcK8.png" alt="datanodes"></p><p>Explorer页面(这个页面变化还是挺大的)：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/57FGcB7dC7.png" alt="explorer"><br>可以直接对文件或者文件夹进行删除操作。<br>地址栏右边3个图标作用分别是:</p><ul><li><strong>创建文件夹</strong><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/gL1bhlHjfD.gif" alt="create-dir"></li><li><strong>上传文件</strong><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/hDghfj6fdG.gif" alt="upload-file"></li><li><strong>剪切文件</strong><br><strong>勾选</strong>你要进行剪切的文件，点击<strong>Cut</strong>，网页会提示你操作文件或文件夹的个数，然后找到目标位置，点击<strong>Paste</strong>即可：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/iB903hAhbI.gif" alt="move-file"></li></ul><p>网页上还可以进行权限、用户、用户组、文件副本数量的设置，不过默认的网页用户是<strong>dr.who</strong>，没有权限进行用户与用户组的设置：</p><ul><li><strong>设置权限</strong><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/KljecidK4h.png" alt="set-permission"></li><li><strong>修改用户</strong><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/fi8kh13424.png" alt="set-file-user1"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/Hd33iABD95.png" alt="set-file-user2"></li><li><strong>修改用户组</strong><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/eAdckHGbAf.png" alt="set-group"></li><li><strong>修改副本数</strong><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/b7I7f3eH08.png" alt="set-rep"><br>由于我这就一个节点，就没有测试这一项。</li></ul><p>点击文件，还可以直接对文件内容进行预览，可以分别查看前32K和后32K：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/lK4hF444Kc.gif" alt="文件预览"></p><p>然后就是Datanode WEB UI 地址了：<a href="http://datanode_ip_or_hostname:9864" target="_blank" rel="noopener">http://datanode_ip_or_hostname:9864</a><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/mch50D4061.png" alt="datanode-web"><br>这部分没啥好说的。</p><h1 id="Wordcount"><a href="#Wordcount" class="headerlink" title="Wordcount"></a>Wordcount</h1><p>找个文件进行Wordcount测试：<br><code># yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0.jar wordcount /staroon/input/ /staroon/output/</code><br>日志会有提示：</p><blockquote><p>2017-12-22 11:15:40,838 INFO conf.Configuration: resource-types.xml not found<br>2017-12-22 11:15:40,839 INFO resource.ResourceUtils: Unable to find ‘resource-types.xml’.</p></blockquote><p>不过不影响Job的执行。关于resource-types.xml详细信息，可以去官网查看:<br><a href="https://hadoop.apache.org/docs/r3.0.0/hadoop-yarn/hadoop-yarn-site/ResourceModel.html" target="_blank" rel="noopener">https://hadoop.apache.org/docs/r3.0.0/hadoop-yarn/hadoop-yarn-site/ResourceModel.html</a></p><p>计算结果可以直接在网页上看，可以说是非常方便了：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/3K6EaaGCDK.png" alt="job1"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/Hadoop3Install/171222/h6B5fF6HC1.png" alt="job2"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>以上就是对Hadoop3.0.0进行的很小一部分表面上的体验，但还是给了我焕然一新的感觉，安全性、易用性方面都有了很大的提升，尤其是Namenode网页端，上传、移动、删除、预览文件，修改权限等都可以直接在网页上进行，简直太人性化。</p>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Hadoop </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hive-1.2.1安装配置</title>
      <link href="/2017/12/09/HiveInstall/"/>
      <url>/2017/12/09/HiveInstall/</url>
      <content type="html"><![CDATA[<p>上一篇：<a href="https://staroon.pro/2017/11/30/HBaseInstall/">HBase安装</a><br>这一篇进行Hive-1.2.1的安装与基本配置。<br>Hive下载：<a href="https://mirror.bit.edu.cn/apache/hive/" target="_blank" rel="noopener">点击进入下载Hive</a></p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p><code># tar -zxvf apache-hive-1.2.1-bin.tar.gz -C /usr/hadoop/</code><br><code># cd /usr/hadoop</code><br><code># mv apache-hive-1.2.1-bin hive-1.2.1</code></p><h2 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h2><p><code># vim /etc/profile</code></p><pre><code class="profile">export HIVE_HOME=/usr/hadoop/hive-1.2.1export PATH=$PATH:$HIVE_HOME/bin</code></pre><p><code># source /etc/profile</code></p><h2 id="配置hive-env-sh"><a href="#配置hive-env-sh" class="headerlink" title="配置hive-env.sh"></a>配置<code>hive-env.sh</code></h2><p><code># cd $HIVE_HOME/conf</code><br><code># cp hive-env.sh.template hive-env.sh</code><br><code># vim hive-env.sh</code></p><pre><code class="profile">HADOOP_HOME=/usr/hadoop/hadoop-2.7.3</code></pre><h2 id="配置hive-site-xml（需要新建）"><a href="#配置hive-site-xml（需要新建）" class="headerlink" title="配置hive-site.xml（需要新建）"></a>配置<code>hive-site.xml</code>（需要新建）</h2><p>指定元数据库存储库，需要预先创建好。<br>这里使用<code>Mysql</code>，数据库名为<code>hive</code>，字符集为<code>latin1</code>。<br>为什么不用<code>utf8</code>?<br>你自己试一下就知道了~<br><code># vim hive-site.xml</code></p><pre><code>&lt;configuration&gt;  &lt;property&gt;    &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;    &lt;value&gt;jdbc:mysql://master1:3306/hive?createDatabaseIfNotExist=true&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;    &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;    &lt;value&gt;root&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;    &lt;value&gt;123456&lt;/value&gt;  &lt;/property&gt;&lt;/configuration&gt;</code></pre><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><ol><li>启动前需要确保Hadoop服务已启动!!!</li><li>启动前需要添加<strong><a href="https://dev.mysql.com/downloads/connector/j/" target="_blank" rel="noopener">Mysq连接驱动</a></strong>到<code>$HIVE_HOME/lib/</code>目录下!!!    </li></ol><h3 id="启动HiveMetaStore"><a href="#启动HiveMetaStore" class="headerlink" title="启动HiveMetaStore"></a>启动HiveMetaStore</h3><ol><li>直接启动:<br><code># hive --service metastore</code></li><li>后台启动（关闭shell连接依然存在）<br><code># nohup hive --service metastore &gt;&gt; /var/hivelog.log 2&gt;&amp;1 &amp;</code><blockquote><p>默认metastore端口为：9083</p></blockquote></li></ol><h3 id="启动HiveServer2"><a href="#启动HiveServer2" class="headerlink" title="启动HiveServer2"></a>启动HiveServer2</h3><ol><li>直接启动:<br><code># hiveserver2</code></li><li>后台启动<br><code># nohup hiveserver2 &gt;&gt; /var/hivelog.log 2&gt;&amp;1 &amp;</code><blockquote><p>默认hive.server2.thrift.port=10000<br>默认hive.server2.thrift.http.port=10001</p></blockquote></li></ol><p>查看进程<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HiveInstall/171209/k5IfkHlB9E.png" alt="jps"></p><h2 id="Hive命令行工具（推荐使用Beeline）"><a href="#Hive命令行工具（推荐使用Beeline）" class="headerlink" title="Hive命令行工具（推荐使用Beeline）"></a>Hive命令行工具（推荐使用Beeline）</h2><h3 id="使用hive-cli"><a href="#使用hive-cli" class="headerlink" title="使用hive cli"></a>使用hive cli</h3><p><code># hive</code></p><pre><code>[root@master1 conf]# hiveLogging initialized using configuration in jar:file:/usr/hadoop/hive-1.2.1/lib/hive-common-1.2.1.jar!/hive-log4j.propertieshive&gt;创建数据库:hive&gt; create database test;hive&gt; use test；创建people表:hive&gt; create table people(name string, age bigint, adress string) row format delimited fields terminated by &#39;\t&#39;;加载数据到people表:hive&gt; load data inpath &#39;/upload/word.txt&#39; overwrite into table people;查询sql:hive&gt; select * from people;</code></pre><h3 id="使用Beeline"><a href="#使用Beeline" class="headerlink" title="使用Beeline"></a>使用Beeline</h3><p>需要确保hiveserver2服务已启动。<br><code># beeline</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HiveInstall/171209/CHb28B0li4.png" alt="beeline"></p><p>退出beeline:<code>!q</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HiveInstall/171209/bdLJGh9d3B.png" alt="exit"></p><h2 id="OVER"><a href="#OVER" class="headerlink" title="OVER"></a>OVER</h2><p>Hive安装部分已结束！</p>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Hive </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>HBase-1.2.6高可用配置</title>
      <link href="/2017/11/30/HBaseInstall/"/>
      <url>/2017/11/30/HBaseInstall/</url>
      <content type="html"><![CDATA[<p>接上一篇:<a href="https://staroon.pro/2017/11/18/HadoopInstall/">Hadoop安装</a><br>这一篇进行HBase-1.2.6(高可用)的安装与基本配置。<br>HBase下载：<a href="https://mirror.bit.edu.cn/apache/hbase/" target="_blank" rel="noopener">点击进入下载</a></p><p>HBase相关服务分配：</p><table><thead><tr><th style="text-align:center">Hostname</th><th style="text-align:center">HMaster</th><th style="text-align:center">Backup Master</th><th style="text-align:center">HRegionServer</th></tr></thead><tbody><tr><td style="text-align:center">master1</td><td style="text-align:center">1</td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">master2</td><td style="text-align:center"></td><td style="text-align:center">1</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">worker1</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">worker2</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center">1</td></tr></tbody></table><h2 id="安装HBase-所有节点"><a href="#安装HBase-所有节点" class="headerlink" title="安装HBase(所有节点)"></a>安装HBase(所有节点)</h2><p><code># tar -zxvf hbase-1.2.6-bin.tar.gz -C /usr/hadoop/</code></p><h2 id="配置HBase环境变量-所有节点"><a href="#配置HBase环境变量-所有节点" class="headerlink" title="配置HBase环境变量 (所有节点)"></a>配置HBase环境变量 (所有节点)</h2><p><code># vim /etc/profile</code></p><pre><code class="profile">export HBASE_HOME=/usr/hadoop/hbase-1.2.6export PATH=$PATH:$HBASE_HOME/bin</code></pre><p><code># source /etc/profile</code></p><h2 id="修改hbase-env-sh"><a href="#修改hbase-env-sh" class="headerlink" title="修改hbase-env.sh"></a>修改<code>hbase-env.sh</code></h2><p>进入到HBase配置文件目录:<br><code># cd /usr/hadoop/hbase-1.2.6/conf</code><br><code># vim hbase-env.sh</code></p><pre><code>export JAVA_HOME=/usr/java/jdk1.8.0_131export HBASE_MANAGES_ZK=false    # 不使用hbase内置的zookeper</code></pre><h2 id="修改regionservers"><a href="#修改regionservers" class="headerlink" title="修改regionservers"></a>修改<code>regionservers</code></h2><p><code># vim regionservers</code><br>删除:localhost</p><pre><code>worker1worker2</code></pre><h2 id="配置backup-masters-默认没有-需要新建"><a href="#配置backup-masters-默认没有-需要新建" class="headerlink" title="配置backup-masters(默认没有,需要新建)"></a>配置<code>backup-masters</code>(默认没有,需要新建)</h2><p><code># vim backup-masters</code></p><pre><code>master2    # 备用master的hostname</code></pre><h2 id="修改hbase-site-xml"><a href="#修改hbase-site-xml" class="headerlink" title="修改hbase-site.xml"></a>修改<code>hbase-site.xml</code></h2><p><code># vim hbase-site.xml</code></p><pre><code class="xml">&lt;configuration&gt;  &lt;property&gt;    &lt;name&gt;hbase.rootdir&lt;/name&gt;    &lt;value&gt;hdfs://ns1/hbase&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;    &lt;value&gt;true&lt;/value&gt;  &lt;/property&gt;  &lt;property&gt;    &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;    &lt;value&gt;master1,master2,worker1&lt;/value&gt;  &lt;/property&gt;&lt;/configuration&gt;</code></pre><h2 id="把hadoop的hdfs-site-xml和core-site-xml复制到hbase-conf下"><a href="#把hadoop的hdfs-site-xml和core-site-xml复制到hbase-conf下" class="headerlink" title="把hadoop的hdfs-site.xml和core-site.xml复制到hbase/conf下"></a>把hadoop的<code>hdfs-site.xml</code>和<code>core-site.xml</code>复制到<code>hbase/conf</code>下</h2><p><code># cp /usr/hadoop/hadoop-2.7.3/etc/hadoop/hdfs-site.xml /usr/hadoop/hbase-1.2.6/conf/</code><br><code># cp /usr/hadoop/hadoop-2.7.3/etc/hadoop/core-site.xml /usr/hadoop/hbase-1.2.6/conf/</code></p><h2 id="复制hbase-conf文件夹里的内容到其他节点"><a href="#复制hbase-conf文件夹里的内容到其他节点" class="headerlink" title="复制hbase/conf文件夹里的内容到其他节点"></a>复制<code>hbase/conf</code>文件夹里的内容到其他节点</h2><p><code># scp * root@master2:/usr/hadoop/hbase-1.2.6/conf</code><br><code># scp * root@worker1:/usr/hadoop/hbase-1.2.6/conf</code><br><code># scp * root@worker2:/usr/hadoop/hbase-1.2.6/conf</code></p><h2 id="启动hbase-在master上执行，其它机器不需要执行"><a href="#启动hbase-在master上执行，其它机器不需要执行" class="headerlink" title="启动hbase (在master上执行，其它机器不需要执行)"></a>启动hbase (在master上执行，其它机器不需要执行)</h2><p>启动之前需要确保Hadoop和Zookeeper集群已启动!!!<br>启动hbase：<br><code># start-hbase.sh</code><br>检查hbase启动情况：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HBaseInstall/171130/CdeHaKFG5k.png" alt="jps"><br>访问网页查看<br><strong>Master</strong>:<code>http://hm-ip:16010/master-status</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HBaseInstall/171130/KFHK2fmG3e.png" alt="hmaster"><br><strong>Backup Master</strong>: <code>http://bak-hm-ip:16010/master-status</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HBaseInstall/171130/l39HE00gI2.png" alt="bak-master"><br><strong>RegionServer</strong>: <code>http://rs-ip:16030/rs-status</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HBaseInstall/171130/2c1G28l77d.png" alt="rs"></p><h2 id="测试Master高可用"><a href="#测试Master高可用" class="headerlink" title="测试Master高可用"></a>测试Master高可用</h2><p>kill掉master1上的HMaster进程<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HBaseInstall/171130/FfmH2leGh1.png" alt="kill"><br>去网页查看，master2已经变为Master状态<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HBaseInstall/171130/eBc9B4c664.png" alt="ha"><br>高可用测试成功!</p><h2 id="OVER"><a href="#OVER" class="headerlink" title="OVER"></a>OVER</h2><p>HBase的安装部分已结束!</p>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> HBase </tag>
            
            <tag> 高可用 </tag>
            
            <tag> HA </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hadoop-2.7.3高可用配置</title>
      <link href="/2017/11/18/HadoopInstall/"/>
      <url>/2017/11/18/HadoopInstall/</url>
      <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p><a href="https://staroon.pro/2017/11/05/SetEnv/">前一篇文章</a>已经大致介绍了安装Hadoop需要的一些环境准备工作，这篇文章就来进行下原生Hadoop（完全分布式+高可用）的安装与配置。</p><p>Hadoop Namenode存在单点故障问题，Hadoop2.0版本以后可以开启两个Namenode来解决这个问题，一个为Active Namenode管理集群，一个为Standby Namenode作为热备份。</p><p>Standby Namenode节点与Active Namenode节点之间数据的同步依赖于JournalNode服务。<br>Zookeeper和ZKFC(ZKFailoverController)服务可以保证集群中有且只有一个Active状态的Namenode。</p><p>本文同时配置了<code>NameNode</code>和<code>Resource Manager</code>的高可用(HA)。</p><p>Zookeeper下载：<a href="https://mirror.bit.edu.cn/apache/zookeeper/" target="_blank" rel="noopener">点击进入下载Zookeeper</a><br>Hadoop下载：<a href="https://mirror.bit.edu.cn/apache/hadoop/common/" target="_blank" rel="noopener">点击进入下载Hadoop</a></p><p>注：本文使用的</p><blockquote><p>Zookeeper版本为3.4.10<br>Hadoop版本为2.7.3   </p></blockquote><h2 id="Zookeeper安装与配置"><a href="#Zookeeper安装与配置" class="headerlink" title="Zookeeper安装与配置"></a>Zookeeper安装与配置</h2><p>需要部署奇数(2N+1)个Zookeeper服务，至少3个，3个节点应该具有相同的硬件配置。</p><h3 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h3><p><code># tar -zxvf zookeeper-3.4.10.tar.gz -C /usr/hadoop/</code></p><h3 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h3><p><code># vim /etc/profile</code></p><pre><code>export ZOOKEEPER_HOME=/usr/hadoop/zookeeper-3.4.10export PATH=$PATH:$ZOOKEEPER_HOME/bin</code></pre><p><code># source /etc/profile</code></p><h3 id="配置Zookeeper"><a href="#配置Zookeeper" class="headerlink" title="配置Zookeeper"></a>配置Zookeeper</h3><p><code># cd /usr/hadoop/zookeeper-3.4.10/conf</code><br><code># cp zoo_sample.cfg zoo.cfg</code><br><code># vim zoo.cfg</code></p><pre><code class="profile">tickTime=2000initLimit=10syncLimit=5# 数据存放位置dataDir=/hadoop/zookeeper/zkdata# 日志存放位置dataLogDir=/hadoop/zookeeper/zklog# 端口clientPort=2181# 指定部署Zookeeper的三个节点server.1=master1:2888:3888server.2=master2:2888:3888server.3=worker1:2888:3888</code></pre><h4 id="创建文件夹"><a href="#创建文件夹" class="headerlink" title="创建文件夹"></a>创建文件夹</h4><p><code># mkdir -p /hadoop/zookeeper/zkdata</code><br><code># mkdir /hadoop/zookeeper/zklog</code></p><h4 id="创建myid"><a href="#创建myid" class="headerlink" title="创建myid"></a>创建<code>myid</code></h4><p>在<code>/hadoop/zookeeper/zkdata</code>下创建文件<code>myid</code><br>编辑内容为当前server数值(1,2,3)，需要与上面<code>zoo.cfg</code>中的配置相对应：</p><blockquote><p>master1节点 -&gt; 1<br>master2节点 -&gt; 2<br>worker1节点 -&gt; 3   </p></blockquote><p><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171118/JclclJk8dE.png" alt="zk-myid"></p><h2 id="Hadoop安装与配置"><a href="#Hadoop安装与配置" class="headerlink" title="Hadoop安装与配置"></a>Hadoop安装与配置</h2><h3 id="解压-1"><a href="#解压-1" class="headerlink" title="解压"></a>解压</h3><p><code># tar -zxvf hadoop-2.7.3.tar.gz -C /usr/hadoop/</code><br>进入配置文件目录<br><code># cd /usr/hadoop/hadoop-2.7.3/etc/hadoop/</code></p><h3 id="配置core-site-xml"><a href="#配置core-site-xml" class="headerlink" title="配置core-site.xml"></a>配置<code>core-site.xml</code></h3><pre><code class="xml">&lt;!-- 指定hdfs nameservice --&gt;&lt;property&gt;    &lt;name&gt;fs.defaultFS&lt;/name&gt;    &lt;value&gt;hdfs://ns1/&lt;/value&gt;&lt;/property&gt;&lt;!-- 开启垃圾回收站功能，值为检查点被删除的分钟数，设为0为禁用 --&gt;&lt;property&gt;    &lt;name&gt;fs.trash.interval&lt;/name&gt;    &lt;value&gt;1440&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定hadoop数据文件夹 --&gt;&lt;property&gt;    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;    &lt;value&gt;/hadoop/hadoop/tmp&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定Zookeeper地址及端口 --&gt;&lt;property&gt;    &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;    &lt;value&gt;master1:2181,master2:2181,worker1:2181&lt;/value&gt;&lt;/property&gt;</code></pre><h3 id="配置hdfs-site-xml"><a href="#配置hdfs-site-xml" class="headerlink" title="配置hdfs-site.xml"></a>配置<code>hdfs-site.xml</code></h3><p>说明: 启用 NameNode HA的话,不再需要开启Secondary NameNode</p><pre><code class="xml">&lt;property&gt;    &lt;name&gt;dfs.nameservices&lt;/name&gt;    &lt;value&gt;ns1&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;dfs.ha.namenodes.ns1&lt;/name&gt;    &lt;value&gt;nn1,nn2&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;dfs.namenode.rpc-address.ns1.nn1&lt;/name&gt;    &lt;value&gt;master1:8020&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;dfs.namenode.http-address.ns1.nn1&lt;/name&gt;    &lt;value&gt;master1:50070&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;dfs.namenode.rpc-address.ns1.nn2&lt;/name&gt;    &lt;value&gt;master2:8020&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;dfs.namenode.http-address.ns1.nn2&lt;/name&gt;    &lt;value&gt;master2:50070&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定JN节点 --&gt;&lt;property&gt;    &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;    &lt;value&gt;qjournal://master1:8485;master2:8485;worker1:8485/ns1&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定JN数据在本地磁盘的存放位置 --&gt;&lt;property&gt;    &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;    &lt;value&gt;/hadoop/hadoop/edits&lt;/value&gt;&lt;/property&gt;&lt;!-- 开启NameNode自动故障切换 --&gt;&lt;property&gt;    &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;    &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;!-- 配置自动故障切换实现方式 --&gt;&lt;property&gt;    &lt;name&gt;dfs.client.failover.proxy.provider.ns1&lt;/name&gt;    &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;    &lt;value&gt;    sshfence      shell(/bin/true)      &lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;    &lt;value&gt;/root/.ssh/id_rsa&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt;    &lt;value&gt;30000&lt;/value&gt;&lt;/property&gt;&lt;!-- 配置block副本数 --&gt;&lt;property&gt;    &lt;name&gt;dfs.replication&lt;/name&gt;    &lt;value&gt;2&lt;/value&gt;&lt;/property&gt;</code></pre><h3 id="配置yarn-site-xml"><a href="#配置yarn-site-xml" class="headerlink" title="配置yarn-site.xml"></a>配置<code>yarn-site.xml</code></h3><pre><code class="xml">&lt;!-- 启用RM高可用 --&gt;&lt;property&gt;    &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;    &lt;value&gt;true&lt;/value&gt;&lt;/property&gt;&lt;!-- 自定义RM的id --&gt;&lt;property&gt;    &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;    &lt;value&gt;yrc&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;    &lt;value&gt;rm1,rm2&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定分配RM服务的地址 --&gt;&lt;property&gt;    &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt;    &lt;value&gt;master1&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt;    &lt;value&gt;master2&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;yarn.resourcemanager.webapp.address.rm1&lt;/name&gt;    &lt;value&gt;master1:8088&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;yarn.resourcemanager.webapp.address.rm2&lt;/name&gt;    &lt;value&gt;master2:8088&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定zk集群地址 --&gt;  &lt;property&gt;    &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;    &lt;value&gt;master1:2181,master2:2181,worker1:2181&lt;/value&gt;&lt;/property&gt;&lt;property&gt;    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;</code></pre><h3 id="配置marped-site-xml"><a href="#配置marped-site-xml" class="headerlink" title="配置marped-site.xml"></a>配置<code>marped-site.xml</code></h3><pre><code class="xml">&lt;!-- 指定mr框架为yarn --&gt;  &lt;property&gt;  &lt;name&gt;mapreduce.framework.name&lt;/name&gt;  &lt;value&gt;yarn&lt;/value&gt;  &lt;/property&gt;</code></pre><h3 id="配置hadoop-env-sh"><a href="#配置hadoop-env-sh" class="headerlink" title="配置hadoop-env.sh"></a>配置<code>hadoop-env.sh</code></h3><pre><code class="bash">export JAVA_HOME=/usr/java/jdk1.8.0_131</code></pre><h3 id="配置slaves"><a href="#配置slaves" class="headerlink" title="配置slaves"></a>配置<code>slaves</code></h3><p>指定DataNode节点(hostname)</p><pre><code>worker1worker2</code></pre><h3 id="将配置好的Hadoop复制到其他节点"><a href="#将配置好的Hadoop复制到其他节点" class="headerlink" title="将配置好的Hadoop复制到其他节点"></a>将配置好的Hadoop复制到其他节点</h3><p><code># scp -r hadoop-2.7.3 root@master2:/usr/hadoop/</code><br><code>...</code></p><h3 id="配置环境变量-1"><a href="#配置环境变量-1" class="headerlink" title="配置环境变量"></a>配置环境变量</h3><p><code># vim /etc/profile</code></p><pre><code class="bash">export HADOOP_PREFIX=/usr/hadoop/hadoop-2.7.3export PATH=$PATH:$HADOOP_PREFIX/bin:$HADOOP_PREFIX/sbin</code></pre><p><code># source /etc/profile</code></p><h2 id="集群启动"><a href="#集群启动" class="headerlink" title="集群启动"></a>集群启动</h2><h3 id="启动Zookeeper"><a href="#启动Zookeeper" class="headerlink" title="启动Zookeeper"></a>启动<code>Zookeeper</code></h3><p>在master1,master2,worker1上执行:<br><code># zkServer.sh start</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/eEH6bB7dL2.png" alt="zkStart"><br>查看状态<code># zkServer.sh status</code>，一个leader，两个flower<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/fmjkdD0djD.png" alt="zkStatus"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/L3iD3LaiJC.png" alt="zkStatus1"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/KbcK7FHLfA.png" alt="zkStatus2"></p><h3 id="启动JournalNode"><a href="#启动JournalNode" class="headerlink" title="启动JournalNode"></a>启动<code>JournalNode</code></h3><p>在master1,master2,worker1上执行:<br><code># hadoop-daemon.sh start journalnode</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/2A2310GjGL.png" alt="JNStart"></p><h3 id="格式化HDFS"><a href="#格式化HDFS" class="headerlink" title="格式化HDFS"></a>格式化<code>HDFS</code></h3><p>在master1上格式化namenode:<br><code># hdfs namenode -format</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/IhHdKei9if.png" alt="nn1"><br>在master1上启动namenode:<br><code># hadoop-daemon.sh start namenode</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/FfF56if0i2.png" alt="nnStart"><br>在master2上格式化namenode:<br><code># hdfs namenode -bootstrapStandby</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/bGddejK2jd.png" alt="nn2"></p><h3 id="格式化zkfc"><a href="#格式化zkfc" class="headerlink" title="格式化zkfc"></a>格式化<code>zkfc</code></h3><p>在master1上执行:<br><code># hdfs zkfc -formatZK</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/kj9imci79h.png" alt="zkfc"></p><h3 id="启动HDFS"><a href="#启动HDFS" class="headerlink" title="启动HDFS"></a>启动<code>HDFS</code></h3><p>在master1上执行:<br><code># start-dfs.sh</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/26hKHabgda.png" alt="hdfsStart"></p><h3 id="启动Yarn"><a href="#启动Yarn" class="headerlink" title="启动Yarn"></a>启动<code>Yarn</code></h3><p>在master1上执行:<br><code># start-yarn.sh</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/Fa7KBbeDCI.png" alt="yarn1"><br>在master2上执行:<br><code># yarn-daemon.sh start resourcemanager</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/eKhkHe65JD.png" alt="yarn2"></p><h3 id="启动完成"><a href="#启动完成" class="headerlink" title="启动完成"></a>启动完成</h3><p>Hadoop已经启动完成，可以访问网页：<code>namenode-ip:50070</code>来查看集群状态并浏览集群文件</p><h2 id="验证NameNode高可用"><a href="#验证NameNode高可用" class="headerlink" title="验证NameNode高可用"></a>验证NameNode高可用</h2><p>首先分别访问：<code>master1:50070</code>和<code>master2:50070</code>网页，查看这两个节点的状态：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/HLhmaF5Ih4.png" alt="n1"><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/GHHCHBJk8J.png" alt="n2"><br>可以看到，master1节点为active状态。<br>然后我们手动kill掉master1的namenode服务：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/cL625hIgH0.png" alt="kill"><br>去master2:50070网页查看发现master2已经变为active状态：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171203/CdGCb1icCl.png" alt="HATest"><br>我们再手动启动master1的namenode服务：<br><code># hadoop-daemon.sh start namenode</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/CHH7il7318.png" alt="HA2"><br>去master1:50070网页查看，master1处于standby状态<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/HadoopInstall/171130/E1mEfJ8Lf8.png" alt="HA22"><br>自动故障切换验证成功！！！</p><h2 id="OVER"><a href="#OVER" class="headerlink" title="OVER"></a>OVER</h2><p>至此，Hadoop的部署已经完成，本文给出的配置只是最简单、最基础的配置，其它详细参数配置请参考官网：<a href="https://hadoop.apache.org/docs/r2.7.3/" target="_blank" rel="noopener">Apache Hadoop 2.7.3 Doc</a></p><p>当然你也可以测试一下MR任务的执行，跑一个WordCount，这里就不演示了。</p>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Hadoop </tag>
            
            <tag> 高可用 </tag>
            
            <tag> HA </tag>
            
            <tag> Zookeeper </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hadoop集群搭建系统环境准备</title>
      <link href="/2017/11/05/SetEnv/"/>
      <url>/2017/11/05/SetEnv/</url>
      <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Hadoop集群的搭建需要一系列的环境准备，包括操作系统参数的调整以及一些必备软件的安装等。</p><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>硬件配置我就不说了，CDH官网有说明：<a href="https://blog.cloudera.com/blog/2013/08/how-to-select-the-right-hardware-for-your-new-hadoop-cluster/" target="_blank" rel="noopener">硬件配置</a></p><p>测试使用嘛，随便搞搞就行。</p><p>操作系统就选用很受欢迎的开源免费的CentOS了。<br>以4个节点的测试集群为例：</p><table><thead><tr><th style="text-align:center">ip</th><th style="text-align:center">hostname</th></tr></thead><tbody><tr><td style="text-align:center">192.168.0.201</td><td style="text-align:center">master1</td></tr><tr><td style="text-align:center">192.168.0.202</td><td style="text-align:center">master2</td></tr><tr><td style="text-align:center">192.168.0.203</td><td style="text-align:center">worker1</td></tr><tr><td style="text-align:center">192.168.0.204</td><td style="text-align:center">worker2</td></tr></tbody></table><p>所有节点安装CentOS7-x64操作系统</p><h3 id="修改主机名hostname"><a href="#修改主机名hostname" class="headerlink" title="修改主机名hostname"></a>修改主机名hostname</h3><p><code># vim /etc/hostname</code><br><code>master1</code><br>或者<br><code># hostnamectl set-hostname master1</code><br>查看hostname<br><code># hostname</code></p><h3 id="配置ip"><a href="#配置ip" class="headerlink" title="配置ip"></a>配置ip</h3><p><code># vim /etc/sysconfig/network-scripts/ifcfg-eth33/</code></p><pre><code class="properties">TYPE=EthernetBOOTPROTO=static                # 设置为静态DEFROUTE=yesPEERDNS=yesPEERROUTES=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_PEERDNS=yesIPV6_PEERROUTES=yesIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyNAME=ens33DEVICE=ens33ONBOOT=yes                      # 开机启用IPADDR=192.168.0.201            # ip地址GATEWAY=xxx.xxx.xxx.xxx         # 网关NETMASK=xxx.xxx.xxx.xxx         # 子网掩码DNS=xxx.xxx.xxx.xxx             # DNS</code></pre><p>重启服务<br><code># systemctl restart network</code><br>查看ip<br><code># ip addr</code></p><h3 id="修改Hosts"><a href="#修改Hosts" class="headerlink" title="修改Hosts"></a>修改Hosts</h3><p><code># vim /etc/hosts</code></p><pre><code>192.168.0.201    master1192.168.0.202    master2192.168.0.203    worker1192.168.0.204    worker2</code></pre><h3 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h3><p>Hadoop集群运行需要用到很多端口，关掉防火墙省事些。<br>关闭防火墙:<br><code># systemctl stop firewalld.service</code><br>关闭开机自动启动:<br><code># systemctl disable firewalld.service</code></p><h3 id="关闭SELinux"><a href="#关闭SELinux" class="headerlink" title="关闭SELinux"></a>关闭SELinux</h3><p>编辑<code>/etc/selinux/config</code>文件，将<code>SELINUX=enforcing</code>改为<code>SELINUX=disabled</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/SetEnv/SELinux.png" alt=""></p><h3 id="配置SSH免密码登陆"><a href="#配置SSH免密码登陆" class="headerlink" title="配置SSH免密码登陆"></a>配置SSH免密码登陆</h3><p>1.查看ssh服务状态(CentOS默认已安装并开机自启动的)<br><code># service sshd status</code><br>2.生成私钥和公钥(所有节点都执行)<br><code># ssh-keygen -t rsa</code><br><code># cd ~/.ssh</code><br>3.在master2节点<br><code># cp id_rsa.pub master2.id_rsa.pub</code><br><code># scp master2.id_rsa.pub root@master1:~/.ssh</code><br>4.在worker1节点<br><code># cp id_rsa.pub worker1.id_rsa.pub</code><br><code># scp worker1.id_rsa.pub root@master1:~/.ssh</code><br>5.在worker2节点<br><code># cp id_rsa.pub worker2.id_rsa.pub</code><br><code># scp worker2.id_rsa.pub root@master1:~/.ssh</code><br>6.在master1节点<br>将所有节点的公钥信息保存到主节点下的authorized_keys（新生成的）文件中<br><code># cat id_rsa.pub &gt;&gt; authorized_keys</code><br><code># cat master2.id_rsa.pub &gt;&gt; authorized_keys</code><br><code># cat worker1.id_rsa.pub &gt;&gt; authorized_keys</code><br><code># cat worker2.id_rsa.pub &gt;&gt; authorized_keys</code><br>如图所示:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/SetEnv/ssh1.png" alt=""><br>7.再把authorized_keys文件拷贝到其它节点上去<br><code># scp authorized_keys root@master2:~/.ssh</code><br><code># scp authorized_keys root@worker1:~/.ssh</code><br><code># scp authorized_keys root@worker2:~/.ssh</code><br>8.测试SSH:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/SetEnv/ssh2.png" alt=""></p><h3 id="配置ntp时间同步"><a href="#配置ntp时间同步" class="headerlink" title="配置ntp时间同步"></a>配置ntp时间同步</h3><p>集群中所有节点必须保持时间同步，如果时间相差较大会引起问题(如HBase服务无法正常启动)</p><p>实现方法：master1节点作为ntp服务器，对其它节点提供时间同步服务。 所有其它节点以master1节点为基础同步时间。<br>1.所有节点安装相关ntp组件<br><code># yum install ntp/或者手动安装rpm包</code><br>2.所有节点设置时区,中国上海:<br><code># timedatectl set-timezone Asia/Shanghai</code><br>3.启动ntp，以及设置开机启动<br><code># systemctl start ntpd</code><br><code># systemctl enable ntpd</code><br>4.在master1节点上设置现在的准确时间<br><code># date -s “2017-06-15 09:10:00”</code><br>5.配置ntp服务器(master1节点)<br><code># vim /etc/ntp.conf</code><br>配置示例：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/SetEnv/ntp1.png" alt=""><br>6.在其它节点上设置ntp客户端<br><code># vim /etc/ntp.conf</code><br>配置示例：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/SetEnv/ntp2.png" alt=""><br>7.配置文件修改完毕后，重启ntp服务<br><code># systemctl restart ntpd</code><br>8.在其它节点上手动同步master1的时间<br><code># ntpdate -u 192.168.0.201</code><br>9.查看同步状态(可能需要稍等一会才能同步上)<br><code># ntpstat</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/SetEnv/ntp3.png" alt=""></p><h3 id="禁用Transparent-Hugepage"><a href="#禁用Transparent-Hugepage" class="headerlink" title="禁用Transparent Hugepage"></a>禁用Transparent Hugepage</h3><p>1.查看当前是否启用(启用状态可能会严重降低Hadoop集群性能，CentOS默认启用)<br><code># cat /sys/kernel/mm/transparent_hugepage/enabled</code></p><pre><code>[always] madvise never    表示已启用always madvise [never]    表示已禁用</code></pre><p>2.禁用Transparent Hugepage(重启生效):<br><code># vim /etc/rc.local</code></p><pre><code>echo never &gt; /sys/kernel/mm/transparent_hugepage/defragecho never &gt; /sys/kernel/mm/transparent_hugepage/enabled</code></pre><p>配置如图：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/SetEnv/trans.png" alt=""><br>3.赋予rc.local文件可执行权限<br><code># chmod +x /etc/rc.d/rc.local</code></p><h3 id="调整vm-swappiness-Linux内核参数"><a href="#调整vm-swappiness-Linux内核参数" class="headerlink" title="调整vm.swappiness Linux内核参数"></a>调整vm.swappiness Linux内核参数</h3><p>该值用于控制从物理内存到磁盘上的虚拟内存的应用数据的交换。值越高，内存交换越积极。值越低，交换的次数越少。</p><p>大多数系统默认为60，但不适用于Hadoop集群，因为即使有足够的内存，Hadoop进程也有可能会被交换到磁盘，影响集群稳定性和性能。</p><p>1.查看当前的参数<br><code># cat /proc/sys/vm/swappiness</code><br><code>30    当前是30，建议设置为1-10之间，最好为1</code><br>2.设置vm.swappiness值为1<br><code># vim /etc/sysctl.conf</code><br><code>vm.swappiness=1</code><br>如图所示:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/SetEnv/vm.png" alt=""></p><h2 id="MySQL-5-6安装"><a href="#MySQL-5-6安装" class="headerlink" title="MySQL 5.6安装"></a>MySQL 5.6安装</h2><p>1.检查MySQL及相关RPM包是否已安装，如果有安装，则移除<br><code># rpm -qa | grep -i mysql</code><br><code># yum -y remove mysql-libxxxx</code><br>2.下载MySQL包：<a href="https://dev.mysql.com/downloads/mysql/5.6.html#downloads" target="_blank" rel="noopener">MySQL-5.6.36-1.linux_glibc2.5.x86_64.rpm-bundle.tar</a><br>解压:<br><code># tar -xvf MySQL-5.6.36-1.linux_glibc2.5.x86_64.rpm-bundle.tar</code><br>3.安装mysql-server<br><code># rpm -ivh MySQL-server-5.6.36-1.linux_glibc2.5.x86_64.rpm</code><br>与已安装的软件有冲突，需要卸载有冲突的软件:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/SetEnv/mysql1.png" alt=""><br><code># yum -y remove xxxxxxxxx</code><br>再次安装mysql-server，安装成功，但是下面执行数据库初始化会报错，缺少一个模块<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/SetEnv/mysql2.png" alt=""><br>需要安装autoconf(需要联网或者搭建本地yum仓库或者从CentOS7安装包里拷出autoconf的rpm包及其依赖包，手动安装):<br><code># yum -y install autoconf</code></p><p><strong>说明</strong>：这里有个坑，即最好是先安装autoconf，然后再装mysql-server，这个时候安装程序就会自动进行Mysql初始化。<br>4.安装客户端<br><code># rpm -ivh MySQL-client-5.6.36-1.linux_glibc2.5.x86_64.rpm</code><br>5.初始化mysql(因为安装server之前没有安装autoconf，所以这里需要手动初始化mysql)<br><code># /usr/bin/mysql_install_db</code><br>6.启动mysql服务<br><code># service mysql start</code><br>若无法启动则将<code>/var/lib/mysql</code>目录下所有文件及子文件夹的用户及用户组设置为<strong>mysql</strong><br><code># chown -R mysql:mysql /var/lib/mysql/</code><br>设置开机启动:<br><code># chkconfig mysql on</code><br><code># chkconfig --list | grep mysql</code><br>7.对mysql进行安全设置<br>查看root账户密码:<br><code># cat /root/.mysql_secret</code><br>执行安全设置(需要确保MySQL服务已经正常启动)：<br><code># /usr/bin/mysql_secure_installation</code></p><pre><code>a)修改root用户密码 Yb)删除匿名账号 Yc)取消root用户远程登录 Nd)删除test库和对test库的访问权限 Ye)刷新授权表使修改生效 Y</code></pre><p>8.进入mysql<br><code># mysql -uroot -p</code><br>9.开放远程登陆权限<br><code>mysql&gt; GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;password&#39; WITH GRANT OPTION;</code><br><code>mysql&gt; FLUSH PRIVILEGES;</code><br>10.MySQL的默认安装位置</p><blockquote><p>/var/lib/mysql/ ———-#数据库目录<br>/usr/share/mysql ——–#配置文件目录<br>/usr/bin ——————#相关命令目录<br>/etc/init.d/mysql ———#启动脚本</p></blockquote><p>11.如果需要修改字符集则需配置<code>/etc/my.cnf</code>文件<br>若<code>etc</code>目录下没有该文件则从<code>/usr/share/mysql/</code>下复制一个过来<br><code># cp /usr/share/mysql/my-default.cnf /etc/my.cnf</code><br>查看字符集:</p><blockquote><p>mysql&gt; show variables like ‘%collation%’;<br>mysql&gt; show variables like ‘%char%’;<br>mysql&gt; show create database databaseName;<br>mysql&gt; show create table tableName;</p></blockquote><h2 id="JDK1-8安装"><a href="#JDK1-8安装" class="headerlink" title="JDK1.8安装"></a>JDK1.8安装</h2><p>1.查看系统自带java版本，如果已安装就先卸载掉<br><code># java -version</code></p><p>2.安装Oracle官网下载jdk的rpm安装包，并使用rpm -ivh packageName安装:<br><a href="https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="noopener">Download jdk1.8</a><br>3.修改环境变量<br><code># vim /etc/profile</code><br>添加如下(使用rpm安装的java在/usr/java/jdk1.8XXXX)</p><pre><code class="profile">export JAVA_HOME=/usr/java/jdk1.8.0_131export JRE_HOME=/usr/java/jdk1.8.0_131/jreexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH</code></pre><p>4.执行命令使环境变量生效<br><code># source /etc/profile</code><br>5.测试<br><code># java -version</code><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/SetEnv/java.png" alt=""></p><h2 id="OVER"><a href="#OVER" class="headerlink" title="OVER"></a>OVER</h2><p>至此，Hadoop集群搭建的环境准备部分已结束。</p>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CentOS </tag>
            
            <tag> 大数据 </tag>
            
            <tag> Hadoop </tag>
            
            <tag> MySQL安装 </tag>
            
            <tag> Java安装 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hadoop版本选型</title>
      <link href="/2017/11/05/HadoopSelect/"/>
      <url>/2017/11/05/HadoopSelect/</url>
      <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>说到大数据，首先得说一说Hadoop，这个Apache旗下的一个顶级项目，一个分布式的存储、计算系统，适用于超大数据量的存储与计算。<br>Hadoop可以说是大数据生态圈的代名词，有很多基于Hadoop集成开发出来的衍生项目，所以面对众多的Hadoop产品，选择一个合适的产品尤为重要。</p><p>除了原生Hadoop之外，比较受欢迎的开源的可以免费使用的第三方发行版Hadoop有：</p><ul><li><a href="https://www.cloudera.com/products/open-source/apache-hadoop/key-cdh-components.html" target="_blank" rel="noopener">Cloudera’s Distribution including Apache Hadoop (CDH)</a></li><li><a href="https://hortonworks.com/products/data-platforms/hdp/" target="_blank" rel="noopener">Hortonworks Data Platform (HDP)</a></li></ul><p>所以这篇文章就简单介绍一下原生Hadoop和第三方发行版Hadoop的区别</p><h2 id="Apache-Hadoop原生版本优缺点"><a href="#Apache-Hadoop原生版本优缺点" class="headerlink" title="Apache Hadoop原生版本优缺点"></a>Apache Hadoop原生版本优缺点</h2><p>优点:</p><ul><li>完全开源免费</li><li>社区活跃，版本更新快</li><li>文档、资料详实</li><li>自由度高，可定制性强</li></ul><p>缺点：</p><ul><li>集群部署、安装、配置复杂。通常部署集群需要编写大量的配置文件，分发到每一台节点上，容易出错，效率低下。</li><li>对集群的监控，运维，需要安装第三方监控软件，运维难度较大。</li><li>组件选择与搭配困难。在Hadoop生态圈中，组件的选择、使用，比如Hive，HBase，Spark等等，需要大量考虑兼容性、稳定性的问题。</li></ul><h2 id="第三方发行版Hadoop优缺点"><a href="#第三方发行版Hadoop优缺点" class="headerlink" title="第三方发行版Hadoop优缺点"></a>第三方发行版Hadoop优缺点</h2><p>优点:</p><ul><li>基于Apache协议，100%开源。</li><li>比Apache Hadoop在兼容性、安全性、稳定性上有增强。第三方发行版通常都经过了大量的测试验证，有众多部署实例。</li><li>提供了部署、安装、配置工具，大大提高了集群部署的效率。</li><li>运维简单。提供了管理、监控、诊断、配置修改的工具，管理配置方便，定位问题快速、准确，使运维工作简单，有效。</li></ul><p>缺点:</p><ul><li>自由度低，可定制性低</li><li>由于是集成起来的Hadoop平台，考虑到稳定性和兼容性，所有组件版本相比原生版本都比较低，因此发行版Hadoop可能不具有原生版本的某些新功能、新特性。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>刚开始学习大数据的时候，最好是从原生Hadoop学起，因为必须要对Hadoop的安装、配置、启动有个大概了解。公司转入大数据行业初期可以考虑使用第三方发行版Hadoop，因为部署、管理、运维方便，稳定性、兼容性强。后期如果觉得第三方发行版不能满足功能需要，或者需要定制个性化功能的话，可以再去考虑Apache原生版本Hadoop，自己进行集成开发。</p><p>对于第三方发行版Hadoop，我只用过CDH，觉得还是蛮好用的。特别是调整集群参数的时候，有一个管理工具（<a href="https://www.cloudera.com/downloads/manager/5-13-0.html" target="_blank" rel="noopener">Cloudera Manager</a>）是真的方便，原生版本还要手动修改配置文件，再手动分发到其他节点，很容易出差错。</p><p>简单体验过国内上海某公司的发行版Hadoop(?DH)，觉得不如CDH好用，而且收费不开源。有一个社区版，没体验过，不知道跟商业版有什么区别。</p><p>HDP没用过，不做评价，只知道可以使用Apache旗下的一个集群管理工具（<a href="https://ambari.apache.org/" target="_blank" rel="noopener">Ambari</a>）来部署和管理。</p><h2 id="OVER"><a href="#OVER" class="headerlink" title="OVER"></a>OVER</h2>]]></content>
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> Hadoop </tag>
            
            <tag> CDH </tag>
            
            <tag> HDP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>给网页加上js特效 - 让网页动起来</title>
      <link href="/2017/08/12/AddCanvas/"/>
      <url>/2017/08/12/AddCanvas/</url>
      <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>刚搭建好的博客网页背景一片惨白，死气沉沉毫无生机，所以就想着给网站加个动态背景什么的，翻了好久，终于在GitHub上找了个可与鼠标互动的js特效：<a href="https://github.com/hustcc/canvas-nest.js" target="_blank" rel="noopener">canvas-nest.js</a>。使用起来也很简单，只需要在html代码<code>&lt;body&gt;&lt;/body&gt;</code>标签里面加入一行<code>&lt;script&gt;</code>代码就行了。</p><p>但是，网站只有一两个html页面的话手动添加还可以，如果网站有几十个甚至上百个html页面，而且Hexo框架generate后的文件夹很多，想找到这些html文件还得一个个翻文件夹，手动的话岂不得累死？！！！</p><p>我去GitHub上canvas-nest项目下看了下，只有一个wordpress的插件，并没有hexo插件，hexo插件库里好像也没有添加外部js代码的插件。</p><p><a href="https://hexo.io/zh-cn/docs/plugins.html" target="_blank" rel="noopener">Hexo官方文档</a>倒是有一句话：<strong>如果您的代码很简单，建议您编写脚本，您只需要把 JavaScript 文件放到 scripts 文件夹，在启动时就会自动载入。</strong>我试过了，载入的时候会报错，没办法，只好自己写了个shell脚本（Git for Win支持执行Shell脚本），所以就有了这篇文章。</p><h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><p>很简单，先找出hexo generate后存放html文件夹下（public文件夹）的所有html文件路径，然后给这些html文件执行添加js代码命令。</p><p>每次执行<code>hexo g</code>都会重新生成html文件，所以不用担心会重复添加的问题。</p><h2 id="shell代码"><a href="#shell代码" class="headerlink" title="shell代码"></a>shell代码</h2><h4 id="简单版："><a href="#简单版：" class="headerlink" title="简单版："></a>简单版：</h4><p>需要先执行<code>hexo g</code>生成静态网页，<br>再执行shell添加js代码，<br>再执行<code>hexo d</code>部署到github。</p><pre><code>echo &quot;+++++++++++++++ 开始添加js代码 +++++++++++++++&quot;find public/ -name index.html &gt; add-js.logaddJs() {    sed -i &#39;/&lt;\/body&gt;/i\&lt;script type=&quot;text/javascript&quot; color=&quot;63,81,181&quot; opacity=&#39;0.7&#39; zIndex=&quot;-1&quot; count=&quot;180&quot; src=&quot;//cdn.bootcss.com/canvas-nest.js/1.0.1/canvas-nest.min.js&quot;&gt;&lt;\/script&gt;&#39; $1}cat add-js.log | while read linedo    addJs $line    echo &quot;add success -&gt; $line&quot;doneecho &quot;+++++++++++++++ 添加js代码完毕 +++++++++++++++&quot;</code></pre><h4 id="懒人版："><a href="#懒人版：" class="headerlink" title="懒人版："></a>懒人版：</h4><p>只不过是把<code>hexo g</code>和<code>hexo d</code>包含进来了而已…<br>一个脚本搞定所有~~~</p><pre><code>echo &quot;++++++++++++ 开始执行{hexo g}命令 ++++++++++++&quot;hexo gecho &quot;+++++++++++++++ 开始添加js代码 +++++++++++++++&quot;find public/ -name index.html &gt; add-js.logaddJs() {    sed -i &#39;/&lt;\/body&gt;/i\&lt;script type=&quot;text/javascript&quot; color=&quot;63,81,181&quot; opacity=&#39;0.7&#39; zIndex=&quot;-1&quot; count=&quot;180&quot; src=&quot;//cdn.bootcss.com/canvas-nest.js/1.0.1/canvas-nest.min.js&quot;&gt;&lt;\/script&gt;&#39; $1}cat add-js.log | while read linedo    addJs $line    echo &quot;add success -&gt; $line&quot;doneecho &quot;+++++++++++++++ 添加js代码完毕 +++++++++++++++&quot;echo &quot;++++++++++++ 开始执行{hexo d}命令 ++++++++++++&quot;hexo d 2&gt;/dev/null</code></pre><h2 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h2><p>复制shell代码，在你的blog目录下新建一个<strong>add-js.sh</strong><br>文件，编辑该文件（编码格式设为<strong>UTF-8</strong>），将刚刚复制的代码粘贴进去，保存。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/AddCanvas/snap0636.png" alt=""></p><p>至于<code>&lt;script&gt;&lt;/script&gt;</code>标签里面的参数含义，可以去GitHub项目<a href="https://github.com/hustcc/canvas-nest.js" target="_blank" rel="noopener">canvas-nest.js</a>上了解详细信息。</p><p>写完文章以后，<br><strong>简单版：</strong><br>先执行：<code>hexo g</code><br>再执行：<code>./add-js.sh</code><br>最后执行：<code>hexo d</code></p><p><strong>懒人版：</strong><br>直接执行：<code>./add-js.sh</code></p><p>shell执行完毕后会在当前文件夹生成一个<strong>add-js.log</strong>文件，里面存放的是public目录下所有<strong>index.html</strong>的路径。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/AddCanvas/snap0637.png" alt=""></p><p>控制台会也输出哪些文件被修改了：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/AddCanvas/snap0638.png" alt=""></p><p>搞定！！！</p><p>另外，我这Linux Shell是刚学的，代码肯定还能再优化。但是，这又不是不能用，总比手动快多了，手动滑稽~</p>]]></content>
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 博客搭建 </tag>
            
            <tag> Hexo </tag>
            
            <tag> js样式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>利用GitHub Pages + Hexo框架搭建个人博客</title>
      <link href="/2017/07/30/HexoInstall/"/>
      <url>/2017/07/30/HexoInstall/</url>
      <content type="html"><![CDATA[<p>+++本文全部是在Windows10平台联网环境下操作的+++</p><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><h4 id="安装Node-js"><a href="#安装Node-js" class="headerlink" title="安装Node.js"></a>安装<a href="https://nodejs.org/en/download/" target="_blank" rel="noopener">Node.js</a></h4><p>Hexo是基于Node.js的静态博客框架，所以需要安装这个。官网下载msi安装程序（我用的是node-v6.10.3-x64.msi）安装，同时安装过程中不要忘了勾选Add  to PATH选项，用来添加系统环境变量:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0574.png" alt=""></p><h4 id="安装Git-for-Win"><a href="#安装Git-for-Win" class="headerlink" title="安装Git for Win"></a>安装<a href="https://github.com/waylau/git-for-win" target="_blank" rel="noopener">Git for Win</a></h4><p>Git可以很方便的提交代码到GitHub仓库中。由于众所周知的原因，官网下载Git会很慢，所以我找了个国内下载源。<br>Git安装（全部默认即可）完成后开始菜单会有个Git文件夹，我们需要用到的是Git Bash:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0575.png" alt=""></p><h4 id="注册GitHub账号"><a href="#注册GitHub账号" class="headerlink" title="注册GitHub账号"></a>注册<a href="https://github.com/" target="_blank" rel="noopener">GitHub账号</a></h4><p>因为需要用到GitHub的GitHub Pages功能，所以需要有一个GitHub账号。还有，没有GitHub账号的程序员不是一个合格的程序员！</p><h4 id="Git配置"><a href="#Git配置" class="headerlink" title="Git配置"></a>Git配置</h4><p>1.配置账户：<br>打开Git Bash，输入以下两条命令(name替换成你的github用户名，email替换成你注册github时用的邮箱):<br><code>git config --global user.name &quot;name&quot;</code><br><code>git config --global user.email &quot;email&quot;</code></p><p>可以使用<code>git config --list</code>命令来查看当前的配置信息，可以看到<code>user.name</code>和<code>user.email</code>已经出现在了最后两行:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0577.png" alt=""><br>如果你发现信息输入有误，重新执行上面两条命令即可。</p><p>2.配置SSH密钥：<br>打开Git Bash，确保当前位置是用户工作目录，也就是:<strong>~</strong>这个位置：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0600.png" alt=""><br>不在这个位置的话可以输入：<br><code>cd ~</code><br>进入这个目录<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0602.png" alt=""><br>可以看到，这个目录其实是对应电脑上<strong>C:\Users\用户名</strong>这个位置。<br>执行下面的命令来生成ssh密钥文件：<br><code>ssh-keygen -t rsa -C &quot;email&quot;</code><br>email替换成你注册github时用的邮箱。<br>一路回车，过程中让你输入东西的时候不要输入，直接回车，使用默认即可，完后当前目录<br>会多出一个名叫<strong>.ssh</strong>的文件夹，我们进入这个文件夹：<br><code>cd .ssh</code><br>里面有两个密钥文件：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0603.png" alt=""><br>不带<code>.pub</code>后缀的是私钥，带<code>.pub</code>后缀的是公钥，私钥我们要自己保存好，不要泄露出去，公钥是可以公开分享的。<br>然后我们把公钥里面的内容全部复制出来，可以使用cat命令使密钥内容显示出来再复制，也可以使用文本编辑器（不推荐使用记事本）打开再复制：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0604.png" alt=""></p><p>再然后登陆我们前面注册的github账号，点击头像，进入设置<br>找到<strong>SSH and GPG keys</strong>，点击右侧的<strong>New SSH key</strong>：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0605.png" alt=""><br><strong>Title</strong>随便填，把我们刚才复制的公钥内容粘贴进<strong>Key</strong>下面的输入框内，点击<strong>Add SSH key</strong><br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0606.png" alt=""></p><p>最后测试一下SSH<br>命令行执行：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0609.png" alt=""><br>第一次执行这个命令的话程序会问你是否要继续进行连接，输入<code>yes</code>回车就好。<br>然后控制台输出：<br><code>Hi Staroon! You&#39;ve successfully authenticated, but GitHub does not provide shell access.</code><br>说明SSH密钥配置成功！！！</p><h4 id="创建本地Git仓库"><a href="#创建本地Git仓库" class="headerlink" title="创建本地Git仓库"></a>创建本地Git仓库</h4><p>我这里把它建在了D盘，所有文件夹名字都是可以自定义的。打开Git Bash:<br><code>cd \d:</code><br><code>mkdir git_repository</code><br>创建我们的博客文件夹：<br><code>cd git_repository</code><br><code>mkdir blog</code><br>进入blog文件夹：<br><code>cd blog</code><br>这是我电脑上的blog文件夹全路径: <strong>/d/git_repository/blog</strong></p><h2 id="部署Hexo"><a href="#部署Hexo" class="headerlink" title="部署Hexo"></a>部署Hexo</h2><h4 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h4><p>打开Git Bash，执行下面的命令:<br><code>npm install -g hexo-cli</code><br>稍等一会儿，不要着急，会开始自动下载安装:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0579.png" alt=""><br>可能会报下面的两个警告，不用理会，我还没发现有什么影响。</p><blockquote><p><code>npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@^1.0.0 (node_modules\hexo-cli\node_modules\chokidar\node_modules\fsevents):</code><br><code>npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.1.2: wanted {&quot;os&quot;:&quot;darwin&quot;,&quot;arch&quot;:&quot;any&quot;} (current: {&quot;os&quot;:&quot;win32&quot;,&quot;arch&quot;:&quot;x64&quot;})</code>   </p></blockquote><p>可以使用<code>hexo -v</code>命令测试是否安装成功:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0580.png" alt=""></p><h4 id="初始化Hexo"><a href="#初始化Hexo" class="headerlink" title="初始化Hexo"></a>初始化Hexo</h4><p>进入blog文件夹，空白处鼠标右键，点击Git Bash Here进入命令窗口，执行初始化命令：<br><code>hexo init</code><br>等待初始化完成…<br>最后会有一句: </p><blockquote><p><code>INFO  Start blogging with Hexo!</code></p></blockquote><p>然后执行:<br><code>npm install</code><br>等待执行结束，初始化成功！现在就已经可以开始使用Hexo了！！！</p><p>但是还有一些插件最好提前装上：</p><ul><li>索引生成器：<code>npm install hexo-generator-index --save</code></li><li>归档生成器：<code>npm install hexo-generator-archive --save</code></li><li>分类生成器：<code>npm install hexo-generator-category --save</code></li><li>标签生成器：<code>npm install hexo-generator-tag --save</code></li><li>本地搜索: <code>npm install hexo-generator-search --save</code></li><li>本地化服务：<code>npm install hexo-server --save</code></li><li>Git部署功能：<code>npm install hexo-deployer-git --save</code></li><li>渲染器：<code>npm install hexo-renderer-marked --save</code></li><li>渲染器：<code>npm install hexo-renderer-stylus --save</code></li><li>置顶功能：<code>npm install hexo-helper-post-top --save</code></li><li>二维码分享: <code>npm install hexo-helper-qrcode --save</code></li><li>站点地图: <code>npm install hexo-generator-seo-friendly-sitemap --save</code></li></ul><p>初始化完成后的文件夹结构是这样的:<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0581.png" alt=""></p><p>关于该目录下的文件及文件夹说明，查看<a href="https://hexo.io/zh-cn/docs/setup.html" target="_blank" rel="noopener">hexo官方文档</a>即可。</p><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>配置文件<code>_config.yml</code>，具体的配置信息还是去<a href="https://hexo.io/zh-cn/docs/configuration.html" target="_blank" rel="noopener">hexo官方文档</a>看吧。</p><p>建议用专业的文本编辑器编辑该文件，不要用Win自带的记事本。我用的是EditPlus.</p><h2 id="开始写文章"><a href="#开始写文章" class="headerlink" title="开始写文章"></a>开始写文章</h2><p>参考<a href="https://hexo.io/zh-cn/docs/writing.html" target="_blank" rel="noopener">hexo官方文档</a>挺好，突然发现官方文档挺详细。。。<br>说明一下，官方文档里新建文章的命令是:<br><code>hexo new [layout] &lt;title&gt;</code><br><code>[layout]</code>默认为<code>post</code>，可以不用加<code>[layout]</code>命令。<br>比如我想新建一个名叫<code>helloHexo</code>的文章，直接命令：<br><code>hexo new &quot;helloHexo&quot;</code><br>即可，然后控制台会输出该文档位置信息：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0591.png" alt=""><br>进入存放我们文章的文件夹，可以看到我们的<code>helloHexo.md</code>已经在这了，另外还有一个<code>hello-word.md</code>文件，这里面写的是一些常用hexo命令，可以删掉这个文件。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0592.png" alt=""><br>用文本编辑器或者Markdown编辑器打开<code>helloHexo.md</code>就可以写文章啦~~<br>我正在用的Markdown编辑器是：<a href="https://code.visualstudio.com/" target="_blank" rel="noopener">Visual Studio Code</a></p><p>打开该文件，里面已经有一部分内容了：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0593.png" alt=""></p><p>这一部分内容官方称为<a href="https://hexo.io/zh-cn/docs/front-matter.html" target="_blank" rel="noopener">Front-matter</a>，可以参考官方文档补充这一部分的内容。</p><p>三道杠<code>---</code>下面的空白地方就是我们要写文章内容的部分了，全部使用Markdown语法。</p><p>一些Markdown语法：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0594.png" alt=""></p><p>文章写完了，先预览一下吧~~<br>这就需要用到我们之前装的server插件了<br>命令行输入：<br><code>hexo server</code><br>启动本地服务器：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0595.png" alt=""></p><p>浏览器访问 <code>http://localhost:4000/</code> 就可以看到最原始状态的博客啦~<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0596.png" alt=""></p><p>说明：同样的Markdown语法在不同的网站上可能会显示出不同的效果，不过没关系，只要能在Github上显示出我们想要的效果就行了，因为我们的目的就是把博客部署在Github上！</p><p>默认的主题太丑？<br>hexo有很多第三方主题，如何配置使用可以去各主题官网查看。</p><p>如何搜索主题？<br>Github上搜索关键字<code>hexo theme</code>一大堆主题</p><p>至此，本地博客已经搭建完成！</p><h2 id="部署博客到GitHub"><a href="#部署博客到GitHub" class="headerlink" title="部署博客到GitHub"></a>部署博客到GitHub</h2><h4 id="创建Github仓库"><a href="#创建Github仓库" class="headerlink" title="创建Github仓库"></a>创建Github仓库</h4><p>仓库名字一定要是：<strong>{github username}.github.io</strong><br>比如我的github用户名是<strong>Staroon</strong>，则仓库名字为：<strong>Staroon.github.io</strong><br>用户名即是Owner那里的用户名<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0599.png" alt=""></p><h4 id="部署配置"><a href="#部署配置" class="headerlink" title="部署配置"></a>部署配置</h4><p>配置<code>_config.yml</code>文件。<br>翻到最下面找到<strong>deploy</strong>这一项，填写：</p><blockquote><p>type: git<br>repo: <a href="mailto:git@github.com" target="_blank" rel="noopener">git@github.com</a>:<strong>{username}</strong>/<strong>{username}</strong>.github.io.git<br>branch: master   </p></blockquote><p>如下图所示<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0607.png" alt=""></p><h4 id="博客发布"><a href="#博客发布" class="headerlink" title="博客发布"></a>博客发布</h4><p>命令行执行：<br><code>hexo g</code><br>然后执行：<br><code>hexo d</code><br>当控制台输出：<code>INFO  Deploy done: git</code>的时候，说明项目已经成功的发布到github上，耐心等待一会儿，就可以通过访问<strong>{username}.github.io</strong>来访问博客了~~</p><h4 id="博客更新"><a href="#博客更新" class="headerlink" title="博客更新"></a>博客更新</h4><p><code>hexo new &quot;name&quot;</code>或者直接在<strong>/source/_posts/</strong>里面新建<code>.md</code>文件<br>写完Markdown文章后，执行：<br><code>hexo g -d</code><br>即可一键部署。</p><p>每次博客内容有改动都可以使用<code>hexo g -d</code>进行部署。</p><p>至此，博客搭建教程已经全部完成！</p><h2 id="注册个人域名"><a href="#注册个人域名" class="headerlink" title="注册个人域名"></a>注册个人域名</h2><p>找个正规的域名厂商注册即可。<br>我是在<a href="https://sg.godaddy.com/zh/" target="_blank" rel="noopener">GoDaddy</a>上注册的。</p><h2 id="将个人域名与博客绑定"><a href="#将个人域名与博客绑定" class="headerlink" title="将个人域名与博客绑定"></a>将个人域名与博客绑定</h2><h4 id="DNS设置"><a href="#DNS设置" class="headerlink" title="DNS设置"></a>DNS设置</h4><p>国内推荐使用<a href="https://www.dnspod.cn/" target="_blank" rel="noopener">DNSPod</a><br>国外的话可以使用<a href="https://www.cloudflare.com" target="_blank" rel="noopener">Cloudflare</a>，可以免费使用https。</p><p>这里以DNSPod为例：<br>注册登录，在<strong>域名解析</strong>里面<strong>添加域名</strong><br>将上面注册的域名添加进去<br>然后点击<strong>添加纪录</strong>添加3条记录，如下图所示：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0610.png" alt=""><br>两条A记录指向的IP分别是：</p><ul><li>192.30.252.153</li><li>192.30.252.154</li></ul><p>CNAME记录指向的是你的原博客地址:<strong>{username}.github.io</strong></p><h4 id="域名服务器设置"><a href="#域名服务器设置" class="headerlink" title="域名服务器设置"></a>域名服务器设置</h4><p>这里以GoDaddy为例：<br>进入<strong>我的产品</strong>页，找到要管理的域名，点击<strong>DNS</strong>进入DNS管理页面：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0611.png" alt=""></p><p>然后找到<strong>域名服务器</strong>点击<strong>更改</strong>：</p><p><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0612.png" alt=""></p><p>将域名服务器修改为DNSPod提供的域名服务器即可。<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0613.png" alt=""></p><h4 id="博客内设置"><a href="#博客内设置" class="headerlink" title="博客内设置"></a>博客内设置</h4><p>在博客<strong>source</strong>目录下，新建一个<strong>CNAME</strong>文件<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0614.png" alt=""><br>编辑该文件，将你的新域名写进去：<br><img src="https://blogfiles-1254091060.cos.ap-shanghai.myqcloud.com/blog/hexoInstall/snap0615.png" alt=""></p><p>然后执行<code>hexo g -d</code>重新部署</p><p>完成！！！</p><p>耐心等待一会儿，就可以使用新域名访问博客了！</p>]]></content>
      
      <categories>
          
          <category> 教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 博客搭建 </tag>
            
            <tag> Hexo </tag>
            
            <tag> GoDaddy域名 </tag>
            
            <tag> DNSPod </tag>
            
            <tag> GitHub </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hello World</title>
      <link href="/2017/06/04/HelloWorld/"/>
      <url>/2017/06/04/HelloWorld/</url>
      <content type="html"><![CDATA[<p>这里是我的第一篇文章。</p><p>所以标题起名叫<strong>Hello World</strong>。</p><p>在<a href="https://www.ithome.com/html/win10/311572.htm" target="_blank" rel="noopener">IT之家</a>看到了利用Github搭建个人博客的教程，觉得挺好玩，就跟着教程做了一下。过程中发现那篇教程并不是很完美，有很多坑且很繁琐，然后去网上搜各种文档，折腾到大半夜才搞定。</p><p>以后就打算在这里写东西了，闲着没事的时候写(zhuan)一(zai)点技术文档或者美文过来，嘿嘿~</p><p>也算是一个小小窝了~</p><p>改天我也写一个搭博客的教程，作为这里的第一篇技术文档(●ˇ∀ˇ●)</p>]]></content>
      
      <categories>
          
          <category> 杂记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 杂记 </tag>
            
            <tag> 随笔 </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
